{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7.8\n",
      "Python 3.7.7\n"
     ]
    }
   ],
   "source": [
    "!jupyter notebook --version\n",
    "!python --version\n",
    "#5.7.8\n",
    "#Python 3.7.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Deep learning to estimate mobility for organic molecules*\n",
    "\n",
    "#### Load, view, and preprocess dataset\n",
    "- Load mobility dataset containing many organic molecules and their associated mobility\n",
    "- Pre-process data and split to test/train sets\n",
    "[QM9](http://moleculenet.ai/datasets-1)\n",
    "QM9 (structure): Geometric,  energetic, electronic and thermodynamic properties of DFT-modelled small molecules dataset to train our models. \n",
    "The QM9 dataset contains the mobility of various small organic molecules.\n",
    "We'll also preprocess the dataset and create train/test splits for the Convolutional Neural Network (CNN) and Variational AutoEncoder (VAE) models.\n",
    "QM9 is a comprehensive dataset that provides geometric, energetic, electronic and thermodynamic properties for a subset of GDB-17 database, comprising 134 thousand stable organic molecules with up to 9 heavy atoms.  All molecules are modeled using density functional theory (B3LYP/6-31G(2df,p) based DFT).\n",
    "\n",
    "    - \"mol_id\" - Molecule ID (gdb9 index) mapping to the .sdf file\n",
    "    - \"A\" - Rotational constant (unit: GHz)\n",
    "    - \"B\" - Rotational constant (unit: GHz)\n",
    "    - \"C\" - Rotational constant (unit: GHz)\n",
    "    - \"mu\" - Dipole moment (unit: D)\n",
    "    - \"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "    - \"homo\" - Highest occupied molecular orbital energy (unit: Hartree)\n",
    "    - \"lumo\" - Lowest unoccupied molecular orbital energy (unit: Hartree)\n",
    "    - \"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "    - \"r2\" - Electronic spatial extent (unit: Bohr^2)\n",
    "    - \"zpve\" - Zero point vibrational energy (unit: Hartree)\n",
    "    - \"u0\" - Internal energy at 0K (unit: Hartree)\n",
    "    - \"u298\" - Internal energy at 298.15K (unit: Hartree)\n",
    "    - \"h298\" - Enthalpy at 298.15K (unit: Hartree)\n",
    "    - \"g298\" - Free energy at 298.15K (unit: Hartree)\n",
    "    - \"cv\" - Heat capavity at 298.15K (unit: cal/(mol*K))\n",
    "    - \"u0_atom\" - Atomization energy at 0K (unit: kcal/mol)\n",
    "    - \"u298_atom\" - Atomization energy at 298.15K (unit: kcal/mol)\n",
    "    - \"h298_atom\" - Atomization enthalpy at 298.15K (unit: kcal/mol)\n",
    "    - \"g298_atom\" - Atomization free energy at 298.15K (unit: kcal/mol)\n",
    "  \"u0_atom\" ~ \"g298_atom\" (used in MoleculeNet) are calculated from the\n",
    "  differences between \"u0\" ~ \"g298\" and sum of reference energies of all\n",
    "  atoms in the molecules, as given in\n",
    " [here](https://figshare.com/articles/Atomref%3A_Reference_thermochemical_energies_of_H%2C_C%2C_N%2C_O%2C_F_atoms./1057643).\n",
    " [here](https://github.com/deepchem/deepchem/blob/master/deepchem/molnet/load_function/qm9_datasets.py)\n",
    "\n",
    "\n",
    "we will plot a histogram of SMILES string lengths from dataset. These lengths will be used to determine the length of the inputs for our CNN and VAE models. \n",
    "Below are examples of the SMILES representation: \n",
    "1. Methane: 'C'\n",
    "2. Pentane: 'CCCCC'\n",
    "3. Methanol and Ethanol: 'CO' and 'CCO'\n",
    "4. Pyridine: 'C1:C:C:N:C:C:1'\n",
    "\n",
    "To learn more about the SMILES representation, click [here](https://chem.libretexts.org/Courses/University_of_Arkansas_Little_Rock/ChemInformatics_(2017)%3A_Chem_4399%2F%2F5399/2.3%3A_Chemical_Representations_on_Computer%3A_Part_III).\n",
    "\n",
    "#### Data preparation\n",
    "\n",
    "First, we'll get the unique character set from all SMILES strings in the dataset. \n",
    "Then we will use the unique character set to convert our SMILES strings to a one-hot representation, which is a representation that converts raw strings of text to numerical inputs for our models.\n",
    "\n",
    "In a one-hot representation, each character of our SMILES string is encoded as a vector of zeros, except for one non-zero value. For instance, the character 'C' in the SMILES string is converted to a vector of length 31, consisting of 30 zeros and one non-zero entry of one. The length of this vector (31 in our case) is the total number of unique characters in the dataset.\n",
    "\n",
    "Given a string of 5 characters (say Pentane, which is represented as 'CCCCC'), we would thus get 5 vectors each of length 31. Since different molecules have different SMILES string lengths, we can pre-define the length of each string to be the maximum length from the database, with smaller molecules represented with additional characters. In our case, this maximum length is 40 and we represent the extra characters for smaller molecules with pre-defined one-hot vectors. This means that each molecule is now represented as a set of 40 vectors, each of length 31. We can represent this as a 40x31 matrix.\n",
    "\n",
    "One-hot encoding is commonly used in natural language processing, and you can learn more about one-hot encoding [here](https://en.wikipedia.org/wiki/One-hot). \n",
    "\n",
    "Let's briefly visualize what our input data looks like using a heatmap that shows the position of each character in the SMILES string, you can change the index to see various molecules. Each molecule is represented by a 40x31 sparse matrix, the bright spots in the heatmap indicate the position at which a one is found in the matrix. For instance, the first row has a bright spot at index 18, indicating that the first character is 'C'. The second row has a bright spot at index 23, which indicates that the second character is 'O'. For the compound Dimethoxymethane with a SMILES string 'COCOC', we expect the matrix to have alternating bright spots at index 18 and index 23 for the first five rows. Beyond that, the rows all have a bright spot at index 1, which stands for the extra characters padded on to our string to make all SMILES strings the same length. The heatmap below is plotted using the [Seaborn](https://seaborn.pydata.org/) library.\n",
    "\n",
    "Finally, we will define our input and output and create test/train splits in the dataset.\n",
    "\n",
    "#### Train a Convolutional neural network (CNN) \n",
    "- Train a CNN to predict Mobility\n",
    "- Predict mobility from any given SMILES representation of a molecule \n",
    "\n",
    "#### Train a Variational autoencoder (VAE)\n",
    "- Train a VAE to take an encoded SMILES as input and learn a mapping from encoded SMILES to latent space and back to the input\n",
    "- Use a portion of the VAE to generate SMILES by sampling from a unit gaussian\n",
    "\n",
    "[Keras](https://keras.io/) \n",
    "[Tensorflow](https://www.tensorflow.org/)\n",
    "[Pandas](https://pandas.pydata.org/) \n",
    "[Numpy](https://numpy.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/nanohub/bbishnoi/.local/lib/python3.8/site-packages\n",
    "#!conda env list\n",
    "#!conda update -n base conda \n",
    "#!conda create -n py37 python=3.7\n",
    "#!conda create -n yaml24 yaml=0.2.4 -c conda-forge -y\n",
    "#!conda info --envs\n",
    "#!conda remove -n <envs_name> --all\n",
    "#!source debian10/anaconda/anaconda-7/bin/activate\n",
    "#!python -V\n",
    "#!conda activate py37\n",
    "#!python -V\n",
    "#!conda deactivate \n",
    "#!python -V\n",
    "#!python -m pip install --user <pacakge>\n",
    "#!pip3 show <pacakge>\n",
    "#!pip3 list\n",
    "#!pip3 install pipreqs\n",
    "#!pipreqs .\n",
    "#!\n",
    "#!\n",
    "#!python -m pip install --user pymatgen\n",
    "#!python -m pip install --user matminer\n",
    "#!python -m pip install --user mendeleev\n",
    "#!python -m pip install --user keras_sequential_ascii\n",
    "#!python -m pip install --user -U kaleido\n",
    "#!python -m pip install --user plotly\n",
    "#!python -m pip install --user lolopy\n",
    "#!conda install -c plotly plotly-orca\n",
    "# import sys\n",
    "#print(sys.path)\n",
    "#!python -m pip install --user <pacakge>\n",
    "#!python -m pip install --user  python-utils \n",
    "#!conda install -c conda-forge python-utils -y\n",
    "#conda install -c conda-forge/label/gcc7 python-utils\n",
    "#!python -m pip install --user livelossplot\n",
    "from subprocess import call\n",
    "import gzip\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "#!ls gdrive/MyDrive/'Colab Notebooks'/data/qm9.csv\n",
    "#!ls /home/nanohub/bbishnoi/data/results/vae/qm9.csv \n",
    "#!ls /home/nanohub/bbishnoi/data/results/1909584/citrinednn/bin/utils.py\n",
    "#!python -m pip install --user numpy scipy matplotlib ipython jupyter pandas sympy nose\n",
    "#!ls /apps/citrinednn/r15/bin/utils.py\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_data, head_size, data_size): # This function loads and parses the data\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(head_size)\n",
    "        buf = bytestream.read(data_size * num_data)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8)\n",
    "    return data\n",
    "\n",
    "def load_data():\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz  -o \" + os.getcwd() + \"t10k-images-idx3-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz -o \" + os.getcwd() + \"train-images-idx3-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz -o \" + os.getcwd() + \"train-labels-idx1-ubyte.gz\", shell=True)\n",
    "    call(\"wget -nc https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz -o \" + os.getcwd() + \"t10k-labels-idx1-ubyte.gz\", shell=True)\n",
    "\n",
    "    testImages = extract_data(os.getcwd()  + '/t10k-images-idx3-ubyte.gz', 10000, 16, 28*28)\n",
    "    trainImages = extract_data(os.getcwd() + '/train-images-idx3-ubyte.gz', 60000, 16, 28*28)\n",
    "    trainLabels = extract_data(os.getcwd() + '/train-labels-idx1-ubyte.gz', 60000, 8, 1)\n",
    "    testLabels = extract_data(os.getcwd()  + '/t10k-labels-idx1-ubyte.gz', 10000, 8, 1)\n",
    "\n",
    "    return trainImages,testImages,trainLabels,testLabels\n",
    "\n",
    "\n",
    "trainImages,testImages,trainLabels,testLabels = load_data()\n",
    "\n",
    "trainImages = (np.reshape(trainImages,(60000, 28, 28))).astype(np.uint8)\n",
    "testImages = (np.reshape(testImages,(10000, 28, 28))).astype(np.uint8)\n",
    "trainLabels = (np.reshape(trainLabels,(60000, 1))).astype(np.uint8)\n",
    "testLabels = (np.reshape(testLabels,(10000, 1))).astype(np.uint8)\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # Label Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install --user pymatgen-db\n",
    "from pymatgen.db import QueryEngine\n",
    "qe = QueryEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os, stat\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    user = str(input())\n",
    "    clear_output()\n",
    "    if user == None:\n",
    "        raise TypeError('Empty')\n",
    "    with open(os.path.expanduser('~/.wolframkey.txt'), 'w') as keyfile:\n",
    "        keyfile.write(user)\n",
    "    os.chmod(os.path.expanduser('~/.wolframkey.txt'), stat.S_IREAD | stat.S_IWRITE)\n",
    "    del user\n",
    "    print(\"Success\")\n",
    "except:\n",
    "    print(\"Something seems wrong with your key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, stat\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    user = str(input())\n",
    "    clear_output()\n",
    "    if user == None:\n",
    "        raise TypeError('Empty')\n",
    "    with open(os.path.expanduser('~/.citrinekey.txt'), 'w') as keyfile:\n",
    "        keyfile.write(user)\n",
    "    os.chmod(os.path.expanduser('~/.citrinekey.txt'), stat.S_IREAD | stat.S_IWRITE)\n",
    "    del user\n",
    "    print(\"Success\")\n",
    "except:\n",
    "    print(\"Something seems wrong with your key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines import both libraries and then define an array with elements to be used below\n",
    "\n",
    "#Citrination\n",
    "from citrination_client import *\n",
    "from matminer.data_retrieval.retrieve_Citrine import CitrineDataRetrieval\n",
    "#Wolframalpha\n",
    "import wolframalpha\n",
    "\n",
    "#Misc. Tools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Import WolframAlpha API Key\n",
    "file = open(os.path.expanduser('~/.wolframkey.txt'),\"r+\")\n",
    "apikey_wolfram = file.readline()\n",
    "file.close()\n",
    "\n",
    "#Import Citrine API Key\n",
    "file = open(os.path.expanduser('~/.citrinekey.txt'),\"r+\")\n",
    "apikey_citrine = file.readline()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, stat\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    user = str(input())\n",
    "    clear_output()\n",
    "    if not user.isalnum():\n",
    "        raise TypeError('Wrong Key')\n",
    "    if user == None:\n",
    "        raise TypeError('Empty')\n",
    "    with open(os.path.expanduser('~/.mpkey.txt'), 'w') as keyfile:\n",
    "        keyfile.write(user)\n",
    "    os.chmod(os.path.expanduser('~/.mpkey.txt'), stat.S_IREAD | stat.S_IWRITE)\n",
    "    del user\n",
    "    print(\"Success\")\n",
    "except:\n",
    "    print(\"Something seems wrong with your key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines import both libraries and then define an array with elements to be used below\n",
    "\n",
    "#Pymatgen and sub-libraries\n",
    "\n",
    "#import pymatgen as pymat\n",
    "#import mendeleev as mendel\n",
    "import pymatgen\n",
    "#from pymatgen import MPRester, Composition, Element, Structure\n",
    "from pymatgen.ext.matproj import MPRester, Composition, Element, Structure\n",
    "\n",
    "#Misc. Tools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Import API Key\n",
    "file = open(os.path.expanduser('~/.mpkey.txt'),\"r+\")\n",
    "apikey = file.readline()\n",
    "file.close()\n",
    "rester = MPRester(apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines import both libraries and then define an array with elements to be used below\n",
    "\n",
    "#Pymatgen and sub-libraries\n",
    "import pymatgen\n",
    "from pymatgen.ext.matproj import MPRester, Composition, Element, Structure\n",
    "from pymatgen.io.vasp import Vasprun\n",
    "from pymatgen.entries.computed_entries import ComputedEntry\n",
    "from pymatgen.entries.compatibility import MaterialsProjectCompatibility\n",
    "from pymatgen.util.plotting import *\n",
    "from pymatgen.analysis.phase_diagram import *\n",
    "#import pymatgen.core.composition\n",
    "from pymatgen.apps.borg.hive import VaspToComputedEntryDrone\n",
    "from pymatgen.entries.compatibility import MaterialsProjectCompatibility\n",
    "import json\n",
    "\n",
    "#This is a utility function that will transform the chemicalFormula column into a Matminer composition object, which will be then used to extract features.\n",
    "def get_compostion(c): # Function to get compositions from chemical formula using pymatgen\n",
    "    try:\n",
    "        return Composition(c)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "#Misc. Tools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "#Import API Key\n",
    "file = open(os.path.expanduser('~/.mpkey.txt'),\"r+\")\n",
    "apikey = file.readline()\n",
    "file.close()\n",
    "#Define MP API rester key\n",
    "rester = MPRester(apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hackingmaterials.lbl.gov/matminer/featurizer_summary.html\n",
    "#https://github.com/CitrineInformatics/lolo/blob/develop/python/examples/ling-immi-2017.ipynb\n",
    "from matminer.data_retrieval.retrieve_Citrine import CitrineDataRetrieval\n",
    "from matminer.featurizers.base import MultipleFeaturizer\n",
    "from matminer.featurizers import composition as cf\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "\n",
    "from matminer.datasets import get_available_datasets\n",
    "#from matminer.data_retrieval.retrieve_Citrine import CitrineDataRetrieval\n",
    "from matminer.data_retrieval.retrieve_MP import MPDataRetrieval\n",
    "get_available_datasets()\n",
    "\n",
    "def get_compostion(c): # Function to get compositions from chemical formula using pymatgen\n",
    "    try:\n",
    "        return Composition(c)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "data['composition'] = data['chemicalFormula'].apply(get_compostion) # Transformation of chemicalformula string into Matminer composition\n",
    "data['Measuring Temperature'] = pd.to_numeric(data['Measuring Temperature'], errors='coerce') # Transformation of Measuring Temp dataframe column from type <str> to a numberic type <int>\n",
    "data[property_interest] = pd.to_numeric(data[property_interest], errors='coerce') # Transformation of our property of interest dataframe column from type <str> to a numberic type <int>\n",
    "\n",
    "data = data[data['Crystallographic Structure'] == 'Cubic'] # Filter all non-cubic structures\n",
    "data = data[data['Measuring Temperature']<30] # Filter all high temperature measurements (over room temperature)\n",
    "data = data[data['Measuring Temperature']>18] # Filter all low temperature measurements (over room temperature)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True) # Reindexing of dataframe rows\n",
    "\n",
    "#Before removing duplicates, we will store all the experimental values for compositions that include Tantalum.\n",
    "ta_indexes = []\n",
    "for _ in range(len(data)):\n",
    "    if (\"Zr\" in data['composition'][_] and \"Ta\" in data['composition'][_] and len(data['composition'][_])==5):\n",
    "        ta_indexes.append(_)\n",
    "    elif (\"Zr\" in data['composition'][_] and len(data['composition'][_])==4):\n",
    "        ta_indexes.append(_) \n",
    "        \n",
    "ta_dataframe = data[data.index.isin(ta_indexes)]\n",
    "#display(ta_dataframe)        \n",
    "        \n",
    "x_values_exp = [_[\"Ta\"] for _ in list(ta_dataframe['composition'])]\n",
    "y_values_exp = list(ta_dataframe['Ionic Conductivity'])\n",
    "\n",
    "# In order to reduce noise in the neural network and deal with the inconsistencies in the data, we will filter repeated composition values from different measurements and replace the value for ionic conductivity with the median of the values.\n",
    "\n",
    "dup_indexes = data[data.duplicated(subset = data.columns.tolist()[0], keep=False)].index.tolist()\n",
    "\n",
    "dup_dataframe =data[data.duplicated(subset = data.columns.tolist()[0], keep=False)]\n",
    "\n",
    "#duplicates = [[dup_dataframe.iloc[x][0], dup_dataframe.iloc[x][4], dup_indexes[x]] for x in range(len(dup_dataframe.index))]\n",
    "duplicates = [[dup_dataframe.iloc[x][0], dup_dataframe.iloc[x][4], dup_indexes[x], dup_dataframe.iloc[x][-2]] for x in range(len(dup_dataframe.index))]\n",
    "duplicate_compositions = {k: [] for k in set([dup_dataframe.iloc[x][0] for x in range(len(dup_dataframe.index))])}\n",
    "duplicate_indexes = {k: [] for k in set([dup_dataframe.iloc[x][0] for x in range(len(dup_dataframe.index))])}\n",
    "duplicate_years = {k: [] for k in set([dup_dataframe.iloc[x][0] for x in range(len(dup_dataframe.index))])}\n",
    "\n",
    "for _ in duplicates:\n",
    "    duplicate_compositions[_[0]].append(_[1])\n",
    "    duplicate_indexes[_[0]].append(_[2]) \n",
    "    duplicate_years[_[0]].append(_[3])\n",
    "\n",
    "for k in duplicate_compositions:\n",
    "    \n",
    "    duplicate_compositions[k] = np.median(duplicate_compositions[k])\n",
    "    data.at[duplicate_indexes[k][0], 'Ionic Conductivity'] = duplicate_compositions[k]  \n",
    "\n",
    "    duplicate_years[k] = np.min(duplicate_years[k])\n",
    "    data.at[duplicate_indexes[k][0], 'Year Published'] = duplicate_years[k]      \n",
    "    data = data.drop(duplicate_indexes[k][1:], axis = 0)\n",
    "\n",
    "data = data.reset_index()\n",
    "data = data.drop(['index'], axis = 1)\n",
    "    \n",
    "# After removing duplicates, we will query the dataset for the values that were substituted for the Tantalum compositions, the median of the experimental values.\n",
    "    \n",
    "ta_indexes = []\n",
    "for _ in range(len(data)):\n",
    "    if (\"Zr\" in data['composition'][_] and \"Ta\" in data['composition'][_] and len(data['composition'][_])==5):\n",
    "        ta_indexes.append(_)\n",
    "    elif (\"Zr\" in data['composition'][_] and len(data['composition'][_])==4):\n",
    "        ta_indexes.append(_)        \n",
    "        \n",
    "ta_dataframe = data[data.index.isin(ta_indexes)]\n",
    "#display(ta_dataframe)\n",
    "\n",
    "x_values_dupmed = [_[\"Ta\"] for _ in list(ta_dataframe['composition'])]\n",
    "y_values_dupmed = list(ta_dataframe['Ionic Conductivity'])\n",
    "\n",
    "sort_dupmed = list(zip(x_values_dupmed, y_values_dupmed))\n",
    "sort_dupmed = sorted(sort_dupmed, key = lambda t: t[0])\n",
    "\n",
    "x_values_dupmed = [item[0] for item in sort_dupmed ] \n",
    "y_values_dupmed = [item[1] for item in sort_dupmed ]     \n",
    "\n",
    "#The next cell produces a breakdown of the number of elements in the oxides compositions and a distribution of the elements present in the dataset.\n",
    "\n",
    "import collections\n",
    "\n",
    "freq = data[\"composition\"]\n",
    "list_freq = []\n",
    "\n",
    "for _ in freq:\n",
    "    a = [str(x) for x in _]\n",
    "    list_freq.append(a)\n",
    "    \n",
    "list_freq_flat = [item for sublist in list_freq for item in sublist]  \n",
    "listfreqctr = collections.Counter(list_freq_flat)\n",
    "print(listfreqctr)\n",
    "    \n",
    "lengths = list(map(len,list_freq))\n",
    "lenctr = collections.Counter(lengths)\n",
    "\n",
    "print(lenctr)\n",
    "# print(type(freq[0]))\n",
    "# print(freq[0])\n",
    "# print(list(freq[0])[0])\n",
    "\n",
    "# print(type(list(freq[0])[0]))\n",
    "# print(str(list(freq[0])[0]))\n",
    "    \n",
    "# Featurizer\n",
    "f =  MultipleFeaturizer([cf.Stoichiometry(), cf.ElementProperty.from_preset(\"magpie\"), cf.ValenceOrbital(props=['avg']), cf.ElementFraction()]) # Featurizers\n",
    "\n",
    "X = np.array(f.featurize_many(data['composition'], ignore_errors=True)) # Array to store such features\n",
    "\n",
    "measuring_temp_array = np.array(data['Measuring Temperature']).reshape(-1,1) # Here we are stacking the Measuring temperature numpy array into the features previously calculated to add it as a descriptor. \n",
    "X = np.hstack((X,measuring_temp_array))\n",
    "\n",
    "y = data[property_interest].values # Separate the value we want to predict to use as labels.\n",
    "years = data[\"Year Published\"].values\n",
    "\n",
    "# This code is to drop columns with std = 0. \n",
    "x_df = pd.DataFrame(X)\n",
    "x_df = x_df.loc[:, x_df.std() != 0]\n",
    "print(x_df.shape) # This shape is (#Entries, #Descriptors per entry)\n",
    "\n",
    "# This code is to drop columns with std = 0. \n",
    "x_df_prior = pd.DataFrame(X)\n",
    "\n",
    "x_df\n",
    "\n",
    "# Featurizer\n",
    "f =  MultipleFeaturizer([cf.Stoichiometry(), cf.ElementProperty.from_preset(\"magpie\"),\n",
    "                         cf.ValenceOrbital(props=['avg']), cf.IonProperty(fast=True)])\n",
    "# Inputs\n",
    "X = np.array(f.featurize_many(data['composition']))\n",
    "# Labels \n",
    "y = data[property_interest].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rester.query({\"elements\": \"O\", \"nelements\": {\"$gte\": 2}},\n",
    "                    [\"task_id\",\"pretty_formula\",\"formula\",\"volume\",\"density\",\"elements\",\n",
    "                     \"e_above_hull\",\"elasticity\",\"unit_cell_formula\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rester.query('mp-230',['pretty_formula','band_gap','final_structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of oxide structures available on the MP database: %s' % len(data))\n",
    "print('Example output: %s' % data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oxide = pd.DataFrame.from_dict(data)\n",
    "display(df_oxide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_cutoff_value = 1 #energy above convex hull cutoff [meV]\n",
    "df_oxide = df_oxide[df_oxide['e_above_hull'] <= (energy_cutoff_value/1000)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_oxide)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.2\n",
      "  Downloading tensorflow-2.2.0-cp38-cp38-manylinux2010_x86_64.whl (516.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 516.3 MB 1.0 kB/s  eta 0:00:01    |█▊                              | 27.0 MB 16.4 MB/s eta 0:00:30\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (1.12.1)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (1.1.0)\n",
      "Collecting scipy==1.4.1\n",
      "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.0 MB 35 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (0.12.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/nanohub/bbishnoi/.local/lib/python3.8/site-packages (from tensorflow==2.2) (1.34.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (0.36.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/nanohub/bbishnoi/.local/lib/python3.8/site-packages (from tensorflow==2.2) (1.19.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (0.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/nanohub/bbishnoi/.local/lib/python3.8/site-packages (from tensorflow==2.2) (1.15.0)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 60.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorflow==2.2) (3.17.2)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 58.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/nanohub/bbishnoi/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.30.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/nanohub/bbishnoi/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.1.1)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, scipy, h5py, gast, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.7.0\n",
      "    Uninstalling tensorboard-2.7.0:\n",
      "      Successfully uninstalled tensorboard-2.7.0\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/nanohub/bbishnoi/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 16] Device or resource busy: '.nfs0000000093b498d900001134'\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user tensorflow==2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /home/nanohub/bbishnoi/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "/apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringB5cxx11EPNS_15OpKernelContextEb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0m_main_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorflow/core/kernels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m       \u001b[0m_ll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;31m# Load third party dynamic kernels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(library_location)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_libraries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m       \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringB5cxx11EPNS_15OpKernelContextEb"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\r\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringB5cxx11EPNS_15OpKernelContextEb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dd1e630a9a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python -V'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0m_main_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorflow/core/kernels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m       \u001b[0m_ll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;31m# Load third party dynamic kernels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(library_location)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_libraries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m       \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /apps/share64/debian10/anaconda/anaconda-7/lib/python3.8/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringB5cxx11EPNS_15OpKernelContextEb"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "#import pymatgen as pymat\n",
    "#import mendeleev as mendel\n",
    "from subprocess import call\n",
    "import gzip\n",
    "\n",
    "from scipy.stats import norm\n",
    "from IPython.display import HTML\n",
    "\n",
    "# keras imports\n",
    "from keras.layers import (Input, Dense, Conv1D, MaxPool1D, Dropout, GRU, LSTM, TimeDistributed, Add, Flatten, RepeatVector, Lambda, Concatenate)\n",
    "from keras.models import Model, load_model\n",
    "from keras.metrics import binary_crossentropy\n",
    "from keras import initializers, regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "# Visualization\n",
    "from keras_sequential_ascii import keras2ascii\n",
    "\n",
    "# from utils import label_map_util\n",
    "# from utils import visualization_utils as vis_util\n",
    "\n",
    "#from object_detection.utils import label_map_util\n",
    "#from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# utils functions\n",
    "#from python_utils import *\n",
    "from utils import *\n",
    "\n",
    "# Hacky MacOS fix for Tensorflow runtimes... (You won't need this unless you are on MacOS)\n",
    "# This fixes a display bug with progress bars that can pop up on MacOS sometimes.\n",
    "#import sys\n",
    "#import os\n",
    "#sys.path.insert(0, '../src/')\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Remove warnings from output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#!python -m pip install --user numpy --upgrade\n",
    "#!python -m pip install --user tensorflow --upgrade\n",
    "#!python -m pip install --user numpy pycocotools==2.0.0\n",
    "\n",
    "#!python -V\n",
    "#import tensorflow as tf\n",
    "#print(tf.__version__)\n",
    "#import numpy as np\n",
    "#print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['mol_id', 'smiles', 'A', 'B', 'C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'u0', 'u298', 'h298', 'g298', 'cv', 'u0_atom', 'u298_atom', 'h298_atom', 'g298_atom']\n",
      "\n",
      "Length of dataset: 133885\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mol_id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>...</th>\n",
       "      <th>zpve</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0_atom</th>\n",
       "      <th>u298_atom</th>\n",
       "      <th>h298_atom</th>\n",
       "      <th>g298_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43225</th>\n",
       "      <td>gdb_43226</td>\n",
       "      <td>O=C1C2CCCC1C=C2</td>\n",
       "      <td>2.19575</td>\n",
       "      <td>1.83375</td>\n",
       "      <td>1.78978</td>\n",
       "      <td>2.8898</td>\n",
       "      <td>78.73</td>\n",
       "      <td>-0.2330</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.2301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162755</td>\n",
       "      <td>-385.930699</td>\n",
       "      <td>-385.923667</td>\n",
       "      <td>-385.922723</td>\n",
       "      <td>-385.961801</td>\n",
       "      <td>29.000</td>\n",
       "      <td>-1938.509588</td>\n",
       "      <td>-1950.984467</td>\n",
       "      <td>-1961.653375</td>\n",
       "      <td>-1808.771475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18949</th>\n",
       "      <td>gdb_18950</td>\n",
       "      <td>O=CC1C2C3CC2N13</td>\n",
       "      <td>5.76254</td>\n",
       "      <td>1.67862</td>\n",
       "      <td>1.56959</td>\n",
       "      <td>2.2243</td>\n",
       "      <td>65.83</td>\n",
       "      <td>-0.2456</td>\n",
       "      <td>-0.0355</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118824</td>\n",
       "      <td>-362.561835</td>\n",
       "      <td>-362.555470</td>\n",
       "      <td>-362.554526</td>\n",
       "      <td>-362.592646</td>\n",
       "      <td>24.065</td>\n",
       "      <td>-1462.630608</td>\n",
       "      <td>-1471.968569</td>\n",
       "      <td>-1480.266121</td>\n",
       "      <td>-1361.585343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65056</th>\n",
       "      <td>gdb_65057</td>\n",
       "      <td>CC1(CO1)C1(CO1)C#C</td>\n",
       "      <td>2.33460</td>\n",
       "      <td>1.50396</td>\n",
       "      <td>1.24794</td>\n",
       "      <td>2.5230</td>\n",
       "      <td>73.97</td>\n",
       "      <td>-0.2620</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132144</td>\n",
       "      <td>-421.745993</td>\n",
       "      <td>-421.736936</td>\n",
       "      <td>-421.735992</td>\n",
       "      <td>-421.779716</td>\n",
       "      <td>33.773</td>\n",
       "      <td>-1686.271678</td>\n",
       "      <td>-1695.698118</td>\n",
       "      <td>-1705.181034</td>\n",
       "      <td>-1571.293204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27392</th>\n",
       "      <td>gdb_27393</td>\n",
       "      <td>c1c([nH]c(nc1=O)N)O</td>\n",
       "      <td>2.01530</td>\n",
       "      <td>1.87826</td>\n",
       "      <td>0.97339</td>\n",
       "      <td>7.1395</td>\n",
       "      <td>67.95</td>\n",
       "      <td>-0.2213</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102825</td>\n",
       "      <td>-470.075554</td>\n",
       "      <td>-470.067765</td>\n",
       "      <td>-470.066821</td>\n",
       "      <td>-470.107671</td>\n",
       "      <td>29.926</td>\n",
       "      <td>-1447.261657</td>\n",
       "      <td>-1454.816238</td>\n",
       "      <td>-1462.520166</td>\n",
       "      <td>-1350.407526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51740</th>\n",
       "      <td>gdb_51741</td>\n",
       "      <td>O=COC1CCC11CN1</td>\n",
       "      <td>2.95255</td>\n",
       "      <td>1.08628</td>\n",
       "      <td>0.88017</td>\n",
       "      <td>2.6332</td>\n",
       "      <td>74.49</td>\n",
       "      <td>-0.2540</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147164</td>\n",
       "      <td>-439.065902</td>\n",
       "      <td>-439.057354</td>\n",
       "      <td>-439.056409</td>\n",
       "      <td>-439.100076</td>\n",
       "      <td>31.201</td>\n",
       "      <td>-1738.070663</td>\n",
       "      <td>-1748.704431</td>\n",
       "      <td>-1758.779715</td>\n",
       "      <td>-1616.381608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mol_id               smiles        A        B        C      mu  \\\n",
       "43225  gdb_43226      O=C1C2CCCC1C=C2  2.19575  1.83375  1.78978  2.8898   \n",
       "18949  gdb_18950      O=CC1C2C3CC2N13  5.76254  1.67862  1.56959  2.2243   \n",
       "65056  gdb_65057   CC1(CO1)C1(CO1)C#C  2.33460  1.50396  1.24794  2.5230   \n",
       "27392  gdb_27393  c1c([nH]c(nc1=O)N)O  2.01530  1.87826  0.97339  7.1395   \n",
       "51740  gdb_51741       O=COC1CCC11CN1  2.95255  1.08628  0.88017  2.6332   \n",
       "\n",
       "       alpha    homo    lumo     gap  ...      zpve          u0        u298  \\\n",
       "43225  78.73 -0.2330 -0.0029  0.2301  ...  0.162755 -385.930699 -385.923667   \n",
       "18949  65.83 -0.2456 -0.0355  0.2101  ...  0.118824 -362.561835 -362.555470   \n",
       "65056  73.97 -0.2620  0.0181  0.2801  ...  0.132144 -421.745993 -421.736936   \n",
       "27392  67.95 -0.2213  0.0039  0.2252  ...  0.102825 -470.075554 -470.067765   \n",
       "51740  74.49 -0.2540  0.0016  0.2555  ...  0.147164 -439.065902 -439.057354   \n",
       "\n",
       "             h298        g298      cv      u0_atom    u298_atom    h298_atom  \\\n",
       "43225 -385.922723 -385.961801  29.000 -1938.509588 -1950.984467 -1961.653375   \n",
       "18949 -362.554526 -362.592646  24.065 -1462.630608 -1471.968569 -1480.266121   \n",
       "65056 -421.735992 -421.779716  33.773 -1686.271678 -1695.698118 -1705.181034   \n",
       "27392 -470.066821 -470.107671  29.926 -1447.261657 -1454.816238 -1462.520166   \n",
       "51740 -439.056409 -439.100076  31.201 -1738.070663 -1748.704431 -1758.779715   \n",
       "\n",
       "         g298_atom  \n",
       "43225 -1808.771475  \n",
       "18949 -1361.585343  \n",
       "65056 -1571.293204  \n",
       "27392 -1350.407526  \n",
       "51740 -1616.381608  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!ls /home/nanohub/bbishnoi/data/results/vae/qm9.csv\n",
    "#dataset = pd.read_csv(\"/home/nanohub/bbishnoi/data/results/vae/qm9.csv\")\n",
    "# read dataset as a dataframe\n",
    "#dataset = pd.read_csv(\"../data/ESOL_delaney-processed.csv\")\n",
    "\n",
    "from random import shuffle\n",
    "dataset = pd.read_csv(\"./qm9.csv\")\n",
    "#dataset = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/data/qm9.csv\")\n",
    "\n",
    "# This function randomly arranges the elements so we can have representation for all groups both in the training and testing set\n",
    "#shuffle(dataset) \n",
    "\n",
    "# print column names in dataset\n",
    "print(f\"Columns in dataset: {list(dataset.columns)}\")\n",
    "\n",
    "# print number of rows in dataset\n",
    "print(f\"\\nLength of dataset: {len(dataset)}\")\n",
    "\n",
    "# shuffle rows of the dataset (we could do this later as well when doing train/test splits)\n",
    "dataset = dataset.sample(frac=1, random_state=0)\n",
    "\n",
    "# show first 5 rows of dataframe\n",
    "dataset.head()\n",
    "#dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = pd.read_csv('./qm9_1.csv',skiprows=0,nrows=100) \n",
    "#cleaned_dataset.drop([0, 1])\n",
    "cleaned_dataset = cleaned_dataset.drop([\"mol_id\", \"smiles\"], axis=1)\n",
    "#cleaned_dataset.head()\n",
    "cleaned_dataset = cleaned_dataset.loc[:, cleaned_dataset.std() != 0]\n",
    "print(cleaned_dataset.shape) # This shape is (#Entries, #Descriptors per entry)\n",
    "print(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./qm9_3.csv') \n",
    "\n",
    "property_interest = 'gap'\n",
    "data[property_interest] = pd.to_numeric(data[property_interest], errors='coerce')\n",
    "y = data[property_interest].values\n",
    "DF = pd.DataFrame(y)\n",
    "DF.to_csv(\"data_y.csv\")\n",
    "data['cv'] = pd.to_numeric(data['cv'], errors='coerce') # Transformation of Measuring Temp dataframe column from type <str> to a numberic type <int>\n",
    "data[property_interest] = pd.to_numeric(data[property_interest], errors='coerce') # Transformation of our property of interest dataframe column from type <str> to a numberic type <int>\n",
    "\n",
    "print(data['cv'].shape)\n",
    "print(data['cv'])\n",
    "print(data[property_interest].shape)\n",
    "print(data[property_interest])\n",
    "#data.reset_index(drop=True, inplace=True) # Reindexing of dataframe rows\n",
    "#print(data.shape)\n",
    "#data.head(10)\n",
    "#print(data)\n",
    "\n",
    "#cleaned_dataset.drop([0, 1])\n",
    "#cleaned_dataset.head()\n",
    "#data = data.loc[:, cleaned_dataset.std() != 0]\n",
    "#print(data.shape) # This shape is (#Entries, #Descriptors per entry)\n",
    "#data.head()\n",
    "#print(data)\n",
    "#x_df = data\n",
    "\n",
    "data = data.reset_index()\n",
    "data = data.drop(['index'], axis = 1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= data.drop(['mol_id', 'smiles'], axis=1)\n",
    "Z = np.array(data1)#.reshape(-1,1) # Array to store such features\n",
    "print(Z.ndim)\n",
    "DF = pd.DataFrame(Z)\n",
    "DF.to_csv(\"data_Z1.csv\")\n",
    "\n",
    "measuring_temp_array = np.array(data['cv']).reshape(-1,1) # Here we are stacking the Measuring temperature numpy array into the features previously calculated to add it as a descriptor. \n",
    "print(measuring_temp_array.ndim)\n",
    "DF = pd.DataFrame(measuring_temp_array)\n",
    "DF.to_csv(\"measuring_temp_array1.csv\")\n",
    "\n",
    "\n",
    "#print(measuring_temp_array.shape)\n",
    "#print(measuring_temp_array) \n",
    "X = np.hstack((Z,measuring_temp_array))\n",
    "DF = pd.DataFrame(X)\n",
    "DF.to_csv(\"X1.csv\")\n",
    "print(X.ndim)\n",
    "print(X.shape)\n",
    "print(X)\n",
    "DF = pd.DataFrame(y)\n",
    "DF.to_csv(\"data_y1.csv\")\n",
    "y = data[property_interest].values # Separate the value we want to predict to use as labels.\n",
    "print(y.shape)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is to drop columns with std = 0. \n",
    "x_df = pd.DataFrame(X)\n",
    "#x_df = x_df.loc[:, x_df.std() != 0]\n",
    "#print(x_df.shape) # This shape is (#Entries, #Descriptors per entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "all_values = [list(x_df.iloc[x]) for x in range(len(x_df.index))]\n",
    "all_values = np.array(all_values, dtype = float) \n",
    "\n",
    "all_labels = y.copy()\n",
    "print(all_labels.shape)\n",
    "train_percent = 0.80\n",
    "index_split_at = int (train_percent * len(all_labels))\n",
    "\n",
    "#all_values, all_labels = shuffle(all_values, all_labels, random_state=1)\n",
    "\n",
    "train_values, test_values = np.split(all_values, [index_split_at])\n",
    "train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "print(test_labels)\n",
    "feature_mean = np.mean(train_values, axis=0)\n",
    "feature_std = np.std(train_values, axis=0)\n",
    "\n",
    "train_values = (train_values - feature_mean)/ (feature_std)\n",
    "test_values = (test_values - feature_mean)/ (feature_std)\n",
    "\n",
    "print(\"Shape of Train Values:\", train_values.shape)\n",
    "print(\"Shape of Train Labels:\", train_labels.shape)\n",
    "\n",
    "print(\"Shape of Test Values:\", test_values.shape)\n",
    "print(\"Shape of Test Labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly \n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "test_predictions = model.predict(test_values).flatten() # Prediction of the test set\n",
    "\n",
    "values = np.concatenate((train_values, test_values), axis=0) # This line joins the values together to evaluate all of them\n",
    "all_predictions = model.predict(values).flatten()\n",
    "\n",
    "# MATCH PLOT\n",
    "\n",
    "layout0= go.Layout(hovermode='closest', xaxis= dict(title=go.layout.xaxis.Title(text='Experimental Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2),\n",
    "                   yaxis= dict(title=go.layout.yaxis.Title(text='Predicted Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2), width = 1000, height=1000)\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_predictions, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\") # All values\n",
    "testing= go.Scatter(x = test_labels, y = test_predictions, mode = 'markers', \n",
    "                      marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\") # Test set\n",
    "\n",
    "match = go.Scatter(x = [0,1], y = [0,1], mode = 'lines', name = \"Match\",line= dict( color = 'black')) # Match Line\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_values, test_values = np.split(all_values, [index_split_at])\n",
    "train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "\n",
    "# We introduce the model here:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "model =  RandomForestRegressor(n_estimators = 500, random_state = 0)\n",
    "model.fit(train_values, train_labels)\n",
    "\n",
    "test_pred = model.predict(test_values)\n",
    "all_pred = model.predict(all_values)\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_pred, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\")\n",
    "\n",
    "testing= go.Scatter(x = test_labels, y = test_pred, mode = 'markers', marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\")\n",
    "\n",
    "match = go.Scatter(x = [0,1], y = [0,1], mode = 'lines', name = \"Match\",line= dict( color = 'black'))\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --user lolopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, test_values = np.split(all_values, [index_split_at])\n",
    "train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "#import io.citrine.lolo.learners.RandomForest\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "\n",
    "model =  RandomForestRegressor(num_trees=500)\n",
    "model.fit(train_values, train_labels)\n",
    "\n",
    "test_pred, test_std = model.predict(test_values, return_std=True)\n",
    "all_pred, all_std = model.predict(all_values, return_std=True)\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_pred, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\")\n",
    "\n",
    "testing= go.Scatter(x = test_labels, y = test_pred, mode = 'markers', marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\", error_y=dict(type='data', array=test_std,visible=True))\n",
    "\n",
    "match = go.Scatter(x = [0,1], y = [0,1], mode = 'lines', name = \"Match\",line= dict( color = 'black'))\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "all_values = [list(x_df.iloc[x]) for x in range(len(x_df.index))]\n",
    "all_values = np.array(all_values, dtype = float) \n",
    "\n",
    "all_labels = y.copy()\n",
    "\n",
    "train_percent = 0.90\n",
    "#index_split_at = int (train_percent * len(all_values))\n",
    "index_split_at = int (train_percent * len(all_labels))\n",
    "\n",
    "#all_values, all_labels = shuffle(all_values, all_labels, random_state=1)\n",
    "\n",
    "#train_values, test_values = np.split(all_values, [index_split_at])\n",
    "#train_labels, test_labels = np.split(all_values, [index_split_at])\n",
    "\n",
    "train_values, test_values = np.split(all_values, [index_split_at])\n",
    "train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "\n",
    "feature_mean = np.mean(train_values, axis=0)\n",
    "feature_std = np.std(train_values, axis=0)\n",
    "\n",
    "train_values = (train_values - feature_mean)/ (feature_std)\n",
    "test_values = (test_values - feature_mean)/ (feature_std)\n",
    "\n",
    "print(\"Shape of Train Values:\", train_values.shape)\n",
    "print(\"Shape of Train Labels:\", train_labels.shape)\n",
    "\n",
    "print(\"Shape of Test Values:\", test_values.shape)\n",
    "print(\"Shape of Test Labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_values, test_values = np.split(all_values, [index_split_at])\n",
    "#train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "\n",
    "# We introduce the model here:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "model =  RandomForestRegressor(n_estimators = 500, random_state = 0)\n",
    "model.fit(train_values, train_labels)\n",
    "\n",
    "test_pred = model.predict(test_values)\n",
    "all_pred = model.predict(all_values)\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_pred, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\")\n",
    "\n",
    "testing= go.Scatter(x = test_labels, y = test_pred, mode = 'markers', marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\")\n",
    "\n",
    "match = go.Scatter(x = [0,1], y = [0,1], mode = 'lines', name = \"Match\",line= dict( color = 'black'))\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaned_dataset\n",
    "\n",
    "# Uncomment the line below to shuffle the dataset (we do not do this here to ensure consistent results for every run)\n",
    "\n",
    "all_values = [] # Values for Attributes\n",
    "all_labels = [] # Values for Young's Modulus (Property to be estimated)\n",
    "\n",
    "all_values = [list(df.iloc[x]) for x in range(len(all_values))]\n",
    "\n",
    "print(all_values)\n",
    "\n",
    "# List of lists are turned into Numpy arrays to facilitate calculations in steps to follow (Normalization).\n",
    "all_values = np.array(all_values, dtype = float) \n",
    "print(\"Shape of Values:\", all_values.shape)\n",
    "all_labels = np.array(all_labels, dtype = float)\n",
    "print(\"Shape of Labels:\", all_labels.shape)\n",
    "\n",
    "#order = np.argsort(np.random.random(all_labels.shape)) # This numpy argsort returns the indexes that would be used to shuffle a list\n",
    "order = np.arange(100)\n",
    "all_values = all_values[order]\n",
    "all_labels = all_labels[order]\n",
    "\n",
    "# Training Set\n",
    "train_labels = all_labels[:44]\n",
    "train_values = all_values[:44]\n",
    "\n",
    "# Testing Set\n",
    "test_labels = all_labels[-5:]\n",
    "test_values = all_values[-5:]\n",
    "\n",
    "# This line is used for labels in the plots at the end of the tutorial - Testing Set\n",
    "labeled_elements = [elements[x] for x in order[-5:]] \n",
    "elements = [elements[x] for x in order]\n",
    "\n",
    "# NORMALIZATION\n",
    "\n",
    "mean = np.mean(train_values, axis = 0) # mean\n",
    "std = np.std(train_values, axis = 0) # standard deviation\n",
    "\n",
    "train_values = (train_values - mean) / std # input scaling\n",
    "test_values = (test_values - mean) / std # input scaling\n",
    "\n",
    "print(train_values[0]) # print a sample entry from the training set\n",
    "print(test_values[0]) # print a sample entry from the training set\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"smiles\"]\n",
    "dataset[\"smiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[147] \n",
    "dataset.iloc[147] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dataset[\"zpve\"] >= -100\n",
    "nonmetal_dataset = dataset[mask]\n",
    "nonmetal_dataset\n",
    "#dataset[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = dataset.drop([\"A\", \"B\", \"C\", \"h298\"], axis=1)\n",
    "cleaned_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array(dataset['alpha']).reshape(-1,1) # Here we are stacking the Measuring temperature numpy array into the features previously calculated to add it as a descriptor. \n",
    "#X = np.hstack((X,measuring_temp_array))\n",
    "\n",
    "Y = dataset['homo'].values.reshape(-1,1) # Separate the value we want to predict to use as labels.\n",
    "\n",
    "\n",
    "# This code is to drop columns with std = 0. \n",
    "#x_df = pd.DataFrame(X)\n",
    "#x_df = x_df.loc[:, x_df.std() != 0]\n",
    "#print(x_df.shape) \n",
    "print(X.shape) # This shape is (#Entries, #Descriptors per entry)\n",
    "#print(X)\n",
    "print(X[0:10])\n",
    "print(Y.shape) # This shape is (#Entries, #Descriptors per entry)\n",
    "print(Y)\n",
    "plt.scatter(X[:, 0], Y[:, 10])   # plots the scatter of norm height and norm weight values\n",
    "#plt.scatter(Y[:, -1], Y[:, 0])   # plots the scatter of norm height and norm weight values\n",
    "plt.grid(color='gray', linewidth=0.5)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # popular scientific computing package in Python\n",
    "import matplotlib.pyplot as plt # popular static visualization package in Python\n",
    "\n",
    "#X=dataset[[\"alpha\",\"homo\",\"lumo\",\"gap\"]]\n",
    "X=dataset[[\"alpha\",\"gap\",\"homo\",\"lumo\"]]\n",
    "\n",
    "Y = dataset.zpve.astype('int')\n",
    "#print(X)\n",
    "print(X[0:10])\n",
    "print(Y[0:10])\n",
    "X.shape\n",
    "Y.shape\n",
    "# Goal is to emphasize variations and extract strong patterns / correlations in a dataset\n",
    "# PCA can help us decorrelate our data, i.e. compute eigenvectors that are orthogonal to one another\n",
    "\n",
    "# This toy example will only address two input variables, but of course this algorithm extends to N-dimensions\n",
    "# For example, in a population there exists some correlation between height and weight of individuals\n",
    "# Imagine sampling (or querying) from 500 people and obtain their information, then normalize\n",
    "# the results assuming a standard normal distribution\n",
    "# The following lines of code sets up the scenario as if you have already normalized the data\n",
    "\n",
    "# rng = np.random.RandomState(1)  # Container for the \"Mersenne Twister pseudo-random number generator\"\n",
    "                                # allows for generating random numbers drawn from a\n",
    "                                # variety of probability distributions\n",
    "\n",
    "#a = rng.rand(2, 2)              # creates an array of the given shape and populate it with random samples\n",
    "                                # from a uniform distribution over [0, 1)\n",
    "# b = rng.randn(2, 500)           # creates an array of the given shape and populates it with random samples\n",
    "                                # from the “standard normal” distribution\n",
    "\n",
    "#X = np.dot(a,b).T               # computes a dot product to return an array with 500 1x2 arrays\n",
    "# print(X[0:10])\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1])   # plots the scatter of norm height and norm weight values\n",
    "plt.grid(color='gray', linewidth=0.5)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA and keep 50 dimensions\n",
    "X = X - X.mean(axis=0)\n",
    "U, s, V = np.linalg.svd(X, full_matrices=False)\n",
    "X50 = np.dot(U, np.diag(s))[:,:50]\n",
    "\n",
    "# 10 nice colors\n",
    "col = np.array(['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99',\n",
    "                '#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/KlugerLab/FIt-SNE\n",
    "# This is a really basic function that does not do almost any sanity checks\n",
    "#\n",
    "# Usage example:\n",
    "#   import sys; sys.path.append('../FIt-SNE/')\n",
    "#   from fast_tsne import fast_tsne\n",
    "#   import numpy as np\n",
    "#   X = np.random.randn(1000, 50)\n",
    "#   Z = fast_tsne(X)\n",
    "#\n",
    "# Written by Dmitry Kobak\n",
    "\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import struct\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def fast_tsne(\n",
    "    X,\n",
    "    theta=0.5,\n",
    "    perplexity=30,\n",
    "    map_dims=2,\n",
    "    max_iter=750,\n",
    "    stop_early_exag_iter=250,\n",
    "    K=-1,\n",
    "    sigma=-1,\n",
    "    nbody_algo=\"FFT\",\n",
    "    knn_algo=\"annoy\",\n",
    "    mom_switch_iter=250,\n",
    "    momentum=0.5,\n",
    "    final_momentum=0.8,\n",
    "    learning_rate=\"auto\",\n",
    "    early_exag_coeff=12,\n",
    "    no_momentum_during_exag=False,\n",
    "    n_trees=50,\n",
    "    search_k=None,\n",
    "    start_late_exag_iter=\"auto\",\n",
    "    late_exag_coeff=-1,\n",
    "    nterms=3,\n",
    "    intervals_per_integer=1,\n",
    "    min_num_intervals=50,\n",
    "    seed=-1,\n",
    "    initialization=\"pca\",\n",
    "    load_affinities=None,\n",
    "    perplexity_list=None,\n",
    "    df=1,\n",
    "    return_loss=False,\n",
    "    nthreads=-1,\n",
    "    max_step_norm=5,\n",
    "):\n",
    "    \"\"\"Run t-SNE. This implementation supports exact t-SNE, Barnes-Hut t-SNE \n",
    "    and FFT-accelerated interpolation-based t-SNE (FIt-SNE). This is a Python \n",
    "    wrapper to a C++ executable.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: 2D numpy array\n",
    "        Array of observations (n times p)\n",
    "    perplexity: double\n",
    "        Perplexity is used to determine the bandwidth of the Gaussian kernel \n",
    "        in the input space.  Default 30.\n",
    "    theta: double\n",
    "        Set to 0 for exact t-SNE. If non-zero, then the code will use either\n",
    "        Barnes Hut or FIt-SNE based on `nbody_algo`.  If Barnes Hut, then theta\n",
    "        determins the accuracy of BH approximation. Default 0.5.\n",
    "    map_dims: int\n",
    "        Number of embedding dimensions. Default 2. FIt-SNE supports only 1 or 2\n",
    "        dimensions.\n",
    "    max_iter: int\n",
    "        Number of gradient descent iterations. Default 750.\n",
    "    nbody_algo: {'Barnes-Hut', 'FFT'}\n",
    "        If theta is nonzero, this determines whether to use FIt-SNE (default) or \n",
    "        Barnes-Hut approximation.\n",
    "    knn_algo: {'vp-tree', 'annoy'}\n",
    "        Use exact nearest neighbours with VP trees (as in BH t-SNE) or \n",
    "        approximate nearest neighbors with Annoy. Default is 'annoy'.\n",
    "    early_exag_coeff: double\n",
    "        Coefficient for early exaggeration. Default 12.\n",
    "    stop_early_exag_iter: int\n",
    "        When to switch off early exaggeration. Default 250.\n",
    "    late_exag_coeff: double\n",
    "        Coefficient for late exaggeration. Set to -1 in order not to use late \n",
    "        exaggeration. Default -1.\n",
    "    start_late_exag_iter: int or 'auto'\n",
    "        When to start late exaggeration. Default 'auto'; it sets \n",
    "        start_late_exag_iter to -1 meaning that late exaggeration is not used, \n",
    "        unless late_exag_coeff>0. In that case start_late_exag_iter is set to\n",
    "        stop_early_exag_iter.\n",
    "    momentum: double\n",
    "        Initial value of momentum. Default 0.5.\n",
    "    final_momentum: double\n",
    "        The value of momentum to use later in the optimisation. Default 0.8.\n",
    "    mom_switch_iter: int\n",
    "        Iteration number to switch from momentum to final_momentum. Default 250.\n",
    "    learning_rate: double or 'auto'\n",
    "        Learning rate. Default 'auto'; it sets learning rate to \n",
    "        N/early_exag_coeff where N is the sample size, or to 200 if \n",
    "        N/early_exag_coeff < 200.\n",
    "    max_step_norm: double or 'none' (default: 5)\n",
    "        Maximum distance that a point is allowed to move on one iteration. \n",
    "        Larger steps are clipped to this value. This prevents possible\n",
    "        instabilities during gradient descent. Set to 'none' to switch it off.\n",
    "    no_mometum_during_exag: boolean\n",
    "        Whether to switch off momentum during the early exaggeration phase (can \n",
    "        be useful for experiments with large exaggeration coefficients). Default\n",
    "        is False.\n",
    "    sigma: boolean\n",
    "        The standard deviation of the Gaussian kernel to be used for all points \n",
    "        instead of choosing it adaptively via perplexity. Set to -1 to use \n",
    "        perplexity. Default is -1.\n",
    "    K: int\n",
    "        The number of nearest neighbours to use when using fixed sigma instead \n",
    "        of perplexity calibration. Set to -1 when perplexity is used. Default\n",
    "        is -1.\n",
    "    nterms: int\n",
    "        If using FIt-SNE, this is the number of interpolation points per \n",
    "        sub-interval\n",
    "    intervals_per_integer: double\n",
    "        See min_num_intervals              \n",
    "    min_num_intervals: int\n",
    "        The interpolation grid is chosen on each step of the gradient descent. \n",
    "        If Y is the current embedding, let maxloc = ceiling(max(Y.flatten)) and\n",
    "        minloc = floor(min(Y.flatten)), i.e. the points are contained in a \n",
    "        [minloc, maxloc]^no_dims box. The number of intervals in each \n",
    "        dimension is either min_num_intervals or \n",
    "        ceiling((maxloc-minloc)/intervals_per_integer), whichever is larger. \n",
    "        min_num_intervals must be a positive integer and intervals_per_integer \n",
    "        must be positive real value. Defaults: min_num_intervals=50, \n",
    "        intervals_per_integer = 1.\n",
    "    n_trees: int\n",
    "        When using Annoy, the number of search trees to use. Default is 50.\n",
    "    search_k: int\n",
    "        When using Annoy, the number of nodes to inspect during search. Default \n",
    "        is 3*perplexity*n_trees (or K*n_trees when using fixed sigma).\n",
    "    seed: int\n",
    "        Seed for random initialisation. Use -1 to initialise random number \n",
    "        generator with current time. Default -1.\n",
    "    initialization: 'random', 'pca', or numpy array\n",
    "         N x no_dims array to intialize the solution. Default: 'pca'.\n",
    "    load_affinities: {'load', 'save', None}\n",
    "        If 'save', input similarities (p_ij) are saved into a file. If 'load', \n",
    "        they are loaded from a file and not recomputed. If None, they are not\n",
    "        saved and not loaded. Default is None.\n",
    "    perplexity_list: list\n",
    "        A list of perplexities to used as a perplexity combination. Input \n",
    "        affinities are computed with each perplexity on the list and then\n",
    "        averaged. Default is None.\n",
    "    nthreads: int\n",
    "        Number of threads to use. Default is -1, i.e. use all available threads.\n",
    "    df: double\n",
    "        Controls the degree of freedom of t-distribution. Must be positive. The \n",
    "        actual degree of freedom is 2*df-1. The standard t-SNE choice of 1 \n",
    "        degree of freedom corresponds to df=1. Large df approximates Gaussian \n",
    "        kernel. df<1 corresponds to heavier tails, which can often resolve \n",
    "        substructure in the embedding. See Kobak et al. (2019) for details. \n",
    "        Default is 1.0.    \n",
    "    return_loss: boolean\n",
    "        If True, the function returns the loss values computed during \n",
    "        optimisation together with the final embedding. If False, only the\n",
    "        embedding is returned. Default is False.\n",
    "    Returns\n",
    "    -------\n",
    "    Y: numpy array\n",
    "        The embedding.\n",
    "    loss: numpy array\n",
    "        Loss values computed during optimisation. Only returned if return_loss \n",
    "        is True.\n",
    "    \"\"\"\n",
    "\n",
    "    version_number = \"1.2.1\"\n",
    "\n",
    "    # X should be a numpy array of 64-bit doubles\n",
    "    X = np.array(X).astype(float)\n",
    "\n",
    "    if learning_rate == \"auto\":\n",
    "        learning_rate = np.max((200, X.shape[0] / early_exag_coeff))\n",
    "\n",
    "    if start_late_exag_iter == \"auto\":\n",
    "        if late_exag_coeff > 0:\n",
    "            start_late_exag_iter = stop_early_exag_iter\n",
    "        else:\n",
    "            start_late_exag_iter = -1\n",
    "\n",
    "    if isinstance(initialization, str) and initialization == \"pca\":\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        solver = \"arpack\" if X.shape[1] > map_dims else \"auto\"\n",
    "        pca = PCA(\n",
    "            n_components=map_dims,\n",
    "            svd_solver=solver,\n",
    "            random_state=seed if seed != -1 else None,\n",
    "        )\n",
    "        initialization = pca.fit_transform(X)\n",
    "        initialization /= np.std(initialization[:, 0])\n",
    "        initialization *= 0.0001\n",
    "\n",
    "    if perplexity_list is not None:\n",
    "        perplexity = 0  # C++ requires perplexity=0 in order to use perplexity_list\n",
    "\n",
    "    if sigma > 0 and K > 0:\n",
    "        perplexity = -1  # C++ requires perplexity=-1 in order to use sigma\n",
    "\n",
    "    if search_k is None:\n",
    "        if perplexity > 0:\n",
    "            search_k = 3 * perplexity * n_trees\n",
    "        elif perplexity == 0:\n",
    "            search_k = 3 * np.max(perplexity_list) * n_trees\n",
    "        else:\n",
    "            search_k = K * n_trees\n",
    "\n",
    "    # Not much of a speed up, at least on some machines, so I'm removing it.\n",
    "    #\n",
    "    #    if nbody_algo == 'auto':\n",
    "    #        if X.shape[0] < 8000:\n",
    "    #            nbody_algo = 'Barnes-Hut'\n",
    "    #        else:\n",
    "    #            nbody_algo = 'FFT'\n",
    "\n",
    "    if nbody_algo == \"Barnes-Hut\":\n",
    "        nbody_algo = 1\n",
    "    elif nbody_algo == \"FFT\":\n",
    "        nbody_algo = 2\n",
    "    else:\n",
    "        raise ValueError(\"nbody_algo should be 'Barnes-Hut' or 'FFT'\")\n",
    "\n",
    "    if knn_algo == \"vp-tree\":\n",
    "        knn_algo = 2\n",
    "    elif knn_algo == \"annoy\":\n",
    "        knn_algo = 1\n",
    "    else:\n",
    "        raise ValueError(\"knn_algo should be 'vp-tree' or 'annoy'\")\n",
    "\n",
    "    if load_affinities == \"load\":\n",
    "        load_affinities = 1\n",
    "    elif load_affinities == \"save\":\n",
    "        load_affinities = 2\n",
    "    else:\n",
    "        load_affinities = 0\n",
    "\n",
    "    if nthreads == -1:\n",
    "        nthreads = 0\n",
    "\n",
    "    if max_step_norm == \"none\":\n",
    "        max_step_norm = -1\n",
    "\n",
    "    if no_momentum_during_exag:\n",
    "        no_momentum_during_exag = 1\n",
    "    else:\n",
    "        no_momentum_during_exag = 0\n",
    "\n",
    "    # create unique i/o-filenames\n",
    "    timestamp = str(datetime.now()) + '-' + str(np.random.randint(0,1000000000))\n",
    "    infile = 'data_%s.dat' % timestamp\n",
    "    outfile = 'result_%s.dat' % timestamp\n",
    "    \n",
    "    # write data file\n",
    "    with open(os.getcwd() + '/' + infile, 'wb') as f:\n",
    "        n, d = X.shape\n",
    "        f.write(struct.pack(\"=i\", n))\n",
    "        f.write(struct.pack(\"=i\", d))\n",
    "        f.write(struct.pack(\"=d\", theta))\n",
    "        f.write(struct.pack(\"=d\", perplexity))\n",
    "        if perplexity == 0:\n",
    "            f.write(struct.pack(\"=i\", len(perplexity_list)))\n",
    "            for perpl in perplexity_list:\n",
    "                f.write(struct.pack(\"=d\", perpl))\n",
    "        f.write(struct.pack(\"=i\", map_dims))\n",
    "        f.write(struct.pack(\"=i\", max_iter))\n",
    "        f.write(struct.pack(\"=i\", stop_early_exag_iter))\n",
    "        f.write(struct.pack(\"=i\", mom_switch_iter))\n",
    "        f.write(struct.pack(\"=d\", momentum))\n",
    "        f.write(struct.pack(\"=d\", final_momentum))\n",
    "        f.write(struct.pack(\"=d\", learning_rate))\n",
    "        f.write(struct.pack(\"=d\", max_step_norm))\n",
    "        f.write(struct.pack(\"=i\", K))\n",
    "        f.write(struct.pack(\"=d\", sigma))\n",
    "        f.write(struct.pack(\"=i\", nbody_algo))\n",
    "        f.write(struct.pack(\"=i\", knn_algo))\n",
    "        f.write(struct.pack(\"=d\", early_exag_coeff))\n",
    "        f.write(struct.pack(\"=i\", no_momentum_during_exag))\n",
    "        f.write(struct.pack(\"=i\", n_trees))\n",
    "        f.write(struct.pack(\"=i\", search_k))\n",
    "        f.write(struct.pack(\"=i\", start_late_exag_iter))\n",
    "        f.write(struct.pack(\"=d\", late_exag_coeff))\n",
    "        f.write(struct.pack(\"=i\", nterms))\n",
    "        f.write(struct.pack(\"=d\", intervals_per_integer))\n",
    "        f.write(struct.pack(\"=i\", min_num_intervals))\n",
    "        f.write(X.tobytes())\n",
    "        f.write(struct.pack(\"=i\", seed))\n",
    "        f.write(struct.pack(\"=d\", df))\n",
    "        f.write(struct.pack(\"=i\", load_affinities))\n",
    "\n",
    "        if not isinstance(initialization, str) or initialization != \"random\":\n",
    "            initialization = np.array(initialization).astype(float)\n",
    "            f.write(initialization.tobytes())\n",
    "\n",
    "    # run t-sne\n",
    "    subprocess.call(\n",
    "        [\n",
    "            os.path.dirname(os.path.realpath(__file__)) + \"/bin/fast_tsne\",\n",
    "            version_number,\n",
    "            infile,\n",
    "            outfile,\n",
    "            \"{}\".format(nthreads),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # read data file\n",
    "    with open(os.getcwd() + '/' + outfile, 'rb') as f:\n",
    "        (n,) = struct.unpack(\"=i\", f.read(4))\n",
    "        (md,) = struct.unpack(\"=i\", f.read(4))\n",
    "        sz = struct.calcsize(\"=d\")\n",
    "        buf = f.read(sz * n * md)\n",
    "        x_tsne = [\n",
    "            struct.unpack_from(\"=d\", buf, sz * offset) for offset in range(n * md)\n",
    "        ]\n",
    "        x_tsne = np.array(x_tsne).reshape((n, md))\n",
    "        (_,) = struct.unpack(\"=i\", f.read(4))\n",
    "        buf = f.read(sz * max_iter)\n",
    "        loss = [\n",
    "            struct.unpack_from(\"=d\", buf, sz * offset) for offset in range(max_iter)\n",
    "        ]\n",
    "        loss = np.array(loss).squeeze()\n",
    "        if loss.size == 1:\n",
    "            loss = loss[np.newaxis]\n",
    "        loss[np.arange(1, max_iter + 1) % 50 > 0] = np.nan\n",
    "        \n",
    "    # remove i/o-files\n",
    "    os.remove(os.getcwd() + '/' + infile)\n",
    "    os.remove(os.getcwd() + '/' + outfile)\n",
    "\n",
    "    if return_loss:\n",
    "        return (x_tsne, loss)\n",
    "    else:\n",
    "        return x_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "#   import sys; sys.path.append('../FIt-SNE/')\n",
    "#   from fast_tsne import fast_tsne\n",
    "#   import numpy as np\n",
    "#   X = np.random.randn(1000, 50)\n",
    "#   Z = fast_tsne(X)\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# the path should point to the FIt-SNE directory\n",
    "import sys; sys.path.append('./FIt-SNE/')\n",
    "#from fast_tsne import fast_tsne\n",
    "\n",
    "\n",
    "# Running t-SNE on the full PCA-reduced MNIST in the default way \n",
    "# This uses perplexity 30 and PCA initialization.\n",
    "# It runs for 750 iterations with learning rate N/12.\n",
    "#Z = fast_tsne(X50)\n",
    "%time Z = fast_tsne(X50)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.axis('equal')\n",
    "plt.scatter(Z[:,0], Z[:,1], c=col[y], s=2, edgecolors='none')\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "Plotting a randomly correlated dataset Computing PCA and interpreting the output Reducing the dimension\n",
    "Interpretation of PCA algorithm\n",
    "This relationship is quantified by finding a list of the principal axes in the data and using those axes to describe the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.decomposition import PCA # within the scikit-learn module which focuses on\n",
    "                                      # Machine Learning in Python, we import PCA decomposition algorithm\n",
    "pca = PCA(n_components=2)            # applies PCA with the argument that we want a two-component fit\n",
    "pca.fit(X)                           # fits the PCA model with dataset X defined above\n",
    "\n",
    "print(pca)                          # this is only the PCA object!\n",
    "\n",
    "# The fit learns some quantities from the data, namely the \"components\" and \"explained variance\"\n",
    "# In this example, there are two sets of components to be described below\n",
    "\n",
    "print('components: ' + str(pca.components_))                 # each component defined by x-y pair\n",
    "print('explained variance: ' + str(pca.explained_variance_)) # how much variance each component explains \n",
    "                                                              # taking into consideration the entire dataset\n",
    "print('cummulative explained variance: ' + str(round(sum(pca.explained_variance_),3)))\n",
    "\n",
    "print(pca.components_)\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "pca = PCA().fit(X)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "print(\"original shape:   \", X.shape)\n",
    "print(\"transformed shape:\", X_pca.shape)\n",
    "\n",
    "pca = PCA(2)  # project from 64 to 2 dimensions\n",
    "projected = pca.fit_transform(X)\n",
    "print(X.shape)\n",
    "print(projected.shape)\n",
    "\n",
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=X.target, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('spectral', 10))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the quantities as vectors over the input data will help with understanding their values. Use the \"components\" to define the direction of the vector and the \"explained variance\" to define the magnitude of the vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following lines of code creates an arrow based on read-in pairs of values\n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=3,\n",
    "                    shrinkA=0, shrinkB=0, color='R') # defining the style of arrow to be visualized\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)   # put the arrow in the figure using the defined style\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2)             # plots the original data but turns transparancy to 80%\n",
    "for length, vector in zip(pca1.explained_variance_, pca1.components_): # iterate over both arrays\n",
    "    v = vector * 3 * np.sqrt(length)                 # computes the vector after scaling by the expl. variance\n",
    "    draw_vector(pca1.mean_, pca1.mean_ + v)          # plots vectors using the mean norm value as the center\n",
    "plt.axis('equal')\n",
    "plt.grid(color='gray', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing the dimensions\n",
    "Using PCA for dimensionality reduction involves zeroing out the smallest principal components, resulting in a lower-dimensional projection of the data that preserves the maximal data variance. In this case, we will be reducing the dimension from 2D to 1D (getting rid of the least important component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop the model OBJECT\n",
    "pca2 = PCA(n_components=1)    # determining a one-component fit\n",
    "X_pca = pca2.fit_transform(X) # fit the model to our X data and apply the dimensionality reduction on X\n",
    "                              # remember fitting the data only creates the object\n",
    "                              # and does not show a manipulation of our data\n",
    "step1 = pca2.fit(X)\n",
    "print(step1)\n",
    "step2 = pca2.transform(X)\n",
    "print(step2[0:10])\n",
    "\n",
    "# PCA().fit_transform() is a 2-in-1 step!\n",
    "\n",
    "#print(X_pca[0:10])\n",
    "# IMPORTANT: this provides the reduced dimension data based on the defined fit\n",
    "\n",
    "print(\"original shape:   \", X.shape)\n",
    "print(\"transformed shape:\", X_pca.shape)\n",
    "print('components: ' + str(pca2.components_))\n",
    "print('explained variance: ' + str(pca2.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transformed data has been reduced to a single dimension. We can perform the inverse transform of this reduced data and plot it along with the original data:\n",
    "# Applies our reduced dimension model object to the data\n",
    "\n",
    "X_new = pca2.inverse_transform(X_pca) # performs an inverse transform on our reduced dimension result\n",
    "                                      # and maps it back to our original space (norm height and norm weight)\n",
    "# in other words, we obtained the fit in a lower dimensional space (1-D) as our array was of size [500 x 1]\n",
    "# we need to map to back into R^2 space in order to plot it against the original data\n",
    "#print(X_new[0:10])\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2)         # plot of our original data with 80% transparency\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], alpha=0.8) # plot of the data mapped to the single principle component\n",
    "                                                 # axis defined as having the largest explained variance\n",
    "plt.axis('equal')\n",
    "plt.grid(color='gray', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Introduction to dimensionality reduction via matrix decomposition using unsupervised machine learning to develop a three-component chemistry model*\n",
    "\n",
    "#### https://scikit-learn.org/stable/modules/decomposition.html#decompositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview:** The chemical decomposition process of reactive materials is a complex process that is still being explored in the literature. Modeling efforts can provide information regarding the detailed chemistry from reactants to products. Specifically, molecular dynamics using the reactive force field, ReaxFF, can give bonding environment in the form of a time-dependent chemical graph table. For *CHNO* atom types, there are exactly 280 different combinations of bonding environments assuming a maximum number of four bonds (H, N2, H2O, HCO2, etc.). Performing matrix decomposition on the bond table outputted by ReaxFF can reduce the dimensionality of the decomposition process and hint at the most important chemistry events. The following two methods will be used in the analysis:\n",
    "\n",
    "#### Principal component analysis (PCA)\n",
    "1. Converts a set of observations of possibly **correlated** variables into a set of values of linearly **uncorrelated** variables called *principal components*\n",
    "2. Produces a set of **orthogonal** components that explain a *maximum amount of the variance*, which accounts for as much of the variability in the data as possible\n",
    "3. Can learn components in the fitting method and can be used on new data to project it on these components\n",
    "4. Provides a probabilistic interpretation that can give a likelihood of data based on the amount of variance it explains\n",
    "\n",
    "#### Non-negative matrix factorization (NMF)\n",
    "1. Assumes the data and the components are **non-negative**\n",
    "2. Representation of a vector is obtained in an additive fashion, by superimposing the components, without subtracting\n",
    "3. Results in **interpretable** models\n",
    "\n",
    "**What?** In this tutorial, both PCA and NMF will be applied to extract out a 3-component (reactants -> intermediates -> products) chemistry model from an RDX bond table. It will be shown that NMF is more applicable to the problem because the results are more interpretable. However, this is because our results need to be non-negative.\n",
    "\n",
    "*The hope is that understanding how these methods work can provide insight into how you might post process your research data, regardless of the choice between PCA and NMF.*\n",
    "\n",
    "**How to use this?** This tutorial uses Python, some familiarity with programming would be beneficial but is not required. Run each code cell in order by clicking \"Shift + Enter\". Feel free to modify the code, or change the number of components to fit. **Note**: do not use the Cell -> Run All function !!!\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "1. Parsing the bond table and visualize the bond environment\n",
    "2. Running PCA\n",
    "    1. Visualization of raw data\n",
    "3. Running NMF\n",
    "    1. Visualization of raw data\n",
    "    2. Rescale components and visualizing the curves\n",
    "\n",
    "**Get started:** Click \"Shift-Enter\" on the code cells to run! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in our data and showing the first few lines\n",
    "\n",
    "import pandas as pd # data analysis and manipulation tool in Python\n",
    "#dataset = pd.read_csv(\"./qm9.csv\")\n",
    "bondtable = pd.read_csv('./qm9.csv',skiprows=0,nrows=5) # skipping the 1st 6 rows and # only showing 5 rows (+ header)\n",
    "#bondtable1= bondtable.loc[:, ~bondtable.columns.isin(['mol_id'])]\n",
    "#df.loc[:, ~df.columns.isin(['rebounds', 'assists'])]\n",
    "print(bondtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program is based on the work by Edward M. Kober (LANL) which constructs a time-dependent bond graph network from \n",
    "# a reactive force field bond connectivity table. The program itself is currently under work by Michael Sakano \n",
    "# of Purdue University as part of an ONR funded PhD thesis in the Materials Science and Engineering Department.\n",
    "\n",
    "# Manipulating the data into a more readable form where we capture\n",
    "# the number of individual bonding environments that each atom experiences over time\n",
    "# For CHNO atom types, there is a finite number of 280 different combinations assuming a max of 4 bonds\n",
    "# H/C/N/O | H2/C2/N2/O2 | NO2/CO2/H2O | NO3/CO3/NH3 | NH4\n",
    "\n",
    "from numpy import * # imports all extension of numpy; any called functions do not need the prefex np. or numpy.\n",
    "import scipy        # \"ecosystem of open-source software for mathematics, science, and engineering\"\n",
    "import math         # simple operators like exp, ceil, float, etc.\n",
    "import sys          # allows access to system-specific parameters and functions (Ex: arguments to read in)\n",
    "import re           # regular expression matching operations - useful for string comparison/splitting\n",
    "\n",
    "nneigh=10\n",
    "natt=4                                        # number of atom types\n",
    "bc=zeros((natt,natt),float)                   # defines 2-D numpy array of zeros with shape (4,4)\n",
    "t_start=0\n",
    "nats=0\n",
    "input_file='./qm9.csv'\n",
    "ifile=open(input_file, 'r')                   # opens our file defined as input_file and 'reads' information\n",
    "for line in ifile:                            # loops through all lines in the input_file\n",
    "    items=line.split(\" \")                     # splitting the line on whitespace character\n",
    "    if(items[1]==\"mol_id\"):                 # conditional that second element is exactly 'timestep' string\n",
    "        t_start=int(items[2])                 # if condition met, take the third element and convert to int\n",
    "    if(items[1]==\"smiles\"):\n",
    "        nats=int(items[4])\n",
    "        break                                 # after reaching this point, exit out of the outside loop\n",
    "ifile.close()                                 # close file as it can slow down your program, also if you do\n",
    "                                              # any operations on the file, it won't update\n",
    "num_lines=sum(1 for line in open(input_file)) # single line execution to count number of lines in the file\n",
    "nts=int(num_lines/(nats+8))\n",
    "print(\"Number of time frames = \"+str(nts))\n",
    "\n",
    "timestep = 0.025 # fs\n",
    "in_prm=zeros((2,),dtype=float)                # starting times x timesteps\n",
    "in_prm[0]=t_start\n",
    "in_prm[1]=timestep\n",
    "\n",
    "#print(\"Using simple 0.5 bond cutoff\")\n",
    "bc[0,0]=0.50 # H-H\n",
    "bc[0,1]=0.50 # C-H\n",
    "bc[1,0]=0.50 # C-H\n",
    "bc[0,2]=0.50 # N-H\n",
    "bc[2,0]=0.50 # N-H\n",
    "bc[0,3]=0.50 # O-H\n",
    "bc[3,0]=0.50 # O-H\n",
    "bc[1,1]=0.50 # C-C\n",
    "bc[1,2]=0.50 # C-N\n",
    "bc[2,1]=0.50 # C-N\n",
    "bc[1,3]=0.50 # C-O\n",
    "bc[3,1]=0.50 # C-O\n",
    "bc[2,2]=0.50 # N-N\n",
    "bc[2,3]=0.50 # N-O\n",
    "bc[3,2]=0.50 # N-O\n",
    "bc[3,3]=0.50 # O-O\n",
    "\n",
    "atomid=zeros((nts,nats,2),int)\n",
    "bondn=zeros((nts,nats,nneigh),int)\n",
    "bonds=zeros((nts,nats,nneigh),float)\n",
    "geoms=zeros((nts,natt,5,5,5,5,nneigh),int)\n",
    "tstep=zeros((nts),float)\n",
    "bndn=zeros(nneigh,int)\n",
    "bnds=zeros(nneigh,float)\n",
    "j=0\n",
    "t=-1\n",
    "cur=0\n",
    "nbonds=0\n",
    "nlines=nats+8\n",
    "tbonds=0\n",
    "\n",
    "# Read data file\n",
    "ifile=open(input_file, 'r')\n",
    "for line in ifile:\n",
    "    tmp=re.split(r'[\\s]\\s*', line)\n",
    "    if((j%nlines)==0):\n",
    "        pastcur = cur\n",
    "        t+=1\n",
    "        if(t>=nts):\n",
    "            t-=1\n",
    "            break\n",
    "        initial_t=eval(tmp[2])\n",
    "        if(t>0):\n",
    "            cur = initial_t-t_start\n",
    "            tstep[t]=(cur-pastcur)*t*in_prm[1]/1000.\n",
    "    if((j%nlines)==2):\n",
    "        natoms=eval(tmp[4])\n",
    "    if((j%nlines)==4):\n",
    "        nbonds=eval(tmp[7])\n",
    "        if (nbonds>nneigh):\n",
    "            print (\"oops.  exceeded number of neighbors\")\n",
    "    if(((j%nlines)>6) and ((j%nlines)<nats+7)):\n",
    "        i=eval(tmp[1])-1 # atom number offset to 0:nats-1\n",
    "        n=eval(tmp[2])\n",
    "        if (n==2): # accounts for HNNOC atom type (next 3 lines)\n",
    "            n=3\n",
    "        if (n==5):\n",
    "            n=2\n",
    "        k=eval(tmp[3])\n",
    "        atomid[t,i,0]=n # atom type 1-4\n",
    "        atomid[t,i,1]=k # number of bonds to that atom\n",
    "        for kk in range(nneigh): # need to zero these out for sort operation\n",
    "            bndn[kk]=0\n",
    "            bnds[kk]=0.\n",
    "        for kk in range(k):\n",
    "            bndn[kk]=eval(tmp[kk+4])-1 # atom numbers of bonded atoms offset to 0:nats-1\n",
    "            bnds[kk]=eval(tmp[kk+5+k]) # bond orders for bonded atoms\n",
    "            tbonds+=1\n",
    "        ids=argsort(bnds)\n",
    "        for kk in range(k):\n",
    "            bondn[t,i,kk]=bndn[ids[nneigh-1-kk]]\n",
    "            bonds[t,i,kk]=bnds[ids[nneigh-1-kk]]\n",
    "    j+=1\n",
    "ifile.close()\n",
    "\n",
    "# Construct bond graph\n",
    "ts=t+1\n",
    "for t in range(ts):\n",
    "    kkmax=0\n",
    "    for i in range(nats):\n",
    "        ca=atomid[t,i,0]-1  # atom type 0-3\n",
    "        k=atomid[t,i,1] # number of bonds to that atom\n",
    "        cn=zeros(5,int) # numbers of each atom type or nothing bound to atom\n",
    "        kkn=0\n",
    "        kk=k\n",
    "        k=min(k,4)\n",
    "        for kk in range(k):\n",
    "            nn=atomid[t,bondn[t,i,kk],0]-1\n",
    "            if (bonds[t,i,kk]>bc[ca,nn]):\n",
    "                cn[nn]+=1\n",
    "                kkn+=1\n",
    "                cnnn=cn[nn]\n",
    "        kkmax=max(kkmax,kkn)\n",
    "        cn[4]=nneigh-1-cn[0]-cn[1]-cn[2]-cn[3]\n",
    "        geoms[t,ca,cn[0],cn[1],cn[2],cn[3],cn[4]]+=1\n",
    "\n",
    "hdr_for='type'\n",
    "for t in range(ts):\n",
    "   hdr_for+=' %0.3f' \n",
    "hdr_for+=' \\n'\n",
    "hdr_str='tstep[0]' \n",
    "for t in range(ts-1):\n",
    "   hdr_str+=', tstep[%d]' %(t+1)\n",
    "\n",
    "A_str=(\"H\",\"C\",\"N\",\"O\")\n",
    "vec_for='%s'\n",
    "for t in range(ts):\n",
    "   vec_for+=' %d'\n",
    "vec_for+=' \\n'\n",
    "vec_str='label'\n",
    "for t in range(ts):\n",
    "    vec_str+=', dum[%d]' %(t)\n",
    "\n",
    "dum=zeros(nts,float)\n",
    "ofile=open('Example/coord_NVT_3000K.txt', 'w')\n",
    "ofile.write(hdr_for %(eval(hdr_str)))\n",
    "for i in range(4):\n",
    "    for cn in range(5):\n",
    "        for c1 in range(cn+1):\n",
    "            for c2 in range(cn+1-c1):\n",
    "                for c3 in range(cn+1-c1-c2):\n",
    "                    c4=cn-c1-c2-c3\n",
    "                    c5=nneigh-1-cn\n",
    "                    dum[:]=geoms[:,i,c1,c2,c3,c4,c5]\n",
    "                    label='%s[' %(A_str[i])\n",
    "                    for cc in range(c1+1):\n",
    "                        if (cc>0):\n",
    "                            label+='H'\n",
    "                    for cc in range(c2+1):\n",
    "                        if (cc>0):\n",
    "                            label+='C'\n",
    "                    for cc in range(c3+1):\n",
    "                        if (cc>0):\n",
    "                            label+='N'\n",
    "                    for cc in range(c4+1):\n",
    "                        if (cc>0):\n",
    "                            label+='O'\n",
    "                    label+=']'\n",
    "                    ofile.write(vec_for %(eval(vec_str)))\n",
    "ofile.flush()                                              # flushes the internal buffer, which is supposed\n",
    "                                                           # to cause the OS to write out the buffer to\n",
    "                                                           # the file. If you write to a file, it may not be\n",
    "                                                           # completely written by the time you want to open\n",
    "                                                           # it. As such, remember to flush!\n",
    "ofile.close()\n",
    "\n",
    "print (\"Completed Part 1.A. Bond Table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developing the PCA model\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "maxit=5000\n",
    "ncomp=3\n",
    "model = PCA(n_components=ncomp, svd_solver='auto', iterated_power=maxit, random_state=0) # define model object\n",
    "model.fit(X)                                                                             # FITS THE MODEL\n",
    "print('The amount of variance explained by each of the selected components: '+ str(model.explained_variance_ratio_))\n",
    "print('Cumulative variance: '+str(sum(model.explained_variance_ratio_)))\n",
    "#print('The singular values (eigenvalues) corresponding to each of the selected components: '+str(model.singular_values_))\n",
    "W = model.fit_transform(X)                                                               # fit + transform\n",
    "H = model.components_                                                                    # features\n",
    "(wc,wr)=shape(W)\n",
    "(hc,hr)=shape(H)\n",
    "\n",
    "# write W output\n",
    "hdr_str='ts'\n",
    "for i in range(wc):\n",
    "    hdr_str+=',%f' %(ts[i])\n",
    "hdr_str+='\\n'\n",
    "\n",
    "out_str='C%d'\n",
    "out_for='i'\n",
    "for i in range(wc):\n",
    "    out_str+=',%f'\n",
    "    out_for+=',W[%d,i]' %(i)\n",
    "out_str+='\\n'\n",
    "\n",
    "ofile=open('Example/W_PCA.txt', 'w')\n",
    "ofile.write(hdr_str)\n",
    "for i in range(wr):\n",
    "    ofile.write(out_str %(eval(out_for)))\n",
    "ofile.flush()\n",
    "ofile.close()\n",
    "\n",
    "# write H output\n",
    "hdr_str='geom'\n",
    "for i in range(hc):\n",
    "    hdr_str+=',C%d' %(i)\n",
    "hdr_str+='\\n'\n",
    "\n",
    "out_str='%s'\n",
    "out_for='name[i]'\n",
    "for i in range(hc):\n",
    "    out_str+=',%f'\n",
    "    out_for+=',H[%d,i]' %(i)\n",
    "out_str+='\\n'\n",
    "\n",
    "ofile=open('Example/H_PCA.txt', 'w')\n",
    "ofile.write(hdr_str)\n",
    "for i in range(hr):\n",
    "    ofile.write(out_str %(eval(out_for)))\n",
    "ofile.flush()\n",
    "ofile.close()\n",
    "\n",
    "w = zeros((ncomp+1,nts),dtype=float)\n",
    "ifile = open(\"Example/W_PCA.txt\", 'r')\n",
    "counter = 0\n",
    "for line in ifile:\n",
    "    items = line.split(\",\")\n",
    "    for i in range(1,len(items)):\n",
    "        w[counter,i-1] = items[i].replace('\\n','')\n",
    "    counter += 1\n",
    "ifile.close()\n",
    "wt_PCA =  w.transpose()\n",
    "\n",
    "print (\"Completed Part 2.A. PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim((0,wt_PCA[-1,0]))\n",
    "plt.xlabel('Time (ps)')\n",
    "for k in range(ncomp):\n",
    "    plt.plot( wt_PCA[:,0], wt_PCA[:,k+1], linewidth=2)\n",
    "plt.show()\n",
    "print (\"Completed Part 2.B. Visualize PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"gap1\"] = dataset[\"lumo\"] - dataset[\"homo\"]\n",
    "dataset[\"gap1\"] >= dataset[\"gap\"]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.featurizers.composition.thermo import CohesiveEnergy\n",
    "ef = CohesiveEnergy()\n",
    "#element_fractions = ef.featurize(fe2o3)\n",
    "#print(element_fractions)\n",
    "element_fractions = ef.featurize(O=COC1CCC11CN1)\n",
    "print(element_fractions)\n",
    "df = ef.featurize_dataframe(df, \"composition\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['alpha'].values\n",
    "#\"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop([\"mol_id\", \"smiles\", \"homo\", \"alpha\"], axis=1)\n",
    "print(\"There are {} possible descriptors:\".format(len(X.columns)))\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "rf.fit(X, y)\n",
    "# y = \"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "\n",
    "train_values, test_values = np.split(all_values, [index_split_at])\n",
    "train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "\n",
    "# We introduce the model here:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "model =  RandomForestRegressor(n_estimators = 2000, random_state = 0) \n",
    "model.fit(train_values, train_labels)\n",
    "\n",
    "test_pred = model.predict(test_values)\n",
    "all_pred = model.predict(all_values)\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_pred, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\")\n",
    "\n",
    "testing= go.Scatter(x = test_labels, y = test_pred, mode = 'markers', marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\")\n",
    "\n",
    "match = go.Scatter(x = [0,20], y = [0,20], mode = 'lines', name = \"Match\",line= dict( color = 'black'))\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat Maps using Matplotlib and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "qm9 = pd.read_csv(\"./qm9.csv\")\n",
    "qm9.head() # just seeing that data was imported properly by outputing first 5 cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Columns (by different methods)\n",
    "#couple_columns = qm9[['gap','homo', 'lumo']]\n",
    "couple_columns = qm9[['gap','zpve', 'mu']]\n",
    "couple_columns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting same columns a different way\n",
    "qm9.ix[:,['gap','homo', 'lumo']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is essentially would be taking the average of each unique combination. \n",
    "# one important mention is notice how little the data varies from eachother.\n",
    "#homo_lumo_mix = couple_columns.groupby(['homo', 'lumo']).mean()\n",
    "homo_lumo_mix = couple_columns.groupby(['zpve', 'mu']).mean()\n",
    "print(homo_lumo_mix.shape)\n",
    "homo_lumo_mix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_lumo_mix = homo_lumo_mix.reset_index()\n",
    "homo_lumo_mix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat Map using Matplotlib\n",
    "major_ticks = np.arange(0, 200, 20)                                              \n",
    "minor_ticks = np.arange(0, 180, 5)  \n",
    "\n",
    "fig = plt.figure(figsize = (6,5))  \n",
    "ax = fig.add_subplot(1,1,1)  \n",
    "#s = ax.scatter('homo', 'lumo', c = 'gap',data = homo_lumo_mix, cmap = 'Blues_r', marker = 's',s = 190)\n",
    "s = ax.scatter('zpve', 'mu', c = 'gap',data = homo_lumo_mix, cmap = 'Blues_r', marker = 's',s = 190)\n",
    "#ax.axis([homo_lumo_mix['homo'].min()-10, homo_lumo_mix['homo'].max()+10, homo_lumo_mix['lumo'].min()-10, homo_lumo_mix['lumo'].max()+10])\n",
    "ax.axis([homo_lumo_mix['zpve'].min()-10, homo_lumo_mix['zpve'].max()+10, homo_lumo_mix['mu'].min()-10, homo_lumo_mix['mu'].max()+10])\n",
    "ax.set_xticks(major_ticks)                                                       \n",
    "ax.set_xticks(minor_ticks, minor=True)                                           \n",
    "ax.set_yticks(major_ticks)                                                                                                                                                      \n",
    "ax.grid(which='both', alpha = 0.3)                                                                                                           \n",
    "ax.grid(which='major', alpha=0.3) \n",
    "#ax.set_xlabel('homo', fontsize=10);\n",
    "#ax.set_ylabel('lumo', fontsize=10);\n",
    "ax.set_xlabel('zpve', fontsize=10);\n",
    "ax.set_ylabel('mu', fontsize=10);\n",
    "#ax.set_title('gap from homo-lumo', size = 15)\n",
    "ax.set_title('gap from zpve-mu', size = 15)\n",
    "# http://stackoverflow.com/questions/13943217/how-to-add-colorbars-to-scatterplots-created-like-this\n",
    "cbar = plt.colorbar(mappable = s,ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas==0.21\n",
    "import pandas as pd\n",
    "import numpy as np;\n",
    "import seaborn as sns; \n",
    "\n",
    "qm9 = pd.read_csv(\"./qm9.csv\")\n",
    "couple_columns = qm9[['gap','zpve', 'mu']].head(10)\n",
    "print(couple_columns.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Heat Map using Seaborn\n",
    "#import numpy as np;\n",
    "#import seaborn as sns; \n",
    "\n",
    "# To translate into Excel Terms for those familiar with Excel\n",
    "# string 1 is row labels 'helix1 phase'\n",
    "# string 2 is column labels 'helix 2 phase'\n",
    "# string 3 is values 'Energy'\n",
    "# Official pivot documentation\n",
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot.html\n",
    "\n",
    "#homo_lumo_mix.pivot('zpve', 'mu','gap').head()\n",
    "#homo_lumo_mix.pivot('zpve', 'mu')['gap'].head()\n",
    "\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_lumo_mix = couple_columns.groupby(['zpve', 'mu']).mean()\n",
    "print(homo_lumo_mix.shape)\n",
    "homo_lumo_mix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_lumo_mix.pivot('zpve', 'mu')['gap'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn heatmap documentation\n",
    "# https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.heatmap.html\n",
    "\n",
    "# cmap choices: http://matplotlib.org/users/colormaps.html\n",
    "plt.figure(figsize=(9,9))\n",
    "pivot_table = homo_lumo_mix.pivot('zpve', 'mu','gap')\n",
    "plt.xlabel('mu', size = 15)\n",
    "plt.ylabel('zpve', size = 15)\n",
    "plt.title('gap from zpve-mu', size = 15)\n",
    "ax = sns.heatmap(pivot_table, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r1.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subplotting and 3D Heatmaps using Matplotlib and Seaborn\n",
    "initial_data = pd.read_csv(\"./qm9.csv\")\n",
    "initial_data.head() # just seeing that data was imported properly by outputing first 5 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting Columns (by different methods)\n",
    "# selecting a couple columns\n",
    "data = initial_data[['A', 'B', 'C', 'gap']]\n",
    "data2 = data\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is essentially would be taking the average of each unique combination. \n",
    "# one important mention is notice how little the data varies from eachother.\n",
    "data = data.groupby(['A', 'B', 'C']).mean()\n",
    "low = data2.groupby(['A', 'B', 'C']).min()\n",
    "print(homo_lumo_mix.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data2 = data2.reset_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D Matplotlib Heatmap\n",
    "# Main problem here is nnot very interactive or informative. Very Pretty though! \n",
    "# other problem is colorbar takes up space normally used for figure. Also not interactive. \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#colors = cm.hsv(the_fourth_dimension/max(the_fourth_dimension))\n",
    "\n",
    "colmap = cm.ScalarMappable(cmap=cm.Greens_r)\n",
    "colmap.set_array(data[['gap']])\n",
    "\n",
    "# reference for cmap. note cmap and c are different!\n",
    "# http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "ax.scatter(data[['A']], data[['B']], data[['C']], marker='s',s = 140, c=data[['gap']], cmap='Greens_r');\n",
    "cb = fig.colorbar(colmap)\n",
    "\n",
    "ax.set_xlabel('A');\n",
    "ax.set_ylabel('B');\n",
    "ax.set_zlabel('C');\n",
    "plt.show()\n",
    "# change view angle \n",
    "# http://infamousheelfilcher.blogspot.com/2013/02/changing-viewing-angle-of-matplotlib.html\n",
    "#ax.view_init(azim = 0,elev = 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking Average of Unique Combination\n",
    "# It would be a lot of redundant code to make the \n",
    "# labelsize bigger on all the subplots for each future graph\n",
    "# this just graphs pylabs defaults temporarily\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': '17',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.heatmap.html\n",
    "# for more seaborn stuff\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (25,25));\n",
    "\n",
    "filt_data = initial_data[['A', 'B', 'gap']];\n",
    "filt_data = filt_data.groupby(['A', 'B']).mean();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_0 = filt_data.pivot('A', 'B', 'gap');\n",
    "sns.heatmap(pivot_0_0, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[0], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "\n",
    "\n",
    "filt_data = initial_data[['A', 'C', 'gap']];\n",
    "filt_data = filt_data.groupby(['A', 'C']).mean();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_1 = filt_data.pivot('A', 'C', 'gap');\n",
    "sns.heatmap(pivot_0_1, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[1], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "\n",
    "filt_data = initial_data[['B', 'C', 'gap']];\n",
    "filt_data = filt_data.groupby(['B', 'C']).mean();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_2 = filt_data.pivot('B', 'C', 'gap');\n",
    "sns.heatmap(pivot_0_2, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[2], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min of Each Combination\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (25,25));\n",
    "\n",
    "filt_data = initial_data[['A', 'B', 'gap']];\n",
    "filt_data = filt_data.groupby(['A', 'B']).min();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_0 = filt_data.pivot('A', 'B', 'gap');\n",
    "sns.heatmap(pivot_0_0, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[0], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "\n",
    "filt_data = initial_data[['A', 'C', 'gap']];\n",
    "filt_data = filt_data.groupby(['A', 'C']).min();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_1 = filt_data.pivot('A', 'C', 'gap');\n",
    "sns.heatmap(pivot_0_1, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[1], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "filt_data = initial_data[['B', 'C', 'gap']];\n",
    "filt_data = filt_data.groupby(['B', 'C']).min();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_2 = filt_data.pivot('B', 'C', 'gap');\n",
    "sns.heatmap(pivot_0_2, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[2], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (25,25));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking Max of Unique Combination\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (25,25));\n",
    "\n",
    "filt_data = initial_data[['A', 'B', 'gap']];\n",
    "filt_data = filt_data.groupby(['A', 'B']).max();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_0 = filt_data.pivot('A', 'B', 'gap');\n",
    "sns.heatmap(pivot_0_0, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[0], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "filt_data = initial_data[['A', 'C', 'gap']];\n",
    "filt_data = filt_data.groupby(['A', 'C']).max();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_1 = filt_data.pivot('A', 'C', 'gap');\n",
    "sns.heatmap(pivot_0_1, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[1], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "filt_data = initial_data[['B', 'C', 'gap']];\n",
    "filt_data = filt_data.groupby(['B', 'C']).max();\n",
    "filt_data = filt_data.reset_index();\n",
    "pivot_0_2 = filt_data.pivot('B', 'C', 'gap');\n",
    "sns.heatmap(pivot_0_2, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r', ax = axes[2], cbar = False);\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (25,25));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Random Forests with Sample Uncertainties (FUELS Framework) -- MODEL\n",
    "https://proxy.nanohub.org/weber/1910229/wwOPefJEgELWDSHq/10/notebooks/ActiveLearning_Figures.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll re-process the data\n",
    "\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "from lolopy.metrics import root_mean_squared_error\n",
    "\n",
    "history_table = pd.DataFrame(columns=['Composition','Experimental',\"Prediction\"])\n",
    "\n",
    "compositions_examined = np.array(data[\"chemicalFormula\"], dtype = \"object\") # Storing the composition together with \n",
    "\n",
    "all_values = [list(x_df.iloc[x]) for x in range(len(x_df.index))]\n",
    "all_values = np.array(all_values, dtype = float) \n",
    "all_labels = y.copy()\n",
    "\n",
    "\n",
    "# SHUFFLE AND SPLITTING\n",
    "\n",
    "all_values, all_labels, compositions_examined = shuffle(all_values, all_labels, compositions_examined, random_state=6)\n",
    "\n",
    "train_values, test_values = np.split(all_values, [index_split_at])\n",
    "train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "comp_train, comp_test = np.split(compositions_examined, [index_split_at])\n",
    "\n",
    "# MODEL AND TRAINING\n",
    "\n",
    "randomforest_model = RandomForestRegressor(num_trees=500)\n",
    "randomforest_model.fit(train_values, train_labels)\n",
    "\n",
    "test_pred, test_std = randomforest_model.predict(test_values, return_std=True)\n",
    "all_pred, all_std = randomforest_model.predict(all_values, return_std=True)\n",
    "\n",
    "inner_df = pd.DataFrame()\n",
    "inner_df[\"Composition\"] = comp_test\n",
    "inner_df[\"Experimental\"] = test_labels\n",
    "inner_df[\"Predictions\"] = test_pred\n",
    "inner_df[\"residual\"] = test_pred - test_labels\n",
    "inner_df[\"STD\"] = test_std\n",
    "inner_df = inner_df.sort_values(by='Experimental')\n",
    "display(inner_df)\n",
    "\n",
    "mean_rf = mean_absolute_error(test_labels, test_pred)\n",
    "print(mean_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "plt.errorbar(all_labels, all_pred, color='green', marker='o', markersize=12, linestyle='None', label='Training Data')\n",
    "plt.errorbar(test_labels, test_pred, yerr=test_std, color='red', marker='o', markersize=12, linestyle='None',label='Testing Data')\n",
    "plt.plot([-1, 20], [-1, 20], linestyle='dashed', color='black')\n",
    "plt.xticks(np.linspace(0,20,11),fontsize=26)\n",
    "plt.yticks(np.linspace(0,20,11), fontsize=26)\n",
    "plt.xlim([-1,20])\n",
    "plt.ylim([-1,20])\n",
    "plt.grid()\n",
    "plt.legend(loc=2, fontsize=22)\n",
    "plt.ylabel('Predicted Conductivity x10$^{-4}$ (S/cm)', fontsize=26)\n",
    "plt.xlabel('Experimental Conductivity x10$^{-4}$ (S/cm)', fontsize=26)\n",
    "plt.title('Random Forest', fontsize=26)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ta Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_line_comps = []\n",
    "ta_array = np.linspace(0,1,101) # X-Axis granularity to generate nominal stoichometries\n",
    "x_values_pred = np.linspace(0,1,101) # X-Axis granulatirty for plotting\n",
    "\n",
    "\n",
    "# Generating stoichiometric nominal compositions doped with Ta\n",
    "for stg in ta_array:\n",
    "    base_equation_string = \"Li\" + (('%f'%(np.around(7 - stg, decimals=3, out=None))).rstrip('0').rstrip('.')) + \"La3\" + \"Zr\" + (('%f'%(np.around(2 - stg, decimals=3, out=None))).rstrip('0').rstrip('.')) + (\"Ta\" + (('%f'%(np.around(stg, decimals=3, out=None))).rstrip('0').rstrip('.')) if stg > 0 else '') + \"O12\"\n",
    "    ta_line_comps.append(base_equation_string)\n",
    "\n",
    "\n",
    "# Getting descriptors from the chemical formula\n",
    "    \n",
    "ta_composition_test_set_dataframe = pd.DataFrame(ta_line_comps, columns=['chemicalFormula'])\n",
    "ta_composition_test_set_dataframe['composition'] = ta_composition_test_set_dataframe['chemicalFormula'].apply(get_composition) # Transformation of chemicalformula string into Matminer composition\n",
    "ta_feat_test_set= np.array(f.featurize_many(ta_composition_test_set_dataframe['composition'], ignore_errors=True)) # Array to store such features\n",
    "\n",
    "ta_temp_array = np.array([25.0 for _ in range(ta_feat_test_set.shape[0])]).reshape(-1,1) # Array of simulated measuring temperatures\n",
    "ta_feat_test_set = np.hstack((ta_feat_test_set, ta_temp_array))\n",
    "\n",
    "\n",
    "# We need to drop the same columns that were dropped from the original training set so that this map has the same number of descriptors\n",
    "\n",
    "# This code is to drop columns with std = 0. \n",
    "ta_parsed_features_test_set = pd.DataFrame(ta_feat_test_set)\n",
    "ta_parsed_features_test_set_2 = ta_parsed_features_test_set.loc[:,  x_df_prior.std() != 0] # Dropping same columns that were dropped on the training data\n",
    "\n",
    "# Turning these values into an array\n",
    "ta_values = [list(ta_parsed_features_test_set_2.iloc[x]) for x in range(len(ta_parsed_features_test_set_2.index))]\n",
    "ta_values = np.array(ta_values, dtype = float) \n",
    "\n",
    "\n",
    "# Making predictions\n",
    "y_values_pred, err_values_pred = randomforest_model.predict(ta_values, return_std=True)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize =(10,10))\n",
    "plt.plot(x_values_exp,y_values_exp, color='blue', marker='o', fillstyle='none', markersize=12, linestyle = \"None\",  label = \"Experiment\") # This is from the list of Ta-compositions before dropping duplicates\n",
    "plt.plot(x_values_dupmed,y_values_dupmed, color='black',  marker='x', markersize=14, linestyle = \"None\", label = \"Median\") # This is from the list of Ta-compositions after dropping duplicates\n",
    "\n",
    "plt.plot(x_values_pred,y_values_pred, color='red', linestyle='solid',label='Prediction') # Predictions\n",
    "plt.fill_between(np.array(x_values_pred), np.array(y_values_pred)-np.array(err_values_pred), np.array(y_values_pred)+np.array(err_values_pred), facecolor='#EBECF0') # Uncertainty regions\n",
    "\n",
    "plt.grid()\n",
    "plt.legend(fontsize=22)\n",
    "plt.xlabel(\"Ta Content\", fontsize =26)\n",
    "plt.ylabel(\"Ionic Conductivity x10$^{-4}$ (S/cm)\", fontsize =26)\n",
    "plt.xticks(fontsize=26)\n",
    "plt.yticks(fontsize=26)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests with Sample Uncertainties (Citrination's Lolopy)\n",
    "\n",
    "A random forest from the lolopy library is implemented and an equivalent match plot is shown below. This library can yield the sample-wise uncertainties from a model, following the work from Ling et al, and using a combination of the jackknife-after-bootstrap and infinitesimal-jackknife estimates paired with a montecarlo sampling correction. More details on this uncertainty estimates are discussed in the next section.\n",
    "\n",
    "$$ \\sigma^2_i(x) = Cov_j[n_{i,J}, T_J(x)]^2 + [\\overline{T}_{-i}(x) - \\overline{T}(x)]^2 - \\frac{e\\nu}{N_T} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/CitrineInformatics/lolo/blob/develop/python/examples/ling-immi-2017.ipynb\n",
    "train_values, test_values = np.split(all_values, [index_split_at])\n",
    "train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "\n",
    "model =  RandomForestRegressor(num_trees=500)\n",
    "model.fit(train_values, train_labels)\n",
    "\n",
    "test_pred, test_std = model.predict(test_values, return_std=True)\n",
    "all_pred, all_std = model.predict(all_values, return_std=True)\n",
    "\n",
    "layout0= go.Layout(hovermode='closest', xaxis= dict(title=go.layout.xaxis.Title(text='Experimental Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2),\n",
    "                   yaxis= dict(title=go.layout.yaxis.Title(text='Predicted Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2), width = 1000, height=1000)\n",
    "\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_pred, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\")\n",
    "\n",
    "testing= go.Scatter(x = test_labels, y = test_pred, mode = 'markers', marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\", error_y=dict(type='data', array=test_std,visible=True))\n",
    "\n",
    "match = go.Scatter(x = [0,1], y = [0,1], mode = 'lines', name = \"Match\",line= dict( color = 'black'))\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X)\n",
    "# y = \"alpha\" - Isotropic polarizability (unit: Bohr^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print('training RMSE = {:.3f} Bohr^3'.format(np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf, X, y, scoring='neg_mean_squared_error', cv=kfold)\n",
    "\n",
    "rmse_scores = [np.sqrt(abs(s)) for s in scores]\n",
    "print('Mean RMSE: {:.3f} Bohr$^3$'.format(np.mean(rmse_scores)))\n",
    "# y = \"alpha\" - Isotropic polarizability (unit: Bohr^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(rf, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[\"alpha predicted\"] = y_pred\n",
    "dataset[\"percentage_error\"] = (dataset[\"alpha\"] - dataset[\"alpha predicted\"]).abs()/dataset[\"alpha\"] * 100\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a function that takes a value X (Which will be the Symbol of the Element) \n",
    "# and returns a color depending on what its crystal structure is in our arrays from the beginning.\n",
    "# That is because we want to color data according to the crystal structure; therefore, we will have to pass this info to the plot\n",
    "\n",
    "def SetColor_CrystalStr(x):\n",
    "    if x in dataset[dataset.alpha.ge(150)]:\n",
    "        return \"red\" #This are standard CSS colors, but you can also use Hexadecimal Colors (#009900) or RGB \"rgb(0, 128, 0)\"\n",
    "    elif x in dataset[dataset.alpha.le(50)]:\n",
    "        return \"blue\"\n",
    "    elif x in dataset[dataset.alpha.eq(50)]:\n",
    "        return \"yellow\"\n",
    "    else:\n",
    "        return \"lightgray\"\n",
    "    \n",
    "# We will then create a list that passes all element symbols through this function. For that we will use the python function \"map\"    \n",
    "# Map takes each element on a list and evaluates it in a function.\n",
    "\n",
    "colors = list(map(SetColor_CrystalStr, mol_id))\n",
    "\n",
    "# You can see this list of generated colors looks like by uncommenting this line\n",
    "\n",
    "#print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "reference_line = go.Scatter(\n",
    "    x=[0, 200],\n",
    "    y=[0, 200],\n",
    "    line=dict(color=\"black\", dash=\"dash\"),\n",
    "    mode=\"lines\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig = px.scatter(\n",
    "    dataset, \n",
    "    x=\"alpha\", \n",
    "    y=\"alpha predicted\", \n",
    "    #hover_name=\"formula\", \n",
    "    color=\"percentage_error\", \n",
    "    color_continuous_scale=px.colors.sequential.Bluered,\n",
    ")\n",
    "\n",
    "fig.add_trace(reference_line)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "included = X.columns.values\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "fig_bar = px.bar(\n",
    "    x=included[indices][0:5], \n",
    "    y=importances[indices][0:5], \n",
    "    title=\"Feature Importances of Random Forest\",\n",
    "    labels={\"x\": \"Feature\", \"y\": \"Importance\"}\n",
    ")\n",
    "fig_bar.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Learning and Design of Experiments\n",
    "## Active Learning\n",
    "\n",
    "Active learning is the use of algorithms not for regression, but for the improvement of the input sample space that guides the 'experiments' required to get to such maximum values. Even if it does make predictions for a specific material, its main task is the selection of the most likely candidate to be in a global maxima. Global optimization is based on the assumption that a model can perform better when it can \"choose\" which point to query next. This is the approach introduced in the paper by Julia Ling\n",
    "\n",
    "## Uncertainty Estimates\n",
    "\n",
    "The first step on active learning always comes from an approximation of the error in the prediction from the model. Relevant work on how to compute this estimates can be found in publications by [Efron](https://statistics.stanford.edu/sites/g/files/sbiybj6031/f/BIO%20262_0.pdf) and [Wager](https://jmlr.org/papers/volume15/wager14a/wager14a.pdf).\n",
    "\n",
    "To compute an estimate, we need to understand how to compute some important quantities:\n",
    "\n",
    "<b> Expected Value: </b> The mean of the predictions over all the decision trees represents the expected value for this particular model. The equation to compute this quantity is shown below:\n",
    "<br>\n",
    "<br>\n",
    "$$ E[M(x)] = \\frac{1}{N} \\sum\\limits_{J}^{n_T} T_J(x) $$\n",
    "<br>\n",
    "\n",
    "In this equation:\n",
    "\n",
    "$E[M(x)] \\rightarrow $ Expected value of the prediction of the model at point $x$\n",
    "<br>\n",
    "$ T_J(x) \\rightarrow $ Prediction of tree index $J$ for point $x$\n",
    "<br>\n",
    "$n_T $ is the number of trees\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<b> Variance: </b> For the calculation of the variance, we will compute the value of the <b>\"Variance at point x due to training point i \"</b>. For this model, we are following on the work from Ling et al, and using a combination of the jackknife-after-bootstrap and infinitesimal-jackknife estimates paired with a montecarlo sampling correction.\n",
    "\n",
    "$$ \\sigma^2_i(x) = Cov_j[n_{i,J}, T_J(x)]^2 + [\\overline{T}_{-i}(x) - \\overline{T}(x)]^2 - \\frac{e\\nu}{N_T} $$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "$n_{i,J} \\rightarrow $ Number of times point $i$ was used to train tree $J$\n",
    "<br>\n",
    "$\\overline{T}_{-i}(x) \\rightarrow $ Average of the prediction over the trees that were fit without using point $i$\n",
    "<br>\n",
    "$\\overline{T}(x) \\rightarrow $ Average of the prediction over all of the trees\n",
    "<br>\n",
    "$e$ is Euler's number and $\\nu$ is the variance over all trees\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<b> Uncertainty Estimate: </b> For the calculation of the estimate, we will add the contributions of each of the training points to the variance of our test point, together with an explicit bias model and a noise threshold.\n",
    "\n",
    "$$ \\sigma[M(x)] = \\sqrt{ \\sum\\limits_{i=1}^S max[\\sigma^2_i(x), \\omega] + \\widetilde{\\sigma}^{ 2}(x)} $$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "$\\sigma^2_i(x) \\rightarrow $ Variance at point x due to training point i\n",
    "<br>\n",
    "$\\omega \\rightarrow $ Noise threshold \n",
    "<br>\n",
    "$ \\widetilde{\\sigma}^{ 2}(x) \\rightarrow $ Explicit bias model\n",
    "<br>\n",
    "$S$ is the number of training points\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "The noise threshold ($\\omega$) is defined as:\n",
    "$$\\omega = min_i \\sigma^2 [M(x_i)]$$\n",
    "\n",
    "### Information Acquisition Functions\n",
    "\n",
    "Information Acquisition Functions are based on different criteria on which point is more relevant for the model to query next. In this notebook we discuss MEI (Maximum Expected Improvement), MLI (Maximum Likelihood of Improvement), MU (Maximum Uncertainty) and UCB (Upper Confidence Bound).\n",
    "\n",
    "<b>MEI.</b> This approach takes the maximum value of the prediction of the model over the possible experiments to run.\n",
    "\n",
    "<br>\n",
    "$$ x^* = arg\\_max \\enspace E[M(x_i)]$$\n",
    "\n",
    "where $x_i \\rightarrow$ Set of possible experiments to run.\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>MLI.</b> This approach tells us that we are expecting to query a region for which we see an improvement and sufficient uncertainty to have a high likelihood of getting a larger value.\n",
    "\n",
    "$$ x^* = arg\\_max \\enspace \\frac{E[M(x_i)] - E[M(x_{best})]}{\\sigma[M(x_i)]}$$\n",
    "\n",
    "where $x_{best} \\rightarrow$ Value of our current best case.\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>MU.</b> This strategy queries the sample with the highest uncertainty.\n",
    "<br>\n",
    "$$ x^* = arg\\_max \\enspace \\sigma[M(x_i)]$$\n",
    "<br>\n",
    "\n",
    "<b>UCB.</b> This strategy queries the sample with the maximum value of its mean prediction plus its uncertainty.\n",
    "<br>\n",
    "$$ x^* = arg\\_max \\enspace [E[M(x_i)] + \\sigma[M(x_i)]]$$\n",
    "<br>\n",
    "\n",
    "### Approach\n",
    "\n",
    "We will select an initial set of 10 entries, and we'll make sure the highest value is not in it. If it is, the cell will throw an error, just re-run it so that it can shuffle it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, test_values = np.split(all_values, [index_split_at])\n",
    "train_labels, test_labels = np.split(all_labels, [index_split_at])\n",
    "\n",
    "#Create a training set\n",
    "#train_labels =all_labels[length:]\n",
    "#train_values =all_values[length:]\n",
    "\n",
    "#Create a testing set\n",
    "#test_labels =all_labels[:length]\n",
    "#test_values =all_values[:length]\n",
    "\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "\n",
    "model =  RandomForestRegressor(num_trees=500)\n",
    "model.fit(train_values, train_labels)\n",
    "\n",
    "test_pred, test_std = model.predict(test_values, return_std=True)\n",
    "all_pred, all_std = model.predict(all_values, return_std=True)\n",
    "\n",
    "\n",
    "\n",
    "layout0= go.Layout(hovermode='closest', xaxis= dict(title=go.layout.xaxis.Title(text='Experimental Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2),\n",
    "                   yaxis= dict(title=go.layout.yaxis.Title(text='Predicted Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2), width = 1000, height=1000)\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_pred, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\")\n",
    "\n",
    "testing= go.Scatter(x = test_labels, y = test_pred, mode = 'markers', marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\", error_y=dict(type='data', array=test_std,visible=True))\n",
    "\n",
    "match = go.Scatter(x = [0,1], y = [0,1], mode = 'lines', name = \"Match\",line= dict( color = 'black'))\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "# PLOTTING (MATPLOTLIB)\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# PYTHON\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(44) # Random Seed\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# MACHINE LEARNING\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import initializers, regularizers\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# PLOTTING (PLOTLY)\n",
    "import plotly \n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINITION OF THE MODEL\n",
    "\n",
    "kernel_init = initializers.RandomNormal(seed=30)\n",
    "bias_init = initializers.Zeros()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(90, activation='relu', use_bias = True, input_shape=(train_values.shape[1], ), kernel_initializer=kernel_init, bias_initializer=bias_init))\n",
    "model.add(Dense(60, activation='relu', use_bias = True, kernel_initializer=kernel_init, bias_initializer=bias_init))\n",
    "model.add(Dense(30, activation='relu', use_bias = True,  kernel_initializer=kernel_init, bias_initializer=bias_init))\n",
    "model.add(Dense(1, activation='relu', use_bias = True, kernel_initializer=kernel_init, bias_initializer=bias_init))\n",
    "\n",
    "optimizer = tf.optimizers.Adam() #tf.train.AdamOptimizer() \n",
    "\n",
    "model.compile(loss='mae', optimizer=tf.optimizers.Adam(), metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EARLY STOPPING CRITERIAS\n",
    "\n",
    "#mae_es= keras.callbacks.EarlyStopping(monitor='mean_squared_error', min_delta=1e-8, patience=200, verbose=1, mode='auto', restore_best_weights=True)\n",
    "valmae_es= keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error', min_delta=1e-10, patience=1000, verbose=1, mode='auto', restore_best_weights=True)\n",
    "#loss,mae,val_loss,val_mae\n",
    "\n",
    "# EPOCH REAL TIME COUNTER CLASS\n",
    "class PrintEpNum(keras.callbacks.Callback): # This is a function for the Epoch Counter\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"Current Epoch: \" + str(epoch+1) + \" Training Loss: \" + \"%4f\" %logs.get('loss') + '                                       \\r') # Updates current Epoch Number\n",
    "\n",
    "EPOCHS = 30 # Number of EPOCHS\n",
    "\n",
    "# HISTORY Object which contains how the model learned\n",
    "\n",
    "history = model.fit(train_values, train_labels, batch_size=90, validation_split=0.1, shuffle=False, epochs=EPOCHS, verbose = False, callbacks=[PrintEpNum(), valmae_es])   \n",
    "\n",
    "# PLOTTING HISTORY USING MATPLOTLIB\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Abs Error')\n",
    "plt.plot(history.epoch, np.array(history.history['mae']),label='MAE Training') \n",
    "plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),label = 'MAE Validation') \n",
    "print(\"Loss at best epoch\", min(list(np.array(history.history['mean_absolute_error']))))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "[loss, mae] = model.evaluate(train_values, train_labels, verbose=0)\n",
    "print(\"Training Set Mean Absolute Error: {:2.4f} units\".format(mae))\n",
    "\n",
    "[loss, mae] = model.evaluate(test_values, test_labels, verbose=0)\n",
    "print(\"Testing Set Mean Absolute Error: {:2.4f} units\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_values).flatten() # Prediction of the test set\n",
    "\n",
    "values = np.concatenate((train_values, test_values), axis=0) # This line joins the values together to evaluate all of them\n",
    "all_predictions = model.predict(values).flatten()\n",
    "\n",
    "# MATCH PLOT\n",
    "\n",
    "layout0= go.Layout(hovermode='closest', xaxis= dict(title=go.layout.xaxis.Title(text='Experimental Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2),\n",
    "                   yaxis= dict(title=go.layout.yaxis.Title(text='Predicted Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2), width = 1000, height=1000)\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_predictions, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\") # All values\n",
    "testing= go.Scatter(x = test_labels, y = test_predictions, mode = 'markers', \n",
    "                      marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\") # Test set\n",
    "\n",
    "match = go.Scatter(x = [0,1], y = [0,1], mode = 'lines', name = \"Match\",line= dict( color = 'black')) # Match Line\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_values.copy()\n",
    "y = all_labels.copy()\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "#Set up a new model with a small initial set.\n",
    "entry_number_init = 50\n",
    "\n",
    "in_train = np.zeros(len(data), dtype=np.bool)\n",
    "in_train[np.random.choice(len(data), entry_number_init, replace=False)] = True\n",
    "print('Picked {} training entries'.format(in_train.sum()))\n",
    "assert not np.isclose(max(y), max(y[in_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X[in_train], y[in_train])\n",
    "y_pred, y_std = model.predict(X[~in_train], return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, we will query the next material to sample using the four different acquisition functions we described before.\n",
    "\n",
    "#Just as a reminder, the NumPy function argmax returns the index of the maximum value of an array.\n",
    "\n",
    "mei_selection = np.argmax(y_pred)\n",
    "mli_selection = np.argmax(np.divide(y_pred - np.max(y[in_train]), y_std))\n",
    "mu_selection = np.argmax(y_std)\n",
    "ucb_selection = np.argmax([sum(x) for x in zip(y_pred, y_std)])\n",
    "\n",
    "print('Predicted ' + property_interest + ' of material #{} selected based on MEI: {:.6f} +/- {:.6f}'.format(mei_selection, y_pred[mei_selection], y_std[mei_selection]))\n",
    "print('Predicted ' + property_interest + ' of material #{} selected based on MLI: {:.6f} +/- {:.6f}'.format(mli_selection, y_pred[mli_selection], y_std[mli_selection]))\n",
    "print('Predicted ' + property_interest + ' of material #{} selected based on MU: {:.6f} +/- {:.6f}'.format(mu_selection, y_pred[mu_selection], y_std[mu_selection]))\n",
    "print('Predicted ' + property_interest + ' of material #{} selected based on UCB: {:.6f} +/- {:.6f}'.format(ucb_selection, y_pred[ucb_selection], y_std[ucb_selection]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['gap'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resid = []\n",
    "y_uncer = []\n",
    "for train_id, test_id in KFold(8, shuffle=True).split(X):\n",
    "    model.fit(X[train_id], y[train_id])\n",
    "    yf_pred, yf_std = model.predict(X[test_id], return_std=True)\n",
    "    y_resid.extend(yf_pred - y[test_id])\n",
    "    y_uncer.extend(yf_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "x = np.linspace(-8, 8, 50)\n",
    "\n",
    "# Plot the RF uncertainty\n",
    "resid = np.divide(y_resid, y_uncer)\n",
    "axs[0].hist(resid, x, density=True)\n",
    "axs[0].set_title('With Lolo Uncertainty Estimates')\n",
    "\n",
    "# Plot assuming constant errors\n",
    "resid = np.divide(y_resid, np.sqrt(np.power(y_resid, 2).mean()))\n",
    "axs[1].hist(resid, x, density=True)\n",
    "axs[1].set_title('Assuming Constant Error')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.plot(x, norm.pdf(x), 'k--', lw=0.75)\n",
    "    ax.set_xlabel('Normalized Residual')\n",
    "\n",
    "axs[0].set_ylabel('Probability Density')\n",
    "\n",
    "fig.set_size_inches(6.5, 2)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the algorithm that runs the queries. We start with the initial set and we run 50 experiments to test how long would it take for us to get to the sample with the highest value. Each of the approaches selects a different next point to query and include in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of experiments to run\n",
    "n_steps = 100\n",
    "all_inds = set(range(len(y)))\n",
    "\n",
    "#Start this list with our initial set\n",
    "random_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "mei_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "mli_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "mu_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "ucb_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "random_train_inds = []\n",
    "mei_train_inds = []\n",
    "mli_train_inds = []\n",
    "ucb_train_inds = []\n",
    "\n",
    "\n",
    "for i in range(n_steps):\n",
    "    \n",
    "    # Maximum Expected Improvement\n",
    "    #Current set of training indexes\n",
    "    mei_train_inds = mei_train[-1].copy()    # Initial Set (In the first run) / Current Set (From last iteration, after the first run)\n",
    "    #Difference between all indexes and the ones we are training on (where we are searching)\n",
    "    mei_search_inds = list(all_inds.difference(mei_train_inds)) # All samples not in the current set\n",
    "        \n",
    "    model.fit(X[mei_train_inds], y[mei_train_inds]) # Training of the random forest model\n",
    "    mei_y_pred = model.predict(X[mei_search_inds]) # Predictions for the unknown materials\n",
    "    \n",
    "    # Append the value we find with the Acquisition function\n",
    "    mei_train_inds.append(mei_search_inds[np.argmax(mei_y_pred)]) # Information Acquisition Function choice and addition to current set\n",
    "    mei_train.append(mei_train_inds) # Storage of the current set per step    \n",
    "    # Store the evolution of the training indexes for plotting\n",
    " \n",
    "    # Maximum Likelihood of Improvement\n",
    "    \n",
    "    mli_train_inds = mli_train[-1].copy()  \n",
    "    mli_search_inds = list(all_inds.difference(mli_train_inds))\n",
    "    \n",
    "    model.fit(X[mli_train_inds], y[mli_train_inds])\n",
    "    mli_y_pred, mli_y_std = model.predict(X[mli_search_inds], return_std=True)\n",
    "    \n",
    "    mli_train_inds.append(mli_search_inds[np.argmax(np.divide(mli_y_pred - np.max(y[mli_train_inds]), mli_y_std))])\n",
    "    mli_train.append(mli_train_inds)\n",
    "    \n",
    "    # Maximum Uncertainty\n",
    "    \n",
    "    mu_train_inds = mu_train[-1].copy()  \n",
    "    mu_search_inds = list(all_inds.difference(mu_train_inds))\n",
    "    \n",
    "    model.fit(X[mu_train_inds], y[mu_train_inds])\n",
    "    mu_y_pred, mu_y_std = model.predict(X[mu_search_inds], return_std=True)\n",
    "    \n",
    "    mu_train_inds.append(mu_search_inds[np.argmax(mu_y_std)])\n",
    "    mu_train.append(mu_train_inds)\n",
    "    \n",
    "    # Upper Conf Bound\n",
    "    \n",
    "    ucb_train_inds = ucb_train[-1].copy()  \n",
    "    ucb_search_inds = list(all_inds.difference(ucb_train_inds))\n",
    "    \n",
    "    model.fit(X[ucb_train_inds], y[ucb_train_inds])\n",
    "    ucb_y_pred, ucb_y_std = model.predict(X[ucb_search_inds], return_std=True)\n",
    "    \n",
    "    ucb_train_inds.append(ucb_search_inds[np.argmax([sum(x) for x in zip(ucb_y_pred, ucb_y_std)])])\n",
    "    ucb_train.append(ucb_train_inds)\n",
    "    \n",
    "    # RANDOM\n",
    "    \n",
    "    random_train_inds = random_train[-1].copy()    # Initial Set (In the first run) / Current Set (From last iteration, after the first run)\n",
    "    random_search_inds = list(all_inds.difference(random_train_inds)) # All samples not in the current set\n",
    "\n",
    "    model.fit(X[random_train_inds], y[random_train_inds]) # Training\n",
    "    random_y_pred = model.predict(X[random_search_inds]) # Predictions\n",
    "    \n",
    "    random_train_inds.append(np.random.choice(random_search_inds)) # Information Acquisition Function choice and addition to current set\n",
    "    random_train.append(random_train_inds) # Storage of the current set per step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --user ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we present an interactive plot that shows how the approaches get to the maximum value and how the selection per experiment is distributed across the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output, HTML, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from matplotlib import animation, rc\n",
    "#plt.rcParams['animation.writer'] = '/home/nanohub/bbishnoi/.local/lib/python3.8/site-packages/ffmpeg'\n",
    "#plt.rcParams['animation.ffmpeg_path'] = '/home/nanohub/bbishnoi/.local/lib/python3.8/site-packages/ffmpeg'\n",
    "#plt.rcParams['animation.writer'] = '/apps/share64/debian7/anaconda/anaconda-6/bin/ffmpeg'\n",
    "#plt.rcParams['animation.ffmpeg_path'] = '/apps/share64/debian7/anaconda/anaconda-6/bin/ffmpeg'\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,6,figsize=(30,8))\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.4, hspace=None)\n",
    "\n",
    "# FIRST PLOT, Approach lines\n",
    "\n",
    "random_line, = ax[0].plot([], [], color='green', label='Random')\n",
    "mei_line, = ax[0].plot([], [], color='blue', label='MEI')\n",
    "mli_line, = ax[0].plot([], [], color='red', label='MLI')\n",
    "mu_line, = ax[0].plot([], [], color='purple', label='MU')\n",
    "ucb_line, = ax[0].plot([], [], color='orange', label='UCB')\n",
    "max_line, = ax[0].plot(range(n_steps), [max(y) for m in range(n_steps)], '--', color='black', label='Max Value')\n",
    "\n",
    "random_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='green')\n",
    "mei_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='blue')\n",
    "mli_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='red')\n",
    "mu_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='purple')\n",
    "ucb_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='orange')\n",
    "\n",
    "ax[0].legend(loc=4, prop={'size': 12})\n",
    "ax[0].grid()\n",
    "ax[0].set_title(\"Number of Experiments\", fontsize=24)\n",
    "ax[0].set_xlabel(\"Number of Experiments\", fontsize=16)\n",
    "ax[0].set_ylabel(\"Max\"+ property_interest, fontsize=16)\n",
    "mli_line.axes.axis([0, n_steps-1, 0, 1.1*max(y)])\n",
    "mli_line.axes.get_yaxis().set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "# SECOND PLOT, Random Prediction\n",
    "\n",
    "all_values_samples = ax[1].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "random_reallabel = [y[index] for index in random_train_inds]\n",
    "\n",
    "random_initial_set = ax[1].plot(random_train_inds[:entry_number_init], random_reallabel[:entry_number_init], color='black', marker='o', linestyle= 'None',  markersize=10, label = 'Initial Set')\n",
    "\n",
    "random_sample_real, = ax[1].plot([], [], color='green', marker='o', linestyle= 'None',  markersize=10, label = 'Tests')\n",
    "random_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "random_sample_real.axes.get_xaxis().set_ticks([])\n",
    "random_sample_real.axes.get_yaxis().set_tick_params(labelsize=14)\n",
    "\n",
    "ax[1].legend(bbox_to_anchor=(0.8, 0.1), prop={'size': 12})\n",
    "ax[1].grid()\n",
    "ax[1].set_title(\"Random\", fontsize=24)\n",
    "ax[1].set_xlabel(\"Test Candidates\", fontsize=16)\n",
    "ax[1].set_ylabel(property_interest, fontsize=16)\n",
    "\n",
    "#THIRD PLOT, MEI Prediction\n",
    "\n",
    "all_values_samples = ax[2].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "mei_reallabel = [y[index] for index in mei_train_inds]\n",
    "\n",
    "mei_initial_set = ax[2].plot(mei_train_inds[:entry_number_init], mei_reallabel[:entry_number_init], color='black', marker='o',linestyle= 'None',   markersize=10, label = 'Initial Set')\n",
    "\n",
    "mei_sample_real, = ax[2].plot([], [], color='blue', marker='o', linestyle= 'None',  markersize=10, label = 'Tests')\n",
    "mei_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "mei_sample_real.axes.get_xaxis().set_ticks([])\n",
    "mei_sample_real.axes.get_yaxis().set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax[2].legend(bbox_to_anchor=(0.8, 0.1), prop={'size': 12})\n",
    "ax[2].grid()\n",
    "ax[2].set_title(\"MEI\", fontsize=24)\n",
    "ax[2].set_xlabel(\"Test Candidates\", fontsize=16)\n",
    "ax[2].set_ylabel(property_interest, fontsize=16)\n",
    "\n",
    "# 4th PLOT, MLI Prediction\n",
    "\n",
    "all_values_samples = ax[3].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "mli_reallabel = [y[index] for index in mli_train_inds]\n",
    "\n",
    "mli_initial_set = ax[3].plot(mli_train_inds[:entry_number_init], mli_reallabel[:entry_number_init], color='black', marker='o', linestyle= 'None',  markersize=10, label = 'Initial Set')\n",
    "mli_sample_real, = ax[3].plot([], [], color='red', marker='o', linestyle= 'None',  markersize=10, label = 'Tests')\n",
    "mli_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "mli_sample_real.axes.get_xaxis().set_ticks([])\n",
    "mli_sample_real.axes.get_yaxis().set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax[3].legend(bbox_to_anchor=(0.8, 0.1), prop={'size': 12})\n",
    "ax[3].grid()\n",
    "ax[3].set_title(\"MLI\", fontsize=24)\n",
    "ax[3].set_xlabel(\"Test Candidates\", fontsize=16)\n",
    "ax[3].set_ylabel(property_interest, fontsize=16)\n",
    "\n",
    "\n",
    "# 5th plot, MU Prediction\n",
    "\n",
    "all_values_samples = ax[4].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "mu_reallabel = [y[index] for index in mu_train_inds]\n",
    "\n",
    "# Create an empty plot that will be updated.\n",
    "mu_initial_set = ax[4].plot(mu_train_inds[:entry_number_init], mu_reallabel[:entry_number_init], color='black', marker='o', linestyle= 'None',  markersize=10, label = 'Initial Set')\n",
    "#Note the variable syntax that includes a comma\n",
    "mu_sample_real, = ax[4].plot([], [], color='purple', marker='o', linestyle= 'None',  markersize=10, label = 'Tests')\n",
    "mu_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "mu_sample_real.axes.get_xaxis().set_ticks([])\n",
    "mu_sample_real.axes.get_yaxis().set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax[4].legend(bbox_to_anchor=(0.8, 0.1), prop={'size': 12})\n",
    "ax[4].grid()\n",
    "ax[4].set_title(\"MU\", fontsize=24)\n",
    "ax[4].set_xlabel(\"Test Candidates\", fontsize=16)\n",
    "ax[4].set_ylabel(property_interest, fontsize=16)\n",
    "\n",
    "# 6th plot, UCB Prediction\n",
    "\n",
    "all_values_samples = ax[5].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "ucb_reallabel = [y[index] for index in ucb_train_inds]\n",
    "\n",
    "ucb_initial_set = ax[5].plot(ucb_train_inds[:entry_number_init], ucb_reallabel[:entry_number_init], color='black', marker='o', linestyle= 'None',  markersize=10, label = 'Initial Set')\n",
    "ucb_sample_real, = ax[5].plot([], [], color='orange', marker='o', linestyle= 'None',  markersize=10, label = 'Tests')\n",
    "ucb_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "ucb_sample_real.axes.get_xaxis().set_ticks([])\n",
    "ucb_sample_real.axes.get_yaxis().set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax[5].legend(bbox_to_anchor=(0.8, 0.1), prop={'size': 12})\n",
    "ax[5].grid()\n",
    "ax[5].set_title(\"UCB\", fontsize=24)\n",
    "ax[5].set_xlabel(\"Test Candidates\", fontsize=16)\n",
    "ax[5].set_ylabel(property_interest, fontsize=16)\n",
    "\n",
    "#################################################\n",
    "\n",
    "def update(num):\n",
    "    #Number of frames = experiment\n",
    "    if num > 0:\n",
    "        \n",
    "        random_graph = [max(y[list(t)]) for t in random_train[:num]]   # This keeps track of our highest value\n",
    "        if max(y) in random_graph:   #If we find the max, we stop updating the plots\n",
    "            chk_index = [i for i, j in enumerate(random_graph) if j == max(y)][0]\n",
    "            random_line.set_data(np.arange(len(random_train))[:chk_index+1], [max(y[list(t)]) for t in random_train[:chk_index+1]])\n",
    "            random_chk.set_data(chk_index, max(random_graph))  #Put a ★ at max value\n",
    "        else:\n",
    "            random_line.set_data(np.arange(len(random_train))[:num], random_graph)\n",
    "            random_sample_real.set_data(random_train_inds[entry_number_init:entry_number_init+num], random_reallabel[entry_number_init:entry_number_init+num]) #Here we set the data  in our empty plot\n",
    "        \n",
    "        mei_graph = [max(y[list(t)]) for t in mei_train[:num]]\n",
    "        if max(y) in mei_graph:\n",
    "            chk_index = [i for i, j in enumerate(mei_graph) if j == max(y)][0]\n",
    "            mei_line.set_data(np.arange(len(mei_train))[:chk_index+1], [max(y[list(t)]) for t in mei_train[:chk_index+1]])\n",
    "            mei_chk.set_data(chk_index, max(mei_graph))\n",
    "        else:\n",
    "            mei_line.set_data(np.arange(len(mei_train))[:num], mei_graph)\n",
    "            mei_sample_real.set_data(mei_train_inds[entry_number_init:entry_number_init+num], mei_reallabel[entry_number_init:entry_number_init+num])\n",
    "        \n",
    "        mli_graph = [max(y[list(t)]) for t in mli_train[:num]]\n",
    "        if max(y) in mli_graph:\n",
    "            chk_index = [i for i, j in enumerate(mli_graph) if j == max(y)][0]\n",
    "            mli_line.set_data(np.arange(len(mli_train))[:chk_index+1], [max(y[list(t)]) for t in mli_train[:chk_index+1]])\n",
    "            mli_chk.set_data(chk_index, max(mli_graph))\n",
    "        else:\n",
    "            mli_line.set_data(np.arange(len(mli_train))[:num], mli_graph)\n",
    "            mli_sample_real.set_data(mli_train_inds[entry_number_init:entry_number_init+num], mli_reallabel[entry_number_init:entry_number_init+num])          \n",
    "            \n",
    "        mu_graph = [max(y[list(t)]) for t in mu_train[:num]]\n",
    "        if max(y) in mu_graph:\n",
    "            chk_index = [i for i, j in enumerate(mu_graph) if j == max(y)][0]\n",
    "            mu_line.set_data(np.arange(len(mu_train))[:chk_index+1], [max(y[list(t)]) for t in mu_train[:chk_index+1]])\n",
    "            mu_chk.set_data(chk_index, max(mu_graph))\n",
    "        else:\n",
    "            mu_line.set_data(np.arange(len(mu_train))[:num], mu_graph)\n",
    "            mu_sample_real.set_data(mu_train_inds[entry_number_init:entry_number_init+num], mu_reallabel[entry_number_init:entry_number_init+num])   \n",
    "\n",
    "            \n",
    "        ucb_graph = [max(y[list(t)]) for t in ucb_train[:num]]\n",
    "        if max(y) in ucb_graph:\n",
    "            chk_index = [i for i, j in enumerate(ucb_graph) if j == max(y)][0]\n",
    "            ucb_line.set_data(np.arange(len(ucb_train))[:chk_index+1], [max(y[list(t)]) for t in ucb_train[:chk_index+1]])\n",
    "            ucb_chk.set_data(chk_index, max(ucb_graph))\n",
    "        else:\n",
    "            ucb_line.set_data(np.arange(len(ucb_train))[:num], ucb_graph)\n",
    "            ucb_sample_real.set_data(ucb_train_inds[entry_number_init:entry_number_init+num], ucb_reallabel[entry_number_init:entry_number_init+num])\n",
    "            \n",
    "        return random_line, mei_line, mli_line, mu_line, ucb_line, random_sample_real, mei_sample_real,mli_sample_real, mu_sample_real, ucb_sample_real, mli_chk, mei_chk, random_chk, mu_chk, ucb_chk\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update, frames=len(random_train), interval=600, blit=False, repeat = False) ## Experiments len(random_train)\n",
    "# This function merges the plot and the update function \n",
    "#ani = matplotlib.animation.FuncAnimation(fig, update, frames=len(random_train), interval=600, blit=False, repeat = False)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "#HTML(anim.to_html5_video()) \n",
    "#HTML(ani.to_html5_video())\n",
    "HTML(anim.to_jshtml())\n",
    "#This function turns the animation into a video for display\n",
    "#anim.to_html5_video()\n",
    "\n",
    "#FFwriter=animation.FFMpegWriter(fps=10, extra_args=['-vcodec', 'libx264'])\n",
    "#anim.save('noise.mp4', writer=FFwriter, fps=10, dpi=100, metadata={'title':'test'})\n",
    "#anim.save('basic_animation.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "#anim.save('basic_animation.mp4', writer = FFwriter, fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "#im_ani.save('im.mp4', writer=writer)\n",
    "#anim.save('dynamic_images.png')\n",
    "#anim.save('dynamic_images.mp4')\n",
    "#plt.close(fig)\n",
    "\n",
    "\n",
    "# We can find our best performing candidate using 30% of the experiments of what it would take randomly choosing from our po\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this notebook we present a static version of the plot from the main notebook, for publication purposes.\n",
    "\n",
    "fig, ax = plt.subplots(2,3,figsize=(18,14))\n",
    "ax = ax.flatten()\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=0.4)\n",
    "\n",
    "# FIRST PLOT, Approach lines\n",
    "\n",
    "random_line, = ax[0].plot([], [], color='green', label='Random')\n",
    "mei_line, = ax[0].plot([], [], color='blue', label='MEI')\n",
    "mli_line, = ax[0].plot([], [], color='red', label='MLI')\n",
    "mu_line, = ax[0].plot([], [], color='purple', label='MU')\n",
    "ucb_line, = ax[0].plot([], [], color='orange', label='UCB')\n",
    "max_line, = ax[0].plot(range(n_steps), [max(y) for m in range(n_steps)], '--', color='black', label='Maximum Value')\n",
    "\n",
    "random_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='green')\n",
    "mei_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='blue')\n",
    "mli_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='red')\n",
    "mu_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='purple')\n",
    "ucb_chk, = ax[0].plot([], [], markersize=10, marker='*', linestyle='None', color='orange')\n",
    "\n",
    "# ax0leg = ax[0].legend(loc=4, prop={'size': 12})\n",
    "# ax0leg.get_frame().set_edgecolor('k')\n",
    "\n",
    "\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(\"Number of Experiments\", fontsize=24)\n",
    "ax[0].set_ylabel(\"Maximum \"+ property_interest, fontsize=24)\n",
    "mli_line.axes.axis([0, n_steps-1, 0, 1.1*max(y)])\n",
    "\n",
    "mli_line.axes.get_yaxis().set_tick_params(labelsize=20)\n",
    "mli_line.axes.get_xaxis().set_tick_params(labelsize=20)\n",
    "\n",
    "\n",
    "mei_line.axes.get_yaxis().set_tick_params(labelsize=20)\n",
    "mu_line.axes.get_yaxis().set_tick_params(labelsize=20)\n",
    "random_line.axes.get_yaxis().set_tick_params(labelsize=20)\n",
    "ucb_line.axes.get_yaxis().set_tick_params(labelsize=20)\n",
    "\n",
    "# SECOND PLOT, Random Prediction\n",
    "\n",
    "all_values_samples = ax[5].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "random_reallabel = [y[index] for index in random_train_inds]\n",
    "\n",
    "random_initial_set = ax[5].plot(random_train_inds[:entry_number_init], random_reallabel[:entry_number_init], color='black', marker='o', linestyle= 'None',  markersize=10, label = 'Initial Set')\n",
    "\n",
    "\n",
    "# ax5leg = ax[5].legend(prop={'size': 12})\n",
    "# ax5leg.get_frame().set_edgecolor('k')\n",
    "\n",
    "ax[5].grid()\n",
    "ax[5].set_title(\"Random\", fontsize=26)\n",
    "ax[5].set_xlabel(\"Test Candidates\", fontsize=24)\n",
    "ax[5].set_ylabel(property_interest, fontsize=24)\n",
    "\n",
    "\n",
    "#THIRD PLOT, MEI Prediction\n",
    "\n",
    "all_values_samples = ax[1].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "mei_reallabel = [y[index] for index in mei_train_inds]\n",
    "\n",
    "mei_initial_set = ax[1].plot(mei_train_inds[:entry_number_init], mei_reallabel[:entry_number_init], color='black', marker='o',linestyle= 'None',   markersize=10, label = 'Initial Set')\n",
    "\n",
    "# ax1leg = ax[1].legend(prop={'size': 12})\n",
    "# ax1leg.get_frame().set_edgecolor('k')\n",
    "\n",
    "ax[1].grid()\n",
    "ax[1].set_title(\"Maximum Expected \\n Improvement (MEI)\", fontsize=26)\n",
    "ax[1].set_xlabel(\"Test Candidates\", fontsize=24)\n",
    "ax[1].set_ylabel(property_interest, fontsize=24)\n",
    "\n",
    "# 4th PLOT, MLI Prediction\n",
    "\n",
    "all_values_samples = ax[3].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "mli_reallabel = [y[index] for index in mli_train_inds]\n",
    "\n",
    "mli_initial_set = ax[3].plot(mli_train_inds[:entry_number_init], mli_reallabel[:entry_number_init], color='black', marker='o', linestyle= 'None',  markersize=10, label = 'Initial Set')\n",
    "\n",
    "# ax3leg = ax[3].legend(prop={'size': 12})\n",
    "# ax3leg.get_frame().set_edgecolor('k')\n",
    "\n",
    "ax[3].grid()\n",
    "ax[3].set_title(\"Maximum Likelihood \\n of Improvement (MLI)\", fontsize=26)\n",
    "ax[3].set_xlabel(\"Test Candidates\", fontsize=24)\n",
    "ax[3].set_ylabel(property_interest, fontsize=24)\n",
    "\n",
    "\n",
    "# 5th plot, MU Prediction\n",
    "\n",
    "all_values_samples = ax[4].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "mu_reallabel = [y[index] for index in mu_train_inds]\n",
    "\n",
    "mu_initial_set = ax[4].plot(mu_train_inds[:entry_number_init], mu_reallabel[:entry_number_init], color='black', marker='o', linestyle= 'None',  markersize=10, label = 'Initial Set')\n",
    "\n",
    "\n",
    "\n",
    "# ax4leg = ax[4].legend(prop={'size': 12})\n",
    "# ax4leg.get_frame().set_edgecolor('k')\n",
    "\n",
    "ax[4].grid()\n",
    "ax[4].set_title(\"Maximum \\n Uncertainty (MU)\", fontsize=26)\n",
    "ax[4].set_xlabel(\"Test Candidates\", fontsize=24)\n",
    "ax[4].set_ylabel(property_interest, fontsize=24)\n",
    "\n",
    "# 6th plot, UCB Prediction\n",
    "\n",
    "all_values_samples = ax[2].plot(list(all_inds), y, marker='o', alpha=0.2, color='gray', linestyle='None', markersize=10, label='Values')\n",
    "\n",
    "ucb_reallabel = [y[index] for index in ucb_train_inds]\n",
    "\n",
    "ucb_initial_set = ax[2].plot(ucb_train_inds[:entry_number_init], ucb_reallabel[:entry_number_init], color='black', marker='o', linestyle= 'None',  markersize=10, label = 'Initial Set')\n",
    "\n",
    "\n",
    "# ax2leg = ax[2].legend(prop={'size': 12})\n",
    "# ax2leg.get_frame().set_edgecolor('k')\n",
    "\n",
    "ax[2].grid()\n",
    "ax[2].set_title(\"Upper Confidence \\n Bound (UCB)\", fontsize=26)\n",
    "ax[2].set_xlabel(\"Test Candidates\", fontsize=24)\n",
    "ax[2].set_ylabel(property_interest, fontsize=24)\n",
    "\n",
    "#################################################\n",
    "\n",
    "num=90\n",
    "\n",
    "\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "if num > 0:\n",
    "\n",
    "    random_graph = [max(y[list(t)]) for t in random_train[:num]]\n",
    "    chk_index = [i for i, j in enumerate(random_graph) if j == max(y)][0]\n",
    "    random_line.set_data(np.arange(len(random_train))[:chk_index+1], [max(y[list(t)]) for t in random_train[:chk_index+1]])\n",
    "    random_chk.set_data(chk_index, max(random_graph))\n",
    "    \n",
    "    a = list(enumerate(random_train_inds[entry_number_init:entry_number_init+chk_index]))\n",
    "    a = [_[0] for _ in a]\n",
    "    \n",
    "    n = len(a)\n",
    "    colors = np.array(pl.cm.Greens(np.linspace(0,1,n)))\n",
    " \n",
    "    random_sample_real = ax[5].scatter(random_train_inds[entry_number_init:entry_number_init+chk_index], random_reallabel[entry_number_init:entry_number_init+chk_index], c=colors, marker='o', s=100,linestyle= 'None', label = 'Tests')\n",
    "    random_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "    random_sample_real.axes.get_xaxis().set_ticks([])\n",
    "    random_sample_real.axes.get_yaxis().set_tick_params(labelsize=20)\n",
    "    \n",
    "    \n",
    "    mei_graph = [max(y[list(t)]) for t in mei_train[:num]]\n",
    "    chk_index = [i for i, j in enumerate(mei_graph) if j == max(y)][0]\n",
    "    mei_line.set_data(np.arange(len(mei_train))[:chk_index+1], [max(y[list(t)]) for t in mei_train[:chk_index+1]])\n",
    "    mei_chk.set_data(chk_index, max(mei_graph))\n",
    "    \n",
    "    a = list(enumerate(mei_train_inds[entry_number_init:entry_number_init+chk_index]))\n",
    "    a = [_[0] for _ in a]\n",
    "    \n",
    "    n = len(a)\n",
    "    colors = np.array(pl.cm.Blues(np.linspace(0,1,n)))    \n",
    "    \n",
    "    mei_sample_real = ax[1].scatter(mei_train_inds[entry_number_init:entry_number_init+chk_index], mei_reallabel[entry_number_init:entry_number_init+chk_index], c=colors, marker='o', s=100,linestyle= 'None', label = 'Tests')\n",
    "    mei_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "    mei_sample_real.axes.get_xaxis().set_ticks([])\n",
    "    mei_sample_real.axes.get_yaxis().set_tick_params(labelsize=20)\n",
    "    \n",
    "    \n",
    "\n",
    "    mli_graph = [max(y[list(t)]) for t in mli_train[:num]]\n",
    "    chk_index = [i for i, j in enumerate(mli_graph) if j == max(y)][0]\n",
    "    mli_line.set_data(np.arange(len(mli_train))[:chk_index+1], [max(y[list(t)]) for t in mli_train[:chk_index+1]])\n",
    "    mli_chk.set_data(chk_index, max(mli_graph))\n",
    "\n",
    "    \n",
    "    a = list(enumerate(mli_train_inds[entry_number_init:entry_number_init+chk_index]))\n",
    "    a = [_[0] for _ in a]\n",
    "    \n",
    "    n = len(a)\n",
    "    colors = np.array(pl.cm.Reds(np.linspace(0,1,n)))    \n",
    "    \n",
    "    mli_sample_real = ax[3].scatter(mli_train_inds[entry_number_init:entry_number_init+chk_index], mli_reallabel[entry_number_init:entry_number_init+chk_index], c=colors, marker='o', s=100,linestyle= 'None', label = 'Tests') \n",
    "    mli_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "    mli_sample_real.axes.get_xaxis().set_ticks([])\n",
    "    mli_sample_real.axes.get_yaxis().set_tick_params(labelsize=20)    \n",
    "    \n",
    "\n",
    "    mu_graph = [max(y[list(t)]) for t in mu_train[:num]]\n",
    "    chk_index = [i for i, j in enumerate(mu_graph) if j == max(y)][0]\n",
    "    mu_line.set_data(np.arange(len(mu_train))[:chk_index+1], [max(y[list(t)]) for t in mu_train[:chk_index+1]])\n",
    "    mu_chk.set_data(chk_index, max(mu_graph))\n",
    "    \n",
    "    a = list(enumerate(mu_train_inds[entry_number_init:entry_number_init+chk_index]))\n",
    "    a = [_[0] for _ in a]\n",
    "    \n",
    "    n = len(a)\n",
    "    colors = np.array(pl.cm.Purples(np.linspace(0,1,n)))     \n",
    "    \n",
    "    mu_sample_real = ax[4].scatter(mu_train_inds[entry_number_init:entry_number_init+chk_index], mu_reallabel[entry_number_init:entry_number_init+chk_index], c=colors, marker='o', s=100,linestyle= 'None', label = 'Tests') \n",
    "    mu_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "    mu_sample_real.axes.get_xaxis().set_ticks([])\n",
    "    mu_sample_real.axes.get_yaxis().set_tick_params(labelsize=20)    \n",
    "    \n",
    "    \n",
    "    ucb_graph = [max(y[list(t)]) for t in ucb_train[:num]]\n",
    "    chk_index = [i for i, j in enumerate(ucb_graph) if j == max(y)][0]\n",
    "    ucb_line.set_data(np.arange(len(ucb_train))[:chk_index+1], [max(y[list(t)]) for t in ucb_train[:chk_index+1]])\n",
    "    ucb_chk.set_data(chk_index, max(ucb_graph))\n",
    "    \n",
    "    \n",
    "    a = list(enumerate(ucb_train_inds[entry_number_init:entry_number_init+chk_index]))\n",
    "    a = [_[0] for _ in a]\n",
    "    \n",
    "    n = len(a)\n",
    "    colors = np.array(pl.cm.YlOrBr(np.linspace(0,1,n)))     \n",
    "    \n",
    "    ucb_sample_real = ax[2].scatter(ucb_train_inds[entry_number_init:entry_number_init+chk_index], ucb_reallabel[entry_number_init:entry_number_init+chk_index], c=colors, marker='o', s=100,linestyle= 'None', label = 'Tests') \n",
    "    ucb_sample_real.axes.axis([0, len(y), 0, 1.1*max(y)])\n",
    "    ucb_sample_real.axes.get_xaxis().set_ticks([])\n",
    "    ucb_sample_real.axes.get_yaxis().set_tick_params(labelsize=20)    \n",
    "\n",
    "fig.show()\n",
    "#anim.save('dynamic_images.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_values.copy()\n",
    "y = all_labels.copy()\n",
    "\n",
    "entry_number_init = 10\n",
    "in_train = np.zeros(len(data), dtype=np.bool)\n",
    "oldest = np.argpartition(years, entry_number_init)\n",
    "display(data.loc[oldest,['chemicalFormula', 'Year Published']].head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_trials = []\n",
    "mei_trials = []\n",
    "mli_trials = []\n",
    "ucb_trials = []\n",
    "mu_trials = []\n",
    "\n",
    "np.random.seed(2) # Random Seed\n",
    "\n",
    "trial = 0\n",
    "\n",
    "while trial < 30:\n",
    "    \n",
    "    model = RandomForestRegressor(num_trees=500)\n",
    "\n",
    "    #Set up a new model with a small initial set.\n",
    "    entry_number_init = 10\n",
    "    \n",
    "    # -----\n",
    "    #Create a list True/False for the entries.\n",
    "    # Choose some indexes and turn them to True, making sure not to include the maximum value\n",
    "    in_train = np.zeros(len(data), dtype=np.bool)\n",
    "    oldest = np.argpartition(years, entry_number_init)\n",
    "    in_train[oldest[:entry_number_init]] = True\n",
    "    print('Picked {} training entries'.format(in_train.sum()))\n",
    "     \n",
    "    # -----    \n",
    "    \n",
    "#     in_train = np.zeros(len(data), dtype=np.bool)\n",
    "#     in_train[np.random.choice(len(data), entry_number_init, replace=False)] = True\n",
    "#     print('Picked {} training entries'.format(in_train.sum()))\n",
    "    \n",
    "    if not (np.isclose(max(y), max(y[in_train]))):\n",
    "        trial += 1\n",
    "    else: \n",
    "        continue\n",
    "\n",
    "    model.fit(X[in_train], y[in_train])\n",
    "    y_pred, y_std = model.predict(X[~in_train], return_std=True)\n",
    "\n",
    "    print(trial)\n",
    "    n_steps = 90\n",
    "    all_inds = set(range(len(y)))\n",
    "\n",
    "    random_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "    mei_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "    mli_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "    mu_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "    ucb_train = [list(set(np.where(in_train)[0].tolist()))]\n",
    "    random_train_inds = []\n",
    "    mei_train_inds = []\n",
    "    mli_train_inds = []\n",
    "    ucb_train_inds = []\n",
    "\n",
    "\n",
    "    for i in range(n_steps):\n",
    "\n",
    "        # RANDOM\n",
    "\n",
    "        random_train_inds = random_train[-1].copy()\n",
    "\n",
    "        random_search_inds = list(all_inds.difference(random_train_inds))\n",
    "\n",
    "        model.fit(X[random_train_inds], y[random_train_inds])\n",
    "        random_y_pred = model.predict(X[random_search_inds])\n",
    "\n",
    "        random_train_inds.append(np.random.choice(random_search_inds))\n",
    "        random_train.append(random_train_inds)\n",
    "\n",
    "        # Maximum Expected Improvement\n",
    "\n",
    "        mei_train_inds = mei_train[-1].copy()    \n",
    "        mei_search_inds = list(all_inds.difference(mei_train_inds))\n",
    "\n",
    "        # Pick entry with the largest maximum value\n",
    "        model.fit(X[mei_train_inds], y[mei_train_inds])\n",
    "        mei_y_pred = model.predict(X[mei_search_inds])\n",
    "\n",
    "        mei_train_inds.append(mei_search_inds[np.argmax(mei_y_pred)])\n",
    "        mei_train.append(mei_train_inds)\n",
    "\n",
    "        # Maximum Likelihood of Improvement\n",
    "\n",
    "        mli_train_inds = mli_train[-1].copy()  # Last iteration\n",
    "        mli_search_inds = list(all_inds.difference(mli_train_inds))\n",
    "\n",
    "        # Pick entry with the largest maximum value\n",
    "        model.fit(X[mli_train_inds], y[mli_train_inds])\n",
    "        mli_y_pred, mli_y_std = model.predict(X[mli_search_inds], return_std=True)\n",
    "        mli_train_inds.append(mli_search_inds[np.argmax(np.divide(mli_y_pred - np.max(y[mli_train_inds]), mli_y_std))])\n",
    "        mli_train.append(mli_train_inds)\n",
    "\n",
    "        # Maximum Uncertainty\n",
    "\n",
    "        mu_train_inds = mu_train[-1].copy()  # Last iteration\n",
    "        mu_search_inds = list(all_inds.difference(mu_train_inds))\n",
    "\n",
    "        # Pick entry with the largest maximum value\n",
    "        model.fit(X[mu_train_inds], y[mu_train_inds])\n",
    "        mu_y_pred, mu_y_std = model.predict(X[mu_search_inds], return_std=True)\n",
    "        mu_train_inds.append(mu_search_inds[np.argmax(mu_y_std)])\n",
    "        mu_train.append(mu_train_inds)\n",
    "\n",
    "        # Upper Conf Bound\n",
    "\n",
    "        ucb_train_inds = ucb_train[-1].copy()  # Last iteration\n",
    "        ucb_search_inds = list(all_inds.difference(ucb_train_inds))\n",
    "\n",
    "        # Pick entry with the largest maximum value\n",
    "        model.fit(X[ucb_train_inds], y[ucb_train_inds])\n",
    "        ucb_y_pred, ucb_y_std = model.predict(X[ucb_search_inds], return_std=True)\n",
    "        ucb_train_inds.append(ucb_search_inds[np.argmax([sum(x) for x in zip(ucb_y_pred, ucb_y_std)])])\n",
    "        ucb_train.append(ucb_train_inds)\n",
    "\n",
    "    if np.max(y[random_train_inds]) == np.max(y):\n",
    "        random_trials.append(np.argmax(y[random_train_inds][10:])+1)\n",
    "    else:\n",
    "        random_trials.append(n_steps)\n",
    "\n",
    "    if np.max(y[mei_train_inds]) == np.max(y):\n",
    "        mei_trials.append(np.argmax(y[mei_train_inds][10:])+1)\n",
    "    else:\n",
    "        mei_trials.append(n_steps)\n",
    "\n",
    "    if np.max(y[mli_train_inds]) == np.max(y):\n",
    "        mli_trials.append(np.argmax(y[mli_train_inds][10:])+1)\n",
    "    else:\n",
    "        mli_trials.append(n_steps)\n",
    "\n",
    "    if np.max(y[ucb_train_inds]) == np.max(y):\n",
    "        ucb_trials.append(np.argmax(y[ucb_train_inds][10:])+1)\n",
    "    else:\n",
    "        ucb_trials.append(n_steps)\n",
    "\n",
    "    if np.max(y[mu_train_inds]) == np.max(y):\n",
    "        mu_trials.append(np.argmax(y[mu_train_inds][10:])+1)\n",
    "    else:\n",
    "        mu_trials.append(n_steps)\n",
    "        \n",
    "print(\"Random\", random_trials)\n",
    "print(\"MEI\", mei_trials)\n",
    "print(\"MLI\", mli_trials)\n",
    "print(\"UCB\", ucb_trials)\n",
    "print(\"MU\", mu_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Values are listed explicitly here because the previous cell takes a lot of time to run (30 minutes). You can comment these out and work with the variables directly from the cell above.\n",
    "\n",
    "random_trials = [17, 39, 23, 41, 65, 23, 65, 32, 62, 36, 14, 76, 11, 59, 56, 79, 50, 33, 61, 19, 81, 46, 51, 71, 69, 6, 79, 39, 5, 6]\n",
    "mei_trials =  [13, 11, 13, 13, 9, 12, 9, 11, 12, 8, 13, 12, 11, 8, 5, 13, 13, 13, 12, 9, 9, 13, 13, 13, 9, 13, 8, 16, 16, 9]\n",
    "mli_trials =  [3, 12, 2, 17, 12, 12, 3, 13, 3, 12, 17, 13, 3, 14, 12, 12, 3, 15, 16, 13, 3, 11, 14, 17, 3, 15, 4, 13, 3, 12]\n",
    "ucb_trials =  [14, 14, 4, 13, 3, 10, 13, 12, 4, 10, 4, 11, 4, 14, 11, 15, 10, 14, 11, 15, 15, 10, 4, 11, 4, 14, 10, 14, 14, 11]\n",
    "mu_trials = [9, 17, 24, 24, 33, 29, 27, 10, 30, 45, 28, 25, 31, 11, 33, 26, 9, 23, 25, 28, 24, 29, 31, 25, 31, 23, 11, 25, 22, 25]\n",
    "\n",
    "objects = ('MLI', 'UCB', 'MEI', 'MU', 'Random')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "performance = [np.mean(mli_trials),np.mean(ucb_trials),np.mean(mei_trials),np.mean(mu_trials),np.mean(random_trials)]\n",
    "uncertainty = [np.std(mli_trials),np.std(ucb_trials), np.std(mei_trials), np.std(mu_trials),np.std(random_trials)]\n",
    "uncertainty_adj = [x/np.sqrt(30) for x in uncertainty]\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "plt.bar(y_pos, performance, yerr=uncertainty_adj, color=['red', 'orange', 'blue', 'purple', 'green'], align='center', alpha=0.5)\n",
    "plt.axhline(y=45 , linestyle= 'dashed' , linewidth=3, color='gray')\n",
    "plt.xticks(y_pos, objects, fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.ylim([0,60])\n",
    "plt.ylabel('Number of Experiments', fontsize=28)\n",
    "#plt.title('Information Acquistion Functions', fontsize=18)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(\"design_experiment.png\", scale=1, width=600, height=350)\n",
    "#plt.write_image(fig, \"./design_experiment.png\", scale=1, width=600, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Garnet Predictor for codoped LLZO\n",
    "In this section we create a garnet predictor based on all of our training data. It is important to note that these predictions are for an untested region of candidates, and because of the limited data and the inability of random forests to extrapolate, should not be understood with those caveats and not taken as all encompassing predictions. Results from this figure might vary because of the inner initialization of the random forest model, but their intention is to show the limited predicted capabilities of the models by themselves, which can help us motivate the use of active learning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function predicts the color-intensity plot taking the model, dopants and relevant substitutions.\n",
    "\n",
    "def prediction_surface_dualdoped(model, first_dopant, first_dopant_range, second_dopant, second_dopant_range, first_lithium_replace, first_lanthanum_replace, first_zirconium_replace, second_lithium_replace, second_lanthanum_replace, second_zirconium_replace):\n",
    "\n",
    "    # Grid of compositions\n",
    "    st_first = np.around(np.linspace(0,first_dopant_range,81), decimals=3, out=None)\n",
    "    st_second = np.around(np.linspace(0,second_dopant_range,81), decimals=3, out=None)\n",
    "\n",
    "    first_grid, second_grid = np.meshgrid(st_first, st_second)\n",
    "\n",
    "    formula_test_set = []\n",
    "    pairs = []\n",
    "\n",
    "    # Creation of nominal stoichiometries\n",
    "    \n",
    "    for stb in st_first:\n",
    "        for stg in st_second:\n",
    "            base_equation_string = \"Li\" + (('%f'%(np.around(7+first_lithium_replace*stb + second_lithium_replace*stg, decimals=3, out=None))).rstrip('0').rstrip('.')) + \"La\" + (('%f'%(np.around(3+(first_lanthanum_replace*stb) + (second_lanthanum_replace*stg), decimals=3, out=None))).rstrip('0').rstrip('.')) + \"Zr\" + (('%f'%(np.around(2+(first_zirconium_replace*stb) + (second_zirconium_replace*stg), decimals=3, out=None))).rstrip('0').rstrip('.')) + (str(first_dopant) + (('%f'%(np.around(stb, decimals=3, out=None))).rstrip('0').rstrip('.')) if stb > 0 else '') + (str(second_dopant) + (('%f'%(np.around(stg, decimals=3, out=None))).rstrip('0').rstrip('.')) if stg > 0 else '') + \"O12\"\n",
    "            formula_test_set.append(base_equation_string)\n",
    "            pairs.append((stb, stg))\n",
    "\n",
    "    # Descriptors through features\n",
    "    \n",
    "    composition_test_set_dataframe = pd.DataFrame(formula_test_set, columns=['chemicalFormula'])\n",
    "\n",
    "    composition_test_set_dataframe['composition'] = composition_test_set_dataframe['chemicalFormula'].apply(get_composition) # Transformation of chemicalformula string into Matminer composition\n",
    "    feat_test_set= np.array(f.featurize_many(composition_test_set_dataframe['composition'], ignore_errors=True)) # Array to store such features\n",
    "\n",
    "    temp_array = np.array([25.0 for _ in range(feat_test_set.shape[0])]).reshape(-1,1)\n",
    "    feat_test_set = np.hstack((feat_test_set, temp_array))\n",
    "\n",
    "    # This code is to drop columns with std = 0. \n",
    "    parsed_features_test_set = pd.DataFrame(feat_test_set)\n",
    "    parsed_features_test_set_2 = parsed_features_test_set.loc[:,  x_df_prior.std() != 0] # Dropping same columns that were dropped on the training data\n",
    "\n",
    "    values = [list(parsed_features_test_set_2.iloc[x]) for x in range(len(parsed_features_test_set_2.index))]\n",
    "    values = np.array(values, dtype = float) \n",
    "\n",
    "    # Normalization if ANNs\n",
    "    \n",
    "    if model == neuralnetwork_model:\n",
    "        values = (values - feature_mean)/ (feature_std)\n",
    "\n",
    "    # Predictions\n",
    "    predictions = model.predict(values)#.flatten() # Prediction of the test set # Z\n",
    "    \n",
    "    \n",
    "    # Plotting\n",
    "    \n",
    "    Z = np.array([np.array(predictions.reshape(81,81)[:,x]) for x in range(81)])\n",
    "    \n",
    "    colors = []\n",
    "    \n",
    "    color_scale_colors =[[0.0, \"rgb(165,0,38)\"],\n",
    "                [0.1111111111111111, \"rgb(215,48,39)\"],\n",
    "                [0.2222222222222222, \"rgb(244,109,67)\"],\n",
    "                [0.3333333333333333, \"rgb(253,174,97)\"],\n",
    "                [0.4444444444444444, \"rgb(254,224,144)\"],\n",
    "                [0.5555555555555556, \"rgb(224,243,248)\"],\n",
    "                [0.6666666666666666, \"rgb(171,217,233)\"],\n",
    "                [0.7777777777777778, \"rgb(116,173,209)\"],\n",
    "                [0.8888888888888888, \"rgb(69,117,180)\"],\n",
    "                [1.0, \"rgb(49,54,149)\"]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    known_points = []\n",
    "    cross_test_points = []\n",
    "    \n",
    "    test_forset = inner_df[\"Composition\"].apply(get_composition)\n",
    "    \n",
    "    for _ in composition_test_set_dataframe['composition']: # Marking diamonds for the values in the entire dataset\n",
    "        if _ in list(data['composition'].values):\n",
    "            dic_ = dict(_.as_dict()) \n",
    "            if first_dopant in dic_.keys():\n",
    "                x = dic_[first_dopant]\n",
    "            else:\n",
    "                x = 0.0\n",
    "            if second_dopant in dic_.keys():\n",
    "                y = dic_[second_dopant]\n",
    "            else:\n",
    "                y = 0.0              \n",
    "            z = float(data[data['composition'] == _][\"Ionic Conductivity\"])\n",
    "            known_points.append([x,y,z])\n",
    "        if _ in list(test_forset): # Marking crosses for the values in the test dataset\n",
    "            dic_ = dict(_.as_dict()) \n",
    "            if first_dopant in dic_.keys():\n",
    "                x = dic_[first_dopant]\n",
    "            else:\n",
    "                x = 0.0\n",
    "            if second_dopant in dic_.keys():\n",
    "                y = dic_[second_dopant]\n",
    "            else:\n",
    "                y = 0.0              \n",
    "            cross_test_points.append([x,y])\n",
    "            \n",
    "    \n",
    "    known_points = np.array(known_points)   \n",
    "    known_scatter = go.Scatter(x=known_points[:,0], y=known_points[:,1], customdata=known_points[:,2], mode='markers',\n",
    "    marker=dict(\n",
    "        symbol = \"diamond\",\n",
    "        size=20,\n",
    "        color=known_points[:,2],\n",
    "        cmin = 0,\n",
    "        cmax = 18,\n",
    "        opacity=1,  colorbar=dict(thickness=20, title=dict(text='Lithium ion conductivity 10<sup> - 4</sup> S/cm',font = dict(family='Times New Roman',size=32)), titleside = 'right'), line=dict(width=2, color ='white')\n",
    "    ), hovertemplate='D1:%{x:.2f} <br>D2:%{y:.3f} <br>IC:%{customdata:.3f}')\n",
    "    \n",
    "\n",
    "    layout = go.Layout(\n",
    "        width = 800,\n",
    "        height = 600,\n",
    "        font = dict(family='Times New Roman',size=32),\n",
    "        xaxis= dict(title= first_dopant + ' content',zeroline= False, gridwidth= 2),\n",
    "        yaxis= dict(title= second_dopant + ' content',zeroline= False, gridwidth= 2),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    trace_heatmap = go.Heatmap(x=st_first, y = st_second, z=Z, showscale=False, connectgaps=True, zsmooth='best', zauto = False, zmin = 0, zmax = 18,  colorbar=dict(tickfont=dict(size=20)))\n",
    "                              \n",
    "    fig = go.Figure(data=[trace_heatmap,known_scatter], layout=layout)\n",
    "    \n",
    "\n",
    "    \n",
    "    if cross_test_points != []:\n",
    "        cross_test_points = np.array(cross_test_points)   \n",
    "        cross_test_scatter = go.Scatter(x=cross_test_points[:,0], y=cross_test_points[:,1], mode='markers',\n",
    "        marker=dict(\n",
    "            symbol = \"x\",\n",
    "            size=14,\n",
    "            color=\"white\"))\n",
    "        \n",
    "        fig.add_trace(cross_test_scatter)\n",
    "    \n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))    \n",
    "    iplot(fig)\n",
    "    \n",
    "    return first_dopant, second_dopant, st_first, st_second, pairs, colors, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dopant, second_dopant, first_element_range, second_element_range, pairs, colors, other_predictions = prediction_surface_dualdoped(randomforest_model, \"Ta\", 1 , \"Nb\", 1, -1, 0, -1, -1, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dopant, second_dopant, first_element_range, second_element_range, pairs, colors, other_predictions = prediction_surface_dualdoped(randomforest_model, \"Bi\", 1 , \"Ga\", 0.5, -1, 0, -1, -3, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_id = ['gdb_43226', 'gdb_18950', 'gdb_65057', 'gdb_27393']\n",
    "print(mol_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.db import QueryEngine\n",
    "qe = QueryEngine()\n",
    "#entries = qe.get_entries({})\n",
    "\n",
    "qe = [\"alpha\", \"homo\",\"lumo\", \"cv\",\"A\"]\n",
    "\n",
    "sample = ['gdb_43226', 'gdb_18950', 'gdb_65057']\n",
    "\n",
    "for item in sample:\n",
    "    mol_id_object = pymat.mol_id(item)\n",
    "    print(item, mol_id_object.homo) # You can change \"youngs_modulus\" to any of the properties in the querable_pymatgen list\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_43226_data = {} # Initializing a dictionary\n",
    "\n",
    "# Each of the following lines is making a single entry\n",
    "\n",
    "gdb_43226_data[\"alpha\"] = mendel.mol_id(\"gdb_43226\").alpha \n",
    "gdb_43226_data[\"homo\"] = pymat.mol_id(\"gdb_43226\").homo\n",
    "gdb_43226_data[\"lumo\"] = pymat.mol_id(\"gdb_43226\").lumo\n",
    "gdb_43226_data[\"cv\"] = mendel.mol_id(\"gdb_43226\").cv\n",
    "\n",
    "#Print the entire entry for Fe\n",
    "print(gdb_43226_data)\n",
    "\n",
    "#Print a specific attribute:\n",
    "print(gdb_43226_data[\"cv\"])\n",
    "\n",
    "# This line is to delete an entry\n",
    "    # del Fe_data[\"atomic_number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mol_id.copy()\n",
    "\n",
    "cv = [] # In this list we will store the Coefficients of Thermal Expansion\n",
    "alpha = [] # In this list we will store the Young's Moduli\n",
    "homo = [] # In this list we will store the Melting Temperatures\n",
    "\n",
    "for item in sample:\n",
    "    cv.append(pymat.mol_id(item).cv)\n",
    "    alpha.append(pymat.mol_id(item).alpha)\n",
    "    homo.append(pymat.mol_id(item).homo)\n",
    "\n",
    "# You can visualize the lists by uncommenting these print statements\n",
    "print(cv)\n",
    "print(alpha)\n",
    "print(homo)\n",
    "\n",
    "# We will use the following arrays to group elements by their crystal structure at RT, all elements that are gases and liquids at RT have been removed\n",
    "\n",
    "#fcc_elements = [\"Ag\", \"Al\", \"Au\", \"Cu\", \"Ir\", \"Ni\", \"Pb\", \"Pd\", \"Pt\", \"Rh\", \"Sr\", \"Th\", \"Yb\"]\n",
    "\n",
    "#all_values = [] # Values for Attributes\n",
    "\n",
    "#for item in fcc_elements:\n",
    "#    element_values = []\n",
    "\n",
    "#    element_object = pymat.Element(item)    \n",
    "#    for i in querable_pymatgen:\n",
    "#        element_values.append(getattr(element_object,i))\n",
    "        \n",
    "#    all_values.append(element_values) # All lists are appended to another list, creating a list of lists\n",
    "    \n",
    "# Pandas Dataframe\n",
    "#df = pd.DataFrame(all_values, columns=querable_pymatgen)\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index = mol_id\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_big_atoms = dataset[dataset.r2.ge(150)]\n",
    "display(dataset_big_atoms)\n",
    "dataset_poisson = dataset[dataset.homo.eq(0.26)]\n",
    "display(dataset_poisson)\n",
    "dataset_condition = dataset[(dataset['homo'] < 0.26) & (dataset[\"lumo\"] > 0.25)]\n",
    "display(dataset_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "\n",
    "!pip install -U numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "import tensorboard\n",
    "tensorboard.__version__\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.datasets import load_dataset\n",
    "\n",
    "df = load_dataset(\"qm9.csv\")\n",
    "#df = load_dataset(\"jarvis_dft_3d\")\n",
    "#from matminer.featurizer.conversions import ASEAtomstoStructure\n",
    "#aa2s = ASEAtomstoStructure()\n",
    "#df = aa2s.featurize_dataframe(df, \"ase atoms\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.db import QueryEngine\n",
    "qe = QueryEngine()\n",
    "entries = qe.get_entries({})\n",
    "rester.query('',['smiles','alpha','gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.db import QueryEngine\n",
    "qe = QueryEngine()\n",
    "qe \n",
    "#Print the task id and formula of all entries in the database.\n",
    "for r in qe.query(properties=[\"smiles\", \"alpha\"]):\n",
    "    print \"{alpha} - {smiles}\".format(**r)\n",
    "\n",
    "# Get a pymatgen Structure from the task_id.\n",
    ">>> structure = qe.get_structure_from_id(12)\n",
    "\n",
    "# Get pymatgen ComputedEntries using a criteria.\n",
    ">>> entries = qe.get_entries({})\n",
    "\n",
    "rester.query('',['smiles','alpha','gap'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = dataset.rename(columns={\"mol_id\": \"Mol_ID\", \"smiles\": \"SMILES\",\"A\":\"A\",\"B\":\"B\",\"C\":\"C\",\"mu\":\"Mu\",\"alpha\":\"Alpha\",\"homo\":\"HOMO\", \"lumo\":\"LUMO\",\"gap\":\"E. Gap\",\"r2\":\"R2\",\n",
    "                     \"zpve\":\"ZPVE\",\"u0\":\"U0\",\"u298\":\"U298\",\"h298\":\"H298\",\"g298\":\"G298\",\"cv\":\"CV\",\"u0_atom\":\"U0_atom\",\"u298_atom\":\"U298_atom\", \"h298_atom\":\"H298_atom\", \"g298_atom\":\"G298_atom\"})\n",
    "display(dataset_1)\n",
    "# \"alpha\" - Isotropic polarizability (unit: Bohr^3) [Bohr$^3$]\n",
    "# \"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"mol_id\" - Molecule ID (gdb9 index) mapping to the .sdf file\n",
    "#\"A\" - Rotational constant (unit: GHz)\n",
    "#\"B\" - Rotational constant (unit: GHz)\n",
    "#\"C\" - Rotational constant (unit: GHz)\n",
    "#\"mu\" - Dipole moment (unit: D)\n",
    "#\"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "#\"homo\" - Highest occupied molecular orbital energy (unit: Hartree)\n",
    "#\"lumo\" - Lowest unoccupied molecular orbital energy (unit: Hartree)\n",
    "#\"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"r2\" - Electronic spatial extent (unit: Bohr^2)\n",
    "#\"zpve\" - Zero point vibrational energy (unit: Hartree)\n",
    "#\"u0\" - Internal energy at 0K (unit: Hartree)\n",
    "#\"u298\" - Internal energy at 298.15K (unit: Hartree)\n",
    "#\"h298\" - Enthalpy at 298.15K (unit: Hartree)\n",
    "#\"g298\" - Free energy at 298.15K (unit: Hartree)\n",
    "#\"cv\" - Heat capavity at 298.15K (unit: cal/(mol*K))\n",
    "#\"u0_atom\" - Atomization energy at 0K (unit: kcal/mol)\n",
    "#\"u298_atom\" - Atomization energy at 298.15K (unit: kcal/mol)\n",
    "#\"h298_atom\" - Atomization enthalpy at 298.15K (unit: kcal/mol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rester.query({\"elements\": \"O\", \"nelements\": {\"$gte\": 3}},\n",
    "                    [\"task_id\",\"mol_id\",\"smiles\",\"A\",\"B\",\"C\",\"mu\",\"alpha\",\"lumo\",\"gap\",\"r2\",\n",
    "                     \"zpve\",\"u0\",\"u298\",\"h298\",\"g298\",\"cv\",\"u0_atom\",\"u298_atom\", \"h298_atom\", \"g298_atom\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of oxide structures available on the MP database: %s' % len(data))\n",
    "print('Example output: %s' % data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame.from_dict(dataset)\n",
    "display(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_cutoff_value = 10 #energy above convex hull cutoff [meV]\n",
    "df_1 = df_1[df_1['Alpha'] <= (energy_cutoff_value/1)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of SMILES available on the database: %s' % len(dataset))\n",
    "print('Number of SMILES below %.1f meV: %s' %(energy_cutoff_value, len(df_1)))\n",
    "display(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering data for U0_atom\n",
    "df_1 = df_1.dropna(subset=['U0_atom'])\n",
    "print('Number of SMILES available on the database: %s' % len(dataset))\n",
    "print('Number of SMILES below %.1f meV: %s' %(energy_cutoff_value, len(df_1)))\n",
    "display(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_dataframe(print_properties_options=True)\n",
    "display(data.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = (dataset)\n",
    "temp_list = []\n",
    "query_list_all = ['gdb_51741','gdb_18950','gdb_27393','gdb_43226']\n",
    "for mol_id in query_list_all:\n",
    "    res = client.query(mol_id +' alpha')\n",
    "    print(mol_id, next(res.results).text)\n",
    "    alph = float(next(res.results).text[:-21])\n",
    "    temp_list.append(alph)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(query_list_all,temp_list,align='center',label='Query')\n",
    "for i,v in enumerate(temp_list):\n",
    "    plt.text(v + 3, i , int(v), color='black',fontsize=14)\n",
    "plt.xlabel('alpha [Bohr$^{3}$]',fontsize=16)\n",
    "plt.ylabel('mol_id',fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(dataset[\"measured log solubility in mols per litre\"])\n",
    "df = pd.DataFrame(dataset)\n",
    "display(df)\n",
    "df_condition = df[(df['alpha'] < 10) & (df[\"gap\"] > 0.25)]\n",
    "# \"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "# \"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"mol_id\" - Molecule ID (gdb9 index) mapping to the .sdf file\n",
    "#\"A\" - Rotational constant (unit: GHz)\n",
    "#\"B\" - Rotational constant (unit: GHz)\n",
    "#\"C\" - Rotational constant (unit: GHz)\n",
    "#\"mu\" - Dipole moment (unit: D)\n",
    "#\"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "#\"homo\" - Highest occupied molecular orbital energy (unit: Hartree)\n",
    "#\"lumo\" - Lowest unoccupied molecular orbital energy (unit: Hartree)\n",
    "#\"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"r2\" - Electronic spatial extent (unit: Bohr^2)\n",
    "#\"zpve\" - Zero point vibrational energy (unit: Hartree)\n",
    "#\"u0\" - Internal energy at 0K (unit: Hartree)\n",
    "#\"u298\" - Internal energy at 298.15K (unit: Hartree)\n",
    "#\"h298\" - Enthalpy at 298.15K (unit: Hartree)\n",
    "#\"g298\" - Free energy at 298.15K (unit: Hartree)\n",
    "#\"cv\" - Heat capavity at 298.15K (unit: cal/(mol*K))\n",
    "#\"u0_atom\" - Atomization energy at 0K (unit: kcal/mol)\n",
    "#\"u298_atom\" - Atomization energy at 298.15K (unit: kcal/mol)\n",
    "#\"h298_atom\" - Atomization enthalpy at 298.15K (unit: kcal/mol)\n",
    "display(df_condition)\n",
    "df_homo = df[df.homo.eq(0.26)]\n",
    "display(df_homo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_alpha = []\n",
    "data_homo = []\n",
    "data_lumo = []\n",
    "for item in df:\n",
    "    data_alpha.append(df.alpha(item).alpha)\n",
    "    data_homo.append(df.data_homo(item).homo)\n",
    "    data_lumo.append(df.data_lumo(item).lumo)\n",
    "    #data_youngs_modulus.append(pymat.Element(item).youngs_modulus)\n",
    "    #data_CTE.append(pymat.Element(item).coefficient_of_linear_thermal_expansion)\n",
    "print(data_alpha)\n",
    "print(len(data_alpha),len(data_homo))\n",
    "data_alpha[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_Dummy = df.index[df['mol_id'] == 'gdb_32027']\n",
    "df.iloc[index_Dummy, df.columns.get_loc('A')] = 102 # GPa \n",
    "\n",
    "# The labels (values for Young's modulus) are stored separately for clarity (We drop the column later)\n",
    "\n",
    "df.to_csv(os.path.expanduser('./update_data.csv'), index=False, compression=None) # this line saves the data we collected into a .csv file into your home directory\n",
    "\n",
    "all_labels = df['A'].tolist()\n",
    "df = df.drop(['A'], axis=1)\n",
    "\n",
    "#We will rewrite the arrays with the patches we made on the dataset by turning the dataframe back into a list of lists\n",
    "\n",
    "all_values = [list(df.iloc[x]) for x in range(len(all_values))]\n",
    "\n",
    "# SETS\n",
    "\n",
    "# List of lists are turned into Numpy arrays to facilitate calculations in steps to follow (Normalization).\n",
    "all_values = np.array(all_values, dtype = float) \n",
    "print(\"Shape of Values:\", all_values.shape)\n",
    "all_labels = np.array(all_labels, dtype = float)\n",
    "print(\"Shape of Labels:\", all_labels.shape)\n",
    "\n",
    "# Uncomment the line below to shuffle the dataset (we do not do this here to ensure consistent results for every run)\n",
    "\n",
    "#order = np.argsort(np.random.random(all_labels.shape)) # This numpy argsort returns the indexes that would be used to shuffle a list\n",
    "order = np.arange(49)\n",
    "all_values = all_values[order]\n",
    "all_labels = all_labels[order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset(criteria={'dataset.index': '43567'}, print_properties_options=True)\n",
    "#display(data.head())\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "#plotly.offline.init_notebook_mode(connected=True)\n",
    "#plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# \"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "# \"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"mol_id\" - Molecule ID (gdb9 index) mapping to the .sdf file\n",
    "#\"A\" - Rotational constant (unit: GHz)\n",
    "#\"B\" - Rotational constant (unit: GHz)\n",
    "#\"C\" - Rotational constant (unit: GHz)\n",
    "#\"mu\" - Dipole moment (unit: D)\n",
    "#\"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "#\"homo\" - Highest occupied molecular orbital energy (unit: Hartree)\n",
    "#\"lumo\" - Lowest unoccupied molecular orbital energy (unit: Hartree)\n",
    "#\"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"r2\" - Electronic spatial extent (unit: Bohr^2)\n",
    "#\"zpve\" - Zero point vibrational energy (unit: Hartree)\n",
    "#\"u0\" - Internal energy at 0K (unit: Hartree)\n",
    "#\"u298\" - Internal energy at 298.15K (unit: Hartree)\n",
    "#\"h298\" - Enthalpy at 298.15K (unit: Hartree)\n",
    "#\"g298\" - Free energy at 298.15K (unit: Hartree)\n",
    "#\"cv\" - Heat capavity at 298.15K (unit: cal/(mol*K))\n",
    "#\"u0_atom\" - Atomization energy at 0K (unit: kcal/mol)\n",
    "#\"u298_atom\" - Atomization energy at 298.15K (unit: kcal/mol)\n",
    "#\"h298_atom\" - Atomization enthalpy at 298.15K (unit: kcal/mol)\n",
    "\n",
    "fig = px.bar(dataset.head(20), x='smiles', y='mol_id')\n",
    "fig.update_layout(barmode='group', xaxis_tickangle=-45)\n",
    "fig.show()\n",
    "data = fig\n",
    "layout = go.Layout(title= \"Gap between HOMO and LUMO vs. Dipole moment\", hovermode= 'closest',\n",
    "                   font = dict(family='Times New Roman',size=12),\n",
    "                   xaxis= dict(title= '$Gap \\: between \\: HOMO \\: and \\: LUMO \\: [Hartree]$',zeroline= False, gridwidth= 2),\n",
    "                   yaxis= dict(title= '$Dipole \\: moment \\: [D]$',zeroline= False, gridwidth= 2),\n",
    "                   height = 900,\n",
    "                   width = 900,\n",
    "     showlegend= True                \n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)\n",
    "pio.write_image(fig, \"./fig_smiles.png\", scale=2, width=600, height=350)\n",
    "#pio.write_image(fig, \"gdrive/MyDrive/Colab Notebooks/data/fig_smiles.png\", scale=2, width=600, height=350)\n",
    "\n",
    "#fig.write_image(\"gdrive/MyDrive/Colab Notebooks/data/fig_smiles.png\",dpi=600)\n",
    "#ax=px.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_smiles.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "from IPython.display import Image\n",
    "img_bytes = fig.to_image(format=\"png\", width=600, height=350, scale=1)\n",
    "Image(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are creating a function that takes a value X (Which will be the Symbol of the Element) \n",
    "# and returns a color depending on what its crystal structure is in our arrays from the beginning.\n",
    "# That is because we want to color data according to the crystal structure; therefore, we will have to pass this info to the plot\n",
    "\n",
    "def SetColor_CrystalStr(x):\n",
    "    if x in df[df.alpha.ge(25)]:\n",
    "        return \"red\" #This are standard CSS colors, but you can also use Hexadecimal Colors (#009900) or RGB \"rgb(0, 128, 0)\"\n",
    "    elif x in df[df.alpha.le(20)]:\n",
    "        return \"blue\"\n",
    "    elif x in df[df.alpha.eq(22)]:\n",
    "        return \"yellow\"\n",
    "    else:\n",
    "        return \"lightgray\"\n",
    "    \n",
    "# We will then create a list that passes all element symbols through this function. For that we will use the python function \"map\"    \n",
    "# Map takes each element on a list and evaluates it in a function.\n",
    "\n",
    "colors = list(map(SetColor_CrystalStr, df))\n",
    "\n",
    "# You can see this list of generated colors looks like by uncommenting this line\n",
    "\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "#plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# \"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "# \"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"mol_id\" - Molecule ID (gdb9 index) mapping to the .sdf file\n",
    "#\"A\" - Rotational constant (unit: GHz)\n",
    "#\"B\" - Rotational constant (unit: GHz)\n",
    "#\"C\" - Rotational constant (unit: GHz)\n",
    "#\"mu\" - Dipole moment (unit: D)\n",
    "#\"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "#\"homo\" - Highest occupied molecular orbital energy (unit: Hartree)\n",
    "#\"lumo\" - Lowest unoccupied molecular orbital energy (unit: Hartree)\n",
    "#\"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"r2\" - Electronic spatial extent (unit: Bohr^2)\n",
    "#\"zpve\" - Zero point vibrational energy (unit: Hartree)\n",
    "#\"u0\" - Internal energy at 0K (unit: Hartree)\n",
    "#\"u298\" - Internal energy at 298.15K (unit: Hartree)\n",
    "#\"h298\" - Enthalpy at 298.15K (unit: Hartree)\n",
    "#\"g298\" - Free energy at 298.15K (unit: Hartree)\n",
    "#\"cv\" - Heat capavity at 298.15K (unit: cal/(mol*K))\n",
    "#\"u0_atom\" - Atomization energy at 0K (unit: kcal/mol)\n",
    "#\"u298_atom\" - Atomization energy at 298.15K (unit: kcal/mol)\n",
    "#\"h298_atom\" - Atomization enthalpy at 298.15K (unit: kcal/mol)\n",
    "\n",
    "df = pd.DataFrame(dataset.head(200))\n",
    "\n",
    "def SetColor_CrystalStr(x):\n",
    "    if x in df[df['alpha'] == 30]:\n",
    "        return \"red\" #This are standard CSS colors, but you can also use Hexadecimal Colors (#009900) or RGB \"rgb(0, 128, 0)\"\n",
    "    elif x in df[df.cv.eq(20)]:\n",
    "        return \"blue\"\n",
    "    elif x in df[(df['alpha'] < 20) & (df[\"cv\"] > 15)]:\n",
    "        return \"yellow\"\n",
    "    else:\n",
    "        return \"lightgray\"\n",
    "colors = list(map(SetColor_CrystalStr, df))\n",
    "#print(colors)\n",
    "\n",
    "#Layout design. Can change title, font, x/y-axis etc. Commented out pieces are height and width. \n",
    "#For plot in browser I prefer long horizontal plots. For presentations square images may be preferred. \n",
    "#Image can be directly saved by hovering over image and clicking camera icon. \n",
    "layout_cv_alpha = go.Layout(title= 'Heat capavity at 298.15K vs. Isotropic polarizability',\n",
    "                   font = dict(family='Times New Roman',size=12),\n",
    "                   xaxis= dict(title=go.layout.xaxis.Title(text='$Heat \\: capavity \\: (cv) \\: at \\: 298.15K \\: [cal/(mol*K)]$', font=dict(size=24)),zeroline= False, gridwidth= 2, tickfont=dict(size=18)),\n",
    "                   yaxis= dict(title=go.layout.yaxis.Title(text='Isotropic polarizability (alpha) [(Bohr<sup>3</sup>)]', font=dict(size=24)),zeroline= False, gridwidth= 2, tickfont=dict(size=18)),\n",
    "                   height = 600, width = 600, hovermode= 'closest', showlegend=True, legend=dict(font=dict(size=24))                \n",
    ")\n",
    "#text='Isotropic polarizability (alpha) [(Bohr<sup>3</sup>)]'\n",
    "#text=\"$Isotropic \\: polarizability \\: (alpha) \\: [(Bohr^3)]$\"\n",
    "# Hovermode establishes the way the labels that appear when you hover are arranged # Establishing a square plot width=height\n",
    "# Axis Titles. Removing the X-axis Mark. Adding a Grid\n",
    "# Axis Titles. Removing the Y-axis Mark. Adding a Grid\n",
    "# Adding a legend\n",
    "\n",
    "#Scatter plot of collected data. Use df_oxide_all dataframe. df_oxide_all.Density will pull density column.\n",
    "trace_cv_alpha = go.Scatter(x = df.cv, y = df.alpha, mode = 'markers',\n",
    "                    marker=dict(size=12, line= dict(width=1), color=colors), text= sample, showlegend = True)\n",
    "\n",
    "# Empty Traces for Legend\n",
    "legend_plot_alpha = go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=14,  line= dict(width=1),color='red'), name = 'alpha')\n",
    "legend_plot_alpha1 = go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=14,  line= dict(width=1),color='blue'), name = 'alpha1')\n",
    "legend_plot_alpha2 = go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=14,  line= dict(width=1),color='yellow'), name = 'alpha2')\n",
    "\n",
    "data_cv_alpha = [trace_cv_alpha,legend_plot_alpha,legend_plot_alpha1,legend_plot_alpha2]#,trace0,trace2] trace_homo_lumo\n",
    "fig_cv_alpha = go.Figure(data_cv_alpha, layout_cv_alpha)\n",
    "iplot(fig_cv_alpha)\n",
    "pio.write_image(fig_cv_alpha, \"./fig_smiles_trace_cv_alpha.png\", scale=1, width=600, height=350)\n",
    "#pio.write_image(fig_IPF, \"gdrive/MyDrive/Colab Notebooks/data/fig_smiles_trace.png\", scale=2, width=600, height=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "#plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "from IPython.display import Image\n",
    "img_bytes = fig_cv_alpha.to_image(format=\"png\", width=600, height=350, scale=1)\n",
    "Image(img_bytes)\n",
    "\n",
    "layout_homo_lumo = go.Layout(title= \"Highest occupied molecular orbital energy vs. Lowest unoccupied molecular orbital energy\", hovermode= 'closest',\n",
    "                   font = dict(family='Times New Roman',size=12),\n",
    "                   xaxis= dict(title= '$Lowest \\: unoccupied \\: molecular \\: orbital \\: energy \\: (LUMO) \\: [Hartree]$',zeroline= False, gridwidth= 2),\n",
    "                   yaxis= dict(title= '$Highest \\: occupied \\: molecular \\: orbital \\: energy \\: (HUMO) \\: [Hartree]$',zeroline= False, gridwidth= 2),\n",
    "                   height = 600,\n",
    "                   width = 600,\n",
    "     showlegend= True                \n",
    ")\n",
    "trace_homo_lumo = go.Scatter(x = df.loc[:,'homo'],\n",
    "                        y = df.loc[:,'lumo'],\n",
    "                        mode = 'markers', marker=dict(size=18, color='magenta'), text = 'homo lumo', name = 'homo lumo')\n",
    "trace2 = go.Scatter(x = [0,600], y = [0,600], mode = 'lines', name = \"Match\") # This trace is the line X = Y which would indicate that the Prediction equals the real value\n",
    "\n",
    "data_homo_lumo = [trace_homo_lumo,trace2]#,trace0,trace2] trace_homo_lumo\n",
    "fig_homo_lumo = go.Figure(data_homo_lumo, layout=layout_homo_lumo)\n",
    "iplot(fig_homo_lumo)\n",
    "pio.write_image(fig_homo_lumo, \"./fig_smiles_trace_homo_lumo.png\", scale=1, width=600, height=350)\n",
    "#pio.write_image(fig_IPF, \"gdrive/MyDrive/Colab Notebooks/data/fig_smiles_trace.png\", scale=2, width=600, height=350)\n",
    "\n",
    "from IPython.display import Image\n",
    "img_bytes = fig_homo_lumo.to_image(format=\"png\", width=600, height=350, scale=1)\n",
    "Image(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "df = pd.DataFrame(dataset.head(10))\n",
    "\n",
    "layout_IPF_shear_modulus = go.Layout(title= \"Homo vs. Lumo\", hovermode= 'closest',\n",
    "                   font = dict(family='Times New Roman',size=18),\n",
    "                   xaxis= dict(title= '$Highest \\: occupied \\: molecular \\: orbital \\: energy \\: [Hartree]$',zeroline= False, gridwidth= 2),\n",
    "                   yaxis= dict(title= '$Lowest \\: unoccupied \\: molecular \\: orbital \\: energy \\: [Hartree]$',zeroline= False, gridwidth= 2),\n",
    "                   height = 600,\n",
    "                   width = 1200,\n",
    "     showlegend= False              \n",
    ")\n",
    "\n",
    "#Scatter plot of collected data. Use df_oxide_all dataframe. df_oxide_all.Density will pull density column. Could change Density or IPF to Molar Volume or simply volume if you wanted.\n",
    "trace_all_shear = go.Scatter(x = abs(df.homo), y = df.lumo, mode = 'markers', text = df,\n",
    "                            marker=dict(size=12, color=(df['gap']),\n",
    "                                colorbar = dict(title={ 'text': \"gap\", \n",
    "                                                     'font': {'family':'Georgia', 'size': 18}} , \n",
    "                                              tickfont={'family':'Georgia', 'size': 16 })))#, name = 'All Queries'))\n",
    "\n",
    "data_IPF_shear = [trace_all_shear]#,trace0,trace2]\n",
    "fig_IPF_shear = go.Figure(data_IPF_shear, layout=layout_IPF_shear_modulus)\n",
    "iplot(fig_IPF_shear)\n",
    "pio.write_image(fig_IPF, \"./fig_smiles_trace_3variable.png\", scale=2, width=600, height=350)\n",
    "#pio.write_image(fig_IPF, \"gdrive/MyDrive/Colab Notebooks/data/fig_smiles_trace_3variable.png\", scale=2, width=600, height=350)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(img_bytes)\n",
    "img_bytes = fig_IPF_shear.to_image(format=\"png\", width=600, height=350, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "df = pd.DataFrame(dataset.head(10))\n",
    "\n",
    "layout_IPF_shear_modulus = go.Layout(title= \"Mobility vs. Zero Point Vibrational Energy \", hovermode= 'closest',\n",
    "                   font = dict(family='Times New Roman',size=18),\n",
    "                   xaxis= dict(title= '$Mobility \\: \\: [cm2/(V⋅s)]$',zeroline= False, gridwidth= 2),\n",
    "                   yaxis= dict(title= '$Zero Point Vibrational Energy\\: (ZPVE) [GPa]$',zeroline= False, gridwidth= 2),\n",
    "                   height = 600,\n",
    "                   width = 1200,\n",
    "     showlegend= False              \n",
    ")\n",
    "\n",
    "#Scatter plot of collected data. Use df_oxide_all dataframe. df_oxide_all.Density will pull density column. Could change Density or IPF to Molar Volume or simply volume if you wanted.\n",
    "trace_all_shear = go.Scatter(x = abs(df.homo), y = df.lumo, mode = 'markers', text = df,\n",
    "                            marker=dict(size=12, color=(df['gap']),\n",
    "                                colorbar = dict(title={ 'text': \"gap\", \n",
    "                                                     'font': {'family':'Georgia', 'size': 18}} , \n",
    "                                              tickfont={'family':'Georgia', 'size': 16 })))#, name = 'All Queries'))\n",
    "\n",
    "data_IPF_shear = [trace_all_shear]#,trace0,trace2]\n",
    "fig_IPF_shear = go.Figure(data_IPF_shear, layout=layout_IPF_shear_modulus)\n",
    "iplot(fig_IPF_shear)\n",
    "pio.write_image(fig_IPF, \"./fig_smiles_trace_3variable.png\", scale=2, width=600, height=350)\n",
    "#pio.write_image(fig_IPF, \"gdrive/MyDrive/Colab Notebooks/data/fig_smiles_trace_3variable.png\", scale=2, width=600, height=350)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(img_bytes)\n",
    "img_bytes = fig_IPF_shear.to_image(format=\"png\", width=600, height=350, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly #This is the library import\n",
    "import plotly.graph_objs as go # This is the graphical object (Think \"plt\" in Matplotlib if you have used that before)\n",
    "\n",
    "from plotly.offline import iplot # These lines are necessary to run Plotly in Jupyter Notebooks, but not in a dedicated environment\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "# To create a plot, you need a layout and a trace\n",
    "\n",
    "# The layout gives Plotly the instructions on the background grids, tiles in the plot, \n",
    "# axes names, axes ticks, legends, labels, colors on the figure and general formatting.\n",
    "\n",
    "\n",
    "\n",
    "layout = go.Layout(title = \"Mu vs Smile String\", xaxis= dict(title= 'smiles'), yaxis= dict(title= 'mu'))\n",
    "\n",
    "\n",
    "\n",
    "# The trace contains a type of plot (In this case, Scatter, but it can be \"Bars, Lines, Pie Charts\", etc.), \n",
    "# the data we want to visualize and the way (\"Mode\") we want to represent it.\n",
    "\n",
    "df = px.data.iris()\n",
    "trace = go.scatter(df, x=df.alpha, y =df.mu, mode = 'markers')\n",
    "\n",
    "# To plot, we create a figure and implement our components in the following way:\n",
    "\n",
    "data = [trace] # We could include more than just one trace here\n",
    "\n",
    "fig= go.Figure(data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.distplot(dataset[\"measured log solubility in mols per litre\"])\n",
    "\n",
    "#ax = sns.displot(dataset[\"mu\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "#ax=plt.savefig('./fig_mu.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_mu.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "#ax = sns.displot(dataset[\"alpha\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "#ax=plt.savefig('./fig_alpha.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_alpha.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "#ax = sns.displot(dataset[\"homo\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "#ax=plt.savefig('./fig_homo.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_homo.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "#ax = sns.displot(dataset[\"lumo\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "#ax=plt.savefig('./fig_lumo.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_lumo.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "#ax = sns.displot(dataset[\"gap\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "#ax=plt.savefig('./fig_gap.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_gap.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "\n",
    "#ax = sns.displot(dataset[\"zpve\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "#ax=plt.savefig('./fig_zpve.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_zpve.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n",
    "\n",
    "#ax = sns.displot(dataset[\"cv\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "#ax=plt.savefig('./fig_cv.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_cv.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "smiles_lengths = map(len, dataset.smiles.values)\n",
    "#sns.distplot(list(smiles_lengths), bins=20, kde=False)\n",
    "ax = sns.distplot(list(smiles_lengths), bins=20, kde=True, kde_kws={\"color\": \"k\", \"label\": \"KDE\"})\n",
    "ax=plt.savefig('./fig_smiles_lengths.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_smiles_lengths.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n",
    "# ax=plt.savefig('../data/fig_smiles_lengths.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'displot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a365bbc8a43c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msmiles_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#sns.distplot(list(smiles_lengths), bins=20, kde=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'displot'"
     ]
    }
   ],
   "source": [
    "smiles_lengths = map(len, dataset.smiles.values)\n",
    "#sns.distplot(list(smiles_lengths), bins=20, kde=False)\n",
    "sns.displot(list(smiles_lengths), bins=20, kde=False)\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "\n",
    "def generate_charset(full_char_list:list) -> list:\n",
    "    '''\n",
    "    Assumes full_char_list is a list of characters (e.g., ['c', 'c', '1']).\n",
    "    Returns a sorted list of unique characters, with index zero as a NULL character, and a PAD character.\n",
    "    '''\n",
    "    unique_chars = set(''.join(full_char_list))\n",
    "    charset = ['NULL', 'PAD'] + sorted(unique_chars)\n",
    "    return charset\n",
    "\n",
    "def smiles_to_onehots(smiles_strings:list,\n",
    "                     unique_charset:list,\n",
    "                     max_smiles_chars:int) -> np.array:\n",
    "    one_hots = []\n",
    "    charset_length = len(unique_charset)\n",
    "\n",
    "    for smiles_string in smiles_strings:\n",
    "        one_hot_smiles = np.zeros(shape=(max_smiles_chars, charset_length))\n",
    "        for i in range(max_smiles_chars):\n",
    "            one_hot_col = [0]*charset_length\n",
    "            ind = None # Which index will we flip to be \"one-hot\"?\n",
    "            \n",
    "            if i < len(smiles_string):\n",
    "                try:\n",
    "                    ind = unique_charset.index(smiles_string[i])\n",
    "                    # one_hot_col[unique_charset.index(char)] = 1\n",
    "                except ValueError:\n",
    "                    ind = 0 # Treat as NULL if out-of-vocab  \n",
    "                    # one_hot_col[0] = 1 # Treat as NULL if out-of-vocab   \n",
    "            else:\n",
    "                ind = 1 # Add PAD as needed\n",
    "            \n",
    "            one_hot_col[ind] = 1\n",
    "            one_hot_smiles[i,:] = one_hot_col\n",
    "            \n",
    "        one_hots.append(one_hot_smiles)\n",
    "    return np.array(one_hots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120500 13385 120500 13385\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'order' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b0a21651f956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print a sample entry from the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print a sample entry from the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'order' is not defined"
     ]
    }
   ],
   "source": [
    "charset = generate_charset(\n",
    "    dataset[\"smiles\"].values.ravel()\n",
    ")\n",
    "# get the number of unique characters\n",
    "charset_length = len(charset)\n",
    "# define max number of SMILES for model input vector\n",
    "max_smiles_chars = 40\n",
    "# dimension of input vector\n",
    "input_dim = charset_length * max_smiles_chars\n",
    "# get one-hot representation of the SMILES strings \n",
    "one_hots = smiles_to_onehots(dataset[\"smiles\"].values, charset, max_smiles_chars)\n",
    "# split input into train and test sets\n",
    "X_train = one_hots[:-13385] #This takes the first 133885-13385=120500  entries to be the Training Set\n",
    "X_test = one_hots[-13385:] # This takes the last 13385 entries to be the Testing Set\n",
    "\n",
    "# split output to train and test sets\n",
    "output = dataset[\"lumo\"].values\n",
    "#output = dataset[\"homo\"].values\n",
    "#output = dataset[\"cv\"].values\n",
    "#output = dataset[\"r2\"].values\n",
    "\n",
    "# \"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "# \"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"mol_id\" - Molecule ID (gdb9 index) mapping to the .sdf file\n",
    "#\"A\" - Rotational constant (unit: GHz)\n",
    "#\"B\" - Rotational constant (unit: GHz)\n",
    "#\"C\" - Rotational constant (unit: GHz)\n",
    "#\"mu\" - Dipole moment (unit: D)\n",
    "#\"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "#\"homo\" - Highest occupied molecular orbital energy (unit: Hartree)\n",
    "#\"lumo\" - Lowest unoccupied molecular orbital energy (unit: Hartree)\n",
    "#\"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"r2\" - Electronic spatial extent (unit: Bohr^2)\n",
    "#\"zpve\" - Zero point vibrational energy (unit: Hartree)\n",
    "#\"u0\" - Internal energy at 0K (unit: Hartree)\n",
    "#\"u298\" - Internal energy at 298.15K (unit: Hartree)\n",
    "#\"h298\" - Enthalpy at 298.15K (unit: Hartree)\n",
    "#\"g298\" - Free energy at 298.15K (unit: Hartree)\n",
    "#\"cv\" - Heat capavity at 298.15K (unit: cal/(mol*K))\n",
    "#\"u0_atom\" - Atomization energy at 0K (unit: kcal/mol)\n",
    "#\"u298_atom\" - Atomization energy at 298.15K (unit: kcal/mol)\n",
    "#\"h298_atom\" - Atomization enthalpy at 298.15K (unit: kcal/mol)\n",
    "Y_train = output[:-13385] #This takes the first 133885-100=133785 entries to be the Training Set\n",
    "Y_test = output[-13385:] # This takes the last 100 entries to be the Testing Set\n",
    "\n",
    "# This Reshape function in the next two lines, turns each of the horizontal lists [ x, y, z] into a\n",
    "# vertical NumPy array [[x]\n",
    "#                       [y]\n",
    "#                       [z]]\n",
    "# This Step is required to work with the Sklearn Linear Model\n",
    "#Y_train = np.array(melt_train).reshape(-1,1) \n",
    "#Y_test  = np.array(melt_test).reshape(-1,1)\n",
    "print(len(X_train),len(X_test),len(Y_train),len(Y_test))\n",
    "print(X_train[0]) # print a sample entry from the training set\n",
    "print(X_test[0]) # print a sample entry from the training set\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(X_train)\n",
    "#print(X_test)\n",
    "\n",
    "#X_train = np.reshape(X_train, (len(X_train)))\n",
    "#X_test = np.reshape(X_test, (len(X_test)))\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(X_train)\n",
    "#print(X_test)\n",
    "\n",
    "noise_factor = 0.5\n",
    "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \n",
    "X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "\n",
    "print(X_train_noisy.shape)\n",
    "print(X_test_noisy.shape)\n",
    "print(X_train_noisy)\n",
    "print(X_test_noisy)\n",
    "\n",
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
    "\n",
    "print(X_train_noisy.shape)\n",
    "print(X_test_noisy.shape)\n",
    "print(X_train_noisy)\n",
    "print(X_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function defines a model, trains it, and uses it to predict\n",
    "# It also outputs the linear model and information about its accuracy\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#explained-variance-score\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_train = one_hots[:-100] #This takes the first 133885-13385=120500  entries to be the Training Set\n",
    "X_test = one_hots[-100:] # This takes the last 13385 entries to be the Testing Set\n",
    "# split output to train and test sets\n",
    "output = dataset[\"lumo\"].values\n",
    "Y_train = output[:-100] #This takes the first 133885-100=133785 entries to be the Training Set\n",
    "Y_test = output[-100:] # This takes the last 100 entries to be the Testing Set\n",
    "print(len(X_train),len(X_test),len(Y_train),len(Y_test))\n",
    "print(X_train[0]) # print a sample entry from the training set\n",
    "print(X_test[0]) # print a sample entry from the training set\n",
    "print(order)\n",
    "\n",
    "x_train = np.array(X_train).reshape(-1,1)\n",
    "x_test = np.array(X_test).reshape(-1,1)\n",
    "y_train = np.array(Y_train).reshape(-1,1)\n",
    "y_test = np.array(Y_test).reshape(-1,1)\n",
    "\n",
    "def regression(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    # Define the model and train it\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    #Join train + test data \n",
    "    full_x = np.concatenate((x_train), axis=0)\n",
    "    full_y = np.concatenate((y_train), axis=0)\n",
    "    #full_x = np.concatenate((x_train, x_test), axis=0)\n",
    "    #full_y = np.concatenate((y_train, y_test), axis=0)\n",
    "    \n",
    "    # Use the model to predict the entire set of data\n",
    "    predictions = model.predict(full_x) # Make it for all values\n",
    "    \n",
    "    # Print model and mean squared error and variance score\n",
    "    print(\"Linear Equation: %.4e X + (%.4e)\"%(model.coef_, model.intercept_))\n",
    "    print(\"Mean squared error: %.4e\" % (mean_squared_error(full_y, predictions)))\n",
    "    print('Variance score: %.4f' % r2_score(full_y, predictions))    \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly #This is the library import\n",
    "import plotly.graph_objs as go # This is the graphical object (Think \"plt\" in Matplotlib if you have used that before)\n",
    "from plotly.offline import iplot # These lines are necessary to run Plotly in Jupyter Notebooks, but not in a dedicated environment\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "def plot(x_train, x_test, y_train, y_test, x_label, y_label, predictions):\n",
    "    \n",
    "    # The reshape functions in the next two lines, turns each of the\n",
    "    # vertical NumPy array [[x]\n",
    "    #                       [y]\n",
    "    #                       [z]]\n",
    "    # into python lists [ x, y, z]\n",
    "    \n",
    "    # This step is required to create plots with plotly like we did in the previous tutorial\n",
    "    \n",
    "    x_train = x_train.reshape(1,-1).tolist()[0]\n",
    "    x_test = x_test.reshape(1,-1).tolist()[0]\n",
    "    y_train = y_train.reshape(1,-1).tolist()[0]\n",
    "    y_test = y_test.reshape(1,-1).tolist()[0]    \n",
    "    predictions = predictions.reshape(1,-1).tolist()[0]\n",
    "    full_x_list = x_train + x_test\n",
    "\n",
    "    \n",
    "    # Now we get back to what we know. Remember, to plot in Plotly, we need a layout and at least one trace\n",
    "    \n",
    "    layout0= go.Layout(hovermode= 'closest', width = 800, height=600, showlegend=True,  # Hovermode establishes the way the labels that appear when you hover are arranged # Establishing a square plot width=height\n",
    "    xaxis= dict(title=go.layout.xaxis.Title(text=x_label, font=dict(size=24)), zeroline= False, gridwidth= 1, tickfont=dict(size=18)), # Axis Titles. Removing the X-axis Mark. Adding a Grid\n",
    "    yaxis= dict(title=go.layout.yaxis.Title(text=y_label, font=dict(size=24)), zeroline= False, gridwidth= 1, tickfont=dict(size=18)), # Axis Titles. Removing the Y-axis Mark. Adding a Grid\n",
    "    legend=dict(font=dict(size=24))) # Adding a legend\n",
    "    \n",
    "\n",
    "    training = go.Scatter(x = x_train, y = y_train, mode = 'markers', \n",
    "                          marker= dict(size= 10, color= 'green'), name= \"Training Data\") \n",
    "    # This trace contains the values for the data in the training set\n",
    "    \n",
    "    actual = go.Scatter(x = x_test, y = y_test, mode = 'markers', \n",
    "                        marker= dict(size= 10, color= 'red'), name= \"Testing Data\") \n",
    "    # This trace contains the values for the data in the testing set\n",
    "\n",
    "    prediction = go.Scatter(x = full_x_list, y = predictions, mode = 'lines', \n",
    "                            line = dict(color = \"blue\", width = 1.5),name= \"Model\") \n",
    "    # This trace will be the line the model fitted the data to\n",
    "\n",
    "    data = [training, actual, prediction]\n",
    "    fig= go.Figure(data, layout=layout0)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regression(x_train, x_test, y_train, y_test) \n",
    "# This line calls the Regression model implemented in the function \n",
    "\n",
    "plot(x_train, x_test, y_train, y_test, \"Melting Temperature (K)\", \"Young's Modulus (GPa)\", predictions) \n",
    "# This line plots the results from that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O=C1C2CCCC1C=C2\n",
      "O=CC1C2C3CC2N13\n",
      "CC1(CO1)C1(CO1)C#C\n",
      "c1c([nH]c(nc1=O)N)O\n",
      "O=COC1CCC11CN1\n",
      "CC1C(C#C)C1(N)C#N\n",
      "CCOC1(C)CCOC1\n",
      "OCC1OC11CC2NC12\n",
      "CC1C=C2CN3CC1C23\n",
      "CC1=C2CCCC2CC1\n",
      "c1cnc(cc1N)O\n",
      "CCC#CCC\n",
      "N=C1OCC11CN1C=O\n",
      "CC1(COC1)C(C)(C)C\n",
      "CN=COC1COC1\n",
      "COC=NCC(=O)OC\n",
      "CC(=N)N(C=O)C(=O)N\n",
      "COCC(O)C(N)C#N\n",
      "CC1C(C)C1CNC=O\n",
      "NC1=C(F)N=NNC1=N\n",
      "CCC1CC=CCCO1\n",
      "CC1C2OC2C=C1C\n",
      "CC12OCC3C1C1C2N31\n",
      "CC1OCC11COCO1\n",
      "C#CCC12CN(C1)C2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_rows = 5\n",
    "num_cols = 5\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(6*num_cols, 6*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, num_cols, i+1)\n",
    "    #plot_image(i, predictions, testLabels, testImages)\n",
    "#plt.figure(figsize=(30,30))\n",
    "#for i in range(25): #133785 \n",
    "    #plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    #plt.xlabel('Character')\n",
    "    #plt.ylabel('Position in SMILES String')\n",
    "    sns.heatmap(X_train[i])\n",
    "    #plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    #plt.xlabel(class_names[int(trainLabels[i])])\n",
    "    print(dataset.iloc[i]['smiles'])\n",
    "\n",
    "#plt.imshow(X_train[index]) # By altering 'index' you will see another of the pictures imported\n",
    "#plt.colorbar()\n",
    "#plt.grid(False)\n",
    "#print(\"Train Images Array shape:\", trainImages.shape)\n",
    "#print(\"Train Labels Array shape:\", trainLabels.shape)\n",
    "#print(\"Test Images Array shape:\", testImages.shape)\n",
    "#print(\"Test Labels Array shape:\", testLabels.shape)\n",
    "\n",
    "#index = 6986 #index runs from 0 to 138388\n",
    "#sns.heatmap(X_train[index]) # This is a single training example -- note that it is a matrix, not a single vector!\n",
    "#plt.xlabel('Character')\n",
    "#plt.ylabel('Position in SMILES String')\n",
    "#print(dataset.iloc[index]['smiles'])\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_smiles_character.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n",
    "ax=plt.savefig('./fig_smiles_character.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_r2.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will multi-hot encode the sentences. Multi-hot-encoding our lists means turning them into vectors of 0s and 1s. Concretely, this would mean for instance turning the sequence [3, 5] into a 10,000-dimensional vector that would be all-zeros except for indices 3 and 5, which would be ones. This model will quickly overfit to the training set and can be used to demonstrate when overfitting occurs, and how to fight it.\n",
    "\n",
    "The word indices are sorted by frequency, so it is expected that there are more 1-values near index zero, as we can see in the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_processing\n",
    "NUM_WORDS = 10000\n",
    "(train_data, train_labels), (test_data, test_labels) = text_processing.load_data(num_words=10000)\n",
    "\n",
    "def multi_hot_sequences(sequences, dimension):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, word_indices in enumerate(sequences):\n",
    "        results[i, word_indices] = 1.0  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "train_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)\n",
    "test_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)\n",
    "\n",
    "print(train_data[0])\n",
    "_ = plt.plot(train_data[0], marker='o', linestyle = 'None', markersize = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>Supervised CNN model for predicting mobility</ins>\n",
    "\n",
    "In this section, we will set up a convolutional neural network to predict mobility using one-hot SMILES as input. A convolutional neural network is a machine learning model that is commonly used to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create the model structure, starting with the input layer. As described above, each training example is a 40x31 matrix, which is the shape we pass to the Input layer in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer\n",
    "# NOTE: We feed in a sequence here! We're inputting up to max_smiles_chars characters, \n",
    "# and each character is an array of length charset_length\n",
    "smiles_input = Input(shape=(max_smiles_chars, charset_length), name=\"SMILES-Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define the convolution layers where each layer attempts to learn certain features of the images, such as edges and corners. The input to each layer (a matrix) is transformed via convolution operations, which are element by element multiplications of the input matrix and a filter matrix. The convolutional layer learns the filter matrix that will best identify unique features of the image. You can learn more about convolution operations and the math behind convolutional neural networks [here](https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for convolutional layers \n",
    "num_conv_filters = 16\n",
    "kernel_size = 3\n",
    "#kernel_init = initializers.RandomNormal(seed=0)\n",
    "#bias_init = initializers.Zeros()\n",
    "init_weights = initializers.glorot_normal(seed=0)\n",
    "\n",
    "# Define the convolutional layers\n",
    "# Multiple convolutions in a row is a common architecture (but there are many \"right\" choices here)\n",
    "conv_1_func = Conv1D(\n",
    "    filters=num_conv_filters, # What is the \"depth\" of the convolution? How many times do you look at the same spot?\n",
    "    kernel_size=kernel_size, # How \"wide\" of a spot does each filter look at?\n",
    "    name=\"Convolution-1\",\n",
    "    activation=\"relu\", # This is a common activation function: Rectified Linear Unit (ReLU)\n",
    "    kernel_initializer=init_weights #This defines the initial values for the weights\n",
    ")\n",
    "conv_2_func = Conv1D(\n",
    "    filters=num_conv_filters, \n",
    "    kernel_size=kernel_size, \n",
    "    name=\"Convolution-2\",\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=init_weights\n",
    ")\n",
    "conv_3_func = Conv1D(\n",
    "    filters=num_conv_filters, \n",
    "    kernel_size=kernel_size, \n",
    "    name=\"Convolution-3\",\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=init_weights\n",
    ")\n",
    "conv_4_func = Conv1D(\n",
    "    filters=num_conv_filters, \n",
    "    kernel_size=kernel_size,\n",
    "    name=\"Convolution-4\",\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=init_weights\n",
    ")\n",
    "\n",
    "# strides and paddind can be added in the convolution netowrk\n",
    "# strides=2, padding=\"same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four convolution layers defined above will attempt to learn features of the SMILES string (represented as a 40x31 matrix) that are relevant to predicting the mobility. To get a numerical prediction, we now flatten the output of the convolution and pass it to a set of regular `Dense` layers, the last layer predicting one value for the mobility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layer to flatten convolutions\n",
    "flatten_func = Flatten(name=\"Flattened-Convolutions\")\n",
    "\n",
    "# Define the activation function layer\n",
    "hidden_size = 32\n",
    "dense_1_func = Dense(hidden_size, activation=\"relu\", name=\"Fully-Connected\", kernel_initializer=init_weights)\n",
    "\n",
    "# Add a Dense layer with a L1 activity regularizer\n",
    "#dense_1_func = Dense(hidden_size, activation=\"relu\", name=\"Fully-Connected\", activity_regularizer=regularizers.l1(10e-5), kernel_initializer=init_weights)\n",
    "\n",
    "# Define output layer -- it's only one dimension since it is regression\n",
    "output_size = 1\n",
    "output_mobility_func = Dense(output_size, activation=\"linear\", name=\"Log-lumo\", kernel_initializer=init_weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined all the layers, we will connect them together to make a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# connect the CNN graph together\n",
    "conv_1_fwd = conv_1_func(smiles_input)\n",
    "conv_2_fwd = conv_2_func(conv_1_fwd)\n",
    "conv_3_fwd = conv_3_func(conv_2_fwd)\n",
    "conv_4_fwd = conv_4_func(conv_3_fwd)\n",
    "flattened_convs = flatten_func(conv_4_fwd)\n",
    "dense_1_fwd = dense_1_func(flattened_convs)\n",
    "output_mobility_fwd = output_mobility_func(flattened_convs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View model structure and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is ready to train! But first we will define the model as `mobility_model` and compile it, then view some information on the model using the [keras2ascii](https://github.com/stared/keras-sequential-ascii) tool, which visually represents the layers in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "SMILES-Input (InputLayer)    (None, 40, 23)            0         \n",
      "_________________________________________________________________\n",
      "Convolution-1 (Conv1D)       (None, 38, 16)            1120      \n",
      "_________________________________________________________________\n",
      "Convolution-2 (Conv1D)       (None, 36, 16)            784       \n",
      "_________________________________________________________________\n",
      "Convolution-3 (Conv1D)       (None, 34, 16)            784       \n",
      "_________________________________________________________________\n",
      "Convolution-4 (Conv1D)       (None, 32, 16)            784       \n",
      "_________________________________________________________________\n",
      "Flattened-Convolutions (Flat (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Log-lumo (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,985\n",
      "Trainable params: 3,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "mobility_model = Model(\n",
    "            inputs=[smiles_input],\n",
    "            outputs=[output_mobility_fwd]\n",
    ")\n",
    "mae_st = []\n",
    "# compile model\n",
    "#optimizer = optimizers.RMSprop(0.002) # Root Mean Squared Propagation\n",
    "# This line matches the optimizer to the model and states which metrics will evaluate the model's accuracy\n",
    "\n",
    "# loss= mse, mae\n",
    "# loss= categorical_crossentropy\n",
    "#loss='sparse_categorical_crossentropy'\n",
    "#loss='binary_crossentropy'\n",
    "#metrics=['accuracy', 'binary_crossentropy']\n",
    "#metrics=['accuracy']\n",
    "mobility_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "mobility_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --user keras_sequential_ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "               Input   #####     40   23\n",
      "          InputLayer     |   -------------------         0     0.0%\n",
      "                       #####     40   23\n",
      "              Conv1D    \\|/  -------------------      1120    28.1%\n",
      "                relu   #####     38   16\n",
      "              Conv1D    \\|/  -------------------       784    19.7%\n",
      "                relu   #####     36   16\n",
      "              Conv1D    \\|/  -------------------       784    19.7%\n",
      "                relu   #####     34   16\n",
      "              Conv1D    \\|/  -------------------       784    19.7%\n",
      "                relu   #####     32   16\n",
      "             Flatten   ||||| -------------------         0     0.0%\n",
      "                       #####         512\n",
      "               Dense   XXXXX -------------------       513    12.9%\n",
      "                       #####           1\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras_sequential_ascii\n",
    "from keras_sequential_ascii import keras2ascii\n",
    "# view model as a graph\n",
    "keras2ascii(mobility_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN\n",
    "\n",
    "Now we will train our CNN mobility model to the training data! During training, we will see metrics printed after each epoch such as test/train loss (both as Mean Squared Error (MSE) and Mean Absolute Error (MAE))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 120500 samples, validate on 13385 samples\n",
      "Epoch 1/20\n",
      "120500/120500 [==============================] - 284s 2ms/step - loss: 6.7155e-04 - mean_absolute_error: 0.0180 - val_loss: 2.8787e-04 - val_mean_absolute_error: 0.0130\n",
      "Epoch 2/20\n",
      "120500/120500 [==============================] - 63s 521us/step - loss: 2.6403e-04 - mean_absolute_error: 0.0124 - val_loss: 2.2990e-04 - val_mean_absolute_error: 0.0115\n",
      "Epoch 3/20\n",
      "120500/120500 [==============================] - 39s 324us/step - loss: 2.2802e-04 - mean_absolute_error: 0.0115 - val_loss: 2.0415e-04 - val_mean_absolute_error: 0.0109\n",
      "Epoch 4/20\n",
      "120500/120500 [==============================] - 47s 392us/step - loss: 2.0887e-04 - mean_absolute_error: 0.0110 - val_loss: 2.1223e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 5/20\n",
      "120500/120500 [==============================] - 68s 567us/step - loss: 1.9299e-04 - mean_absolute_error: 0.0105 - val_loss: 2.0957e-04 - val_mean_absolute_error: 0.0110\n",
      "Epoch 6/20\n",
      "120500/120500 [==============================] - 68s 562us/step - loss: 1.8518e-04 - mean_absolute_error: 0.0103 - val_loss: 1.8497e-04 - val_mean_absolute_error: 0.0102\n",
      "Epoch 7/20\n",
      "120500/120500 [==============================] - 68s 562us/step - loss: 1.7752e-04 - mean_absolute_error: 0.0101 - val_loss: 1.6914e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 8/20\n",
      "120500/120500 [==============================] - 69s 569us/step - loss: 1.7238e-04 - mean_absolute_error: 0.0099 - val_loss: 1.7470e-04 - val_mean_absolute_error: 0.0100\n",
      "Epoch 9/20\n",
      "120500/120500 [==============================] - 68s 568us/step - loss: 1.6766e-04 - mean_absolute_error: 0.0097 - val_loss: 1.6863e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 10/20\n",
      "120500/120500 [==============================] - 68s 565us/step - loss: 1.6453e-04 - mean_absolute_error: 0.0096 - val_loss: 1.6630e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 11/20\n",
      "120500/120500 [==============================] - 68s 562us/step - loss: 1.6197e-04 - mean_absolute_error: 0.0096 - val_loss: 1.6440e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 12/20\n",
      "120500/120500 [==============================] - 69s 576us/step - loss: 1.6020e-04 - mean_absolute_error: 0.0095 - val_loss: 1.7459e-04 - val_mean_absolute_error: 0.0100\n",
      "Epoch 13/20\n",
      "120500/120500 [==============================] - 70s 581us/step - loss: 1.5705e-04 - mean_absolute_error: 0.0094 - val_loss: 1.5641e-04 - val_mean_absolute_error: 0.0094\n",
      "Epoch 14/20\n",
      "120500/120500 [==============================] - 68s 563us/step - loss: 1.5654e-04 - mean_absolute_error: 0.0094 - val_loss: 1.7236e-04 - val_mean_absolute_error: 0.0099\n",
      "Epoch 15/20\n",
      "120500/120500 [==============================] - 69s 571us/step - loss: 1.5520e-04 - mean_absolute_error: 0.0094 - val_loss: 1.6827e-04 - val_mean_absolute_error: 0.0098\n",
      "Epoch 16/20\n",
      "120500/120500 [==============================] - 69s 570us/step - loss: 1.5407e-04 - mean_absolute_error: 0.0093 - val_loss: 1.5417e-04 - val_mean_absolute_error: 0.0093\n",
      "Epoch 17/20\n",
      "120500/120500 [==============================] - 72s 601us/step - loss: 1.5280e-04 - mean_absolute_error: 0.0093 - val_loss: 1.5317e-04 - val_mean_absolute_error: 0.0093\n",
      "Epoch 18/20\n",
      "120500/120500 [==============================] - 70s 578us/step - loss: 1.4978e-04 - mean_absolute_error: 0.0092 - val_loss: 1.5325e-04 - val_mean_absolute_error: 0.0092\n",
      "Epoch 19/20\n",
      "120500/120500 [==============================] - 70s 583us/step - loss: 1.4992e-04 - mean_absolute_error: 0.0092 - val_loss: 1.4862e-04 - val_mean_absolute_error: 0.0091\n",
      "Epoch 20/20\n",
      "120500/120500 [==============================] - 69s 572us/step - loss: 1.4887e-04 - mean_absolute_error: 0.0092 - val_loss: 1.5142e-04 - val_mean_absolute_error: 0.0091\n"
     ]
    }
   ],
   "source": [
    "#logdir=\"mobility_logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "mae_st = []\n",
    "history = mobility_model.fit(\n",
    "    X_train, # Inputs\n",
    "    Y_train, # Outputs\n",
    "    epochs=20, # How many times to pass over the data\n",
    "    batch_size=64, # How many data rows to compute at once\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    #callbacks=[tensorboard_callback] # You would usually use more splits of the data if you plan to tune hyperparams\n",
    ")\n",
    "#print('mse')\n",
    "#print('mae')\n",
    "mobility_model.save(os.path.expanduser('./cnn_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobility_model.save(os.path.expanduser('./cnn_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05374995, -0.03753396,  0.06745441, -0.11199433,  0.02091711,\n",
       "       -0.00820353, -0.00368068, -0.05676004, -0.0364278 , -0.07744448,\n",
       "        0.00214456, -0.00459748,  0.02492774, -0.04774586, -0.00969402,\n",
       "        0.01586671], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = mobility_model.get_weights()\n",
    "weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline_history= baseline_mobility_model.fit()\n",
    "#smaller_history= smaller_mobility_model.fit()\n",
    "#bigger_history= bigger_mobility_model.fit()\n",
    "\n",
    "def plot_history(histories, key='binary_crossentropy'):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    for name, history in histories:\n",
    "        val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                       '.', markersize=10, linestyle=':', label=name.title()+' Validation')\n",
    "        plt.plot(history.epoch, history.history[key],\"^\", markersize=10, linestyle = '-',color=val[0].get_color(),\n",
    "                 label=name.title()+' Train')\n",
    "\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(key.replace('_',' ').title())\n",
    "        plt.legend()\n",
    "\n",
    "        plt.xlim([0,max(history.epoch)])\n",
    "\n",
    "\n",
    "plot_history([('baseline', baseline_history),\n",
    "              ('smaller', smaller_history),\n",
    "              ('bigger', bigger_history)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EARLY STOPPING CRITERIAS\n",
    "#mae_es= keras.callbacks.EarlyStopping(monitor='mean_squared_error', min_delta=1e-8, patience=200, verbose=1, mode='auto', restore_best_weights=True)\n",
    "valmae_es= keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error', min_delta=1e-10, patience=1000, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "mae_st = []\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# EPOCH REAL TIME COUNTER CLASS\n",
    "class PrintEpNum(keras.callbacks.Callback): # This is a function for the Epoch Counter\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"Current Epoch: \" + str(epoch+1) + \" Training Loss: \" + \"%4f\" %logs.get('loss') + '                                       \\r') # Updates current Epoch Number\n",
    "\n",
    "EPOCHS = 2000 # Number of EPOCHS\n",
    "\n",
    "# HISTORY Object which contains how the model learned\n",
    "\n",
    "# Training Values (Properties), Training Labels (Known Young's Moduli) \n",
    "history = mobility_model.fit(train_values, train_labels, batch_size=train_values.shape[0], \n",
    "                    epochs=EPOCHS, verbose = False, shuffle=False, validation_split=0.1, callbacks=[PrintEpNum(), valmae_es])\n",
    "\n",
    "\n",
    "# PLOTTING HISTORY USING MATPLOTLIB\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "plt.figure()\n",
    "plt.errorbar(all_labels, all_predictions, color='green', marker='o', markersize=12, linestyle='None', label='Training Data')\n",
    "plt.errorbar(test_labels, test_predictions, color='red', marker='o', markersize=12, linestyle='None',label='Testing Data')\n",
    "#plt.plot([-1, 20], [-1, 20], linestyle='dashed', color='black')\n",
    "plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),label='Loss on training set') \n",
    "plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),label = 'Validation loss')\n",
    "plt.xticks(np.linspace(0,20,11),fontsize=26)\n",
    "plt.yticks(np.linspace(0,20,11), fontsize=26)\n",
    "plt.xlim([-1,20])\n",
    "plt.ylim([-1,20])\n",
    "plt.grid()\n",
    "plt.legend(loc=2, fontsize=22)\n",
    "plt.xlabel('Epoch', fontsize=26)\n",
    "plt.ylabel('Mean Abs Error', fontsize=26)\n",
    "#plt.xlabel('Experimental Conductivity x10$^{-4}$ (S/cm)', fontsize=26) \n",
    "#plt.ylabel('Predicted Conductivity x10$^{-4}$ (S/cm)', fontsize=26)\n",
    "plt.title('Artificial Neural Network', fontsize=26)\n",
    "plt.show()\n",
    "fig.show()\n",
    "\n",
    "print(\"Loss at best epoch\", min(list(np.array(history.history['mean_absolute_error']))))\n",
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://proxy.nanohub.org/weber/1910229/wwOPefJEgELWDSHq/10/notebooks/LLZO_ANN_Regularization.ipynb\n",
    "\n",
    "[loss, mae] = model.evaluate(test_values, test_labels, verbose=0)\n",
    "\n",
    "print(\"Testing Set Mean Absolute Error: {:2.2f} GPa\".format(mae))\n",
    "\n",
    "    for _i in range(10):\n",
    "        print(\"Split\", _i) \n",
    "\n",
    "print(\"\\n Test Loss: \", loss)\n",
    "    mae_st.append(mae)\n",
    "\n",
    "print(\"Mean AVG MAE - 10 Splits: %f\"%(np.mean(mae_st)))\n",
    "\n",
    "#Dropout\n",
    "for drop in [0.1, 0.2,0.3]: \n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"Testing %d%% Dropout \"%(drop*100))\n",
    "#neuralnetwork_model.add(Dropout(drop))    \n",
    "    for _i in range(10):\n",
    "        print(\"Split\", _i) \n",
    "\n",
    "print(\"Mean AVG MAE - 10 Splits - %d%% Dropout: %f\"%(drop*100, np.mean(mae_st)))\n",
    "\n",
    "#Regularization\n",
    "for reg in [1e-4, 1e-5, 1e-6]: \n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"Testing L2 Regularization: Penalty %f \"%(reg))\n",
    "    \n",
    "    for _i in range(10):\n",
    "        print(\"Split\", _i)\n",
    "#neuralnetwork_model.add(Dense(30, activation='relu', use_bias = True, kernel_initializer=kernel_init, bias_initializer=bias_init, kernel_regularizer=regularizers.l2(reg) ))\n",
    "        \n",
    "print(\"\\n Test Loss: \", loss)\n",
    "        mae_st.append(mae)\n",
    "\n",
    "    print(\"Mean AVG MAE - 10 Splits - L2 Regularization Penalty %f: %f \"%(reg, np.mean(mae_st)))       \n",
    "        \n",
    "[loss, mae] = model.evaluate(test_values, test_labels, verbose=0)\n",
    "print(\"Testing Set Mean Absolute Error: {:2.4f} units\".format(mae))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import initializers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "class PrintEpNum(keras.callbacks.Callback): # This is a function for the Epoch Counter\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"Current Epoch: \" + str(epoch+1) + '\\r') # Updates current Epoch Number\n",
    "\n",
    "\n",
    "EPOCHS = 300 # Number of EPOCHS\n",
    "\n",
    "# HISTORY Object which contains how the model learned\n",
    "history = mobility_model.fit(train_values, train_labels, batch_size=train_values.shape[0], \\\n",
    "                    epochs=EPOCHS, validation_split=0.1, verbose = False, callbacks=[PrintEpNum()])\n",
    "\n",
    "# PLOTTING HISTORY USING MATPLOTLIB\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(history.epoch, np.array(history.history['acc']),label='Training Accuracy')\n",
    "plt.plot(history.epoch, np.array(history.history['val_acc']),label = 'Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [1000$]')\n",
    "    plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 5])\n",
    "\n",
    "plot_history(history)\n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "history = model.fit(trainValues, trainLabels, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=0,\n",
    "                    callbacks=[early_stop, PrintEpNum()])\n",
    "\n",
    "plot_history(history)\n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "fig.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(train_values, train_labels, verbose=0)\n",
    "\n",
    "print(\"Training Set Accuracy: %f\" %(acc))\n",
    "\n",
    "loss, acc = model.evaluate(test_values, test_labels, verbose=0)\n",
    "\n",
    "print(\"Testing Set Accuracy: %f\" %(acc))\n",
    "\n",
    "train_loss, train_acc = model.evaluate(trainImages, trainLabels)\n",
    "test_loss, test_acc = model.evaluate(testImages, testLabels)\n",
    "\n",
    "print('Train accuracy:', train_acc)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_values).flatten() # Prediction of the test set\n",
    "\n",
    "print(\"Elements in Test Set: \", labeled_elements)\n",
    "print(\"Real Values\", list(test_labels))\n",
    "print(\"Predictions\", list(test_predictions))\n",
    "\n",
    "values = np.concatenate((train_values, test_values), axis=0) # This line joins the values together to evaluate all of them\n",
    "all_predictions = model.predict(values).flatten()\n",
    "\n",
    "# MATCH PLOT\n",
    "\n",
    "layout0= go.Layout(hovermode='closest', xaxis= dict(title=go.layout.xaxis.Title(text='Experimental Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2),\n",
    "                   yaxis= dict(title=go.layout.yaxis.Title(text='Predicted Conductivity x10<sup>-4</sup> (S/cm)', font=dict(size=18)), zeroline= True, gridwidth= 2), width = 1000, height=1000)\n",
    "\n",
    "training = go.Scatter(x = all_labels, y = all_predictions, mode = 'markers', \n",
    "                      marker= dict(size= 12, color='green'), name= \"All Data\") # All values\n",
    "testing= go.Scatter(x = test_labels, y = test_predictions, mode = 'markers', \n",
    "                      marker= dict(size= 9, color= 'red', symbol = 'x'), name= \"Testing Data\") # Test set\n",
    "\n",
    "match = go.Scatter(x = [0,20], y = [0,20], mode = 'lines', name = \"Match\",line= dict( color = 'black')) # Match Line\n",
    "\n",
    "traces = [match,training,testing]\n",
    "fig= go.Figure(traces, layout=layout0)\n",
    "fig.update_yaxes(automargin=True)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testImages)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategies to reduce overfitting\n",
    "Add weight regularization\n",
    "L1 regularization, where the cost added is proportional to the absolute value of the weights (i.e. to what is called the \"L1 norm\" of the weights).\n",
    "\n",
    "L2 regularization, where the cost added is proportional to the square of the value of the weights (i.e. to what is called the \"L2 norm\" of the weights). \n",
    "\n",
    " Add dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L2 regularization\n",
    "l2_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n",
    "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
    "                       activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "\n",
    "l2_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy', 'binary_crossentropy'])\n",
    "\n",
    "l2_model_history = l2_model.fit(train_data, train_labels,\n",
    "                                epochs=20,\n",
    "                                batch_size=512,\n",
    "                                validation_data=(test_data, test_labels),\n",
    "                                verbose=2)\n",
    "\n",
    "# Add dropout\n",
    "dpt_model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])\n",
    "\n",
    "dpt_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy','binary_crossentropy'])\n",
    "\n",
    "dpt_model_history = dpt_model.fit(train_data, train_labels,\n",
    "                                  epochs=20,\n",
    "                                  batch_size=512,\n",
    "                                  validation_data=(test_data, test_labels),\n",
    "                                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history([('baseline', baseline_history),\n",
    "              ('l2', l2_model_history),\n",
    "              ('dropout', dpt_model_history)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save checkpoints during training\n",
    "The primary use case is to automatically save checkpoints both during and at the end of training. This way you can use a trained model without having to retrain it, or pick-up training where you left of—in case the training process was interrupted.\n",
    "\n",
    "tf.keras.callbacks.ModelCheckpoint is a callback that performs this task. The callback takes a couple of arguments to configure checkpointing.\n",
    "https://proxy.nanohub.org/weber/1910557/2sdrh4BRY4brrsPH/2/notebooks/TensorFlow-Save_Restore_Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels,  epochs = 10, \n",
    "          validation_data = (test_images,test_labels),\n",
    "          callbacks = [cp_callback])  # pass callback to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a single collection of TensorFlow checkpoint files that are updated at the end of each epoch. You can find these files in the path marked in the cell above, within the Jupyter Directory.\n",
    "\n",
    "Step 2.2. Test an Untrained Model\n",
    "Now let's create a new, untrained model. When restoring a model from only weights, you must have a model with the same architecture as the original model. Since it's the same model architecture, we can share weights despite that it's a different instance of the model. We can evaluate it on the test set, expecting that an untrained model will perform at chance levels (~10% accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the accuracy of the model improves if we load the weights from the checkpoint (~85% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint callback options\n",
    "This callback provides several options to give the resulting checkpoints unique names, and adjust the checkpointing frequency.\n",
    "\n",
    "We can train a new model, and save uniquely named checkpoints once every 5-epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the epoch in the file name. (uses `str.format`)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # Save weights, every 5-epochs.\n",
    "    period=5)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs = 50, callbacks = [cp_callback],\n",
    "          validation_data = (test_images,test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the resulting checkpoints and choose the latest one. The model used to create these checkpoints will not be saved; therefore we need to reset the model to retest it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually save weights\n",
    "Manually saving the weights is just as simple, using the Model.save_weights method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Restore the weights\n",
    "model = create_model()\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the entire model\n",
    "\n",
    "The entire model can be saved to a file that contains the weight values, the model's configuration, and even the optimizer's configuration. This allows you to checkpoint a model and resume training later—from the exact same state—without access to the original code.\n",
    "\n",
    "Saving a fully-functional model in Keras is very useful — you can load them in [TensorFlow.js](https://js.tensorflow.org/tutorials/import-keras.html) and then train and run them in web browsers.\n",
    "\n",
    "Keras provides a basic save format using the [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) standard. For our purposes, the saved model can be treated as a single binary blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save entire model to a HDF5 file\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now recreate the model from that file:\n",
    "new_model = keras.models.load_model('my_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check its accuracy:\n",
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "#By saving the entire model as shown, you can save the weight values, the model's configuration (architecture) and the optimizer configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard dev upload \\ \n",
    "  --logdir logs \\\n",
    "  --name \"Sample op-level graph\" \\\n",
    "  --one_shot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the learning curve for the trained model.\n",
    "\n",
    "This code will generate a plot where we show the test and train errors (MSE) as a function of epoch (one pass of all training examples through the NN).\n",
    "\n",
    "The learning curve will tell us if the model is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install livelossplot --quiet\n",
    "from livelossplot import PlotLossesKeras\n",
    "#from livelossplot import PlotLossesKeras, PlotPlossesKerasTF\n",
    "from livelossplot.inputs.keras import PlotLossesCallback\n",
    "from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
    "\n",
    "plotlosses = PlotLossesKeras()\n",
    "mobility_model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[plotlosses],\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the learning curve \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(0,)\n",
    "plt.legend(['Train', 'Validation',], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_encoded = solubility_model.predict(X_test, batch_size=64)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(X_test_encoded[:, 0], X_test_encoded[:, 1], c= Y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CNN to make mobility predictions\n",
    "Now that we've trained our model, we can use it to make mobility predictions for any SMILES string! We just have to convert the SMILES string to 1-hot representation, then feed it to the `mobility_model` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted log mobility for SMILES CCCC is 0.08399911969900131\n",
      "The predicted log mobility for SMILES CCCCCCCCCCCCCCCCCCCCCC is 0.059841908514499664\n",
      "The predicted log mobility for SMILES CCO is 0.07424404472112656\n"
     ]
    }
   ],
   "source": [
    "example_smiles = [\n",
    "    'CCCC',\n",
    "    'CCCCCCCCCCCCCCCCCCCCCC',\n",
    "    'CCO'\n",
    "]\n",
    "\n",
    "for smiles in example_smiles:\n",
    "    predict_test_input = smiles_to_onehots([smiles], charset, max_smiles_chars)\n",
    "    mobility_prediction = mobility_model.predict(predict_test_input)[0][0]\n",
    "    print(f'The predicted log mobility for SMILES {smiles} is {mobility_prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make a parity plot comparing the CNN model predictions to the ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe358815cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = mobility_model.predict(X_train)\n",
    "x_y_line = np.linspace(min(Y_train.flatten()), max(Y_train.flatten()), 500)\n",
    "plt.plot(Y_train.flatten(), preds.flatten(), 'o', label='predictions')\n",
    "plt.plot(x_y_line, x_y_line, label='y=x')\n",
    "plt.xlabel(\"mobility (ground truth)\")\n",
    "plt.ylabel(\"mobility (predicted)\")\n",
    "plt.title(\"Parity plot: predictions vs ground truth data\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model\n",
    "We can save/load this model for future use, using the `save()` and `load_model()` functions from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "mobility_model.save(\"mobility_model.hdf5\")\n",
    "\n",
    "# Load it back\n",
    "loaded_model = load_model(\"mobility_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>VAE model for generating SMILES strings</ins>\n",
    "In this section, we will set up a variational autoencoder to encode and decode SMILES strings. An autoencoder is a model that encodes the input to the model into a set of variables (known as encoded or 'latent variables'), which are then decoded to recover the original input. A variational autoencoder is an advanced version of an autoencoder where the encoded/latent variables are learnt as probability distributions rather than discrete values. You can learn more about autoencoders and variational autoencoders [here](https://www.jeremyjordan.me/variational-autoencoders/) and [here](https://www.jeremyjordan.me/autoencoders/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to define some new layers for this model, but we can also reuse old ones! (You will see this when we connect the model together.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.7\n",
      "1.13.1\n",
      "1.16.5\n"
     ]
    }
   ],
   "source": [
    "!python -V\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mse_loss_b(b):\n",
    "     def mseb(Y_train, X_train):\n",
    "         ...\n",
    "         a = np.ones_like(y_true) #numpy array here is not recommended\n",
    "         return K.mean(K.square(y_pred - y_true)) + a\n",
    "     return mseb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden activation layer\n",
    "hidden_size = 16\n",
    "dense_1_func = Dense(hidden_size, activation=\"relu\", name=\"Fully-Connected-Latent\", kernel_initializer=init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define the layers to map to the latent space. We then define a sampling function that samples from a gaussian distribution to return the sampled latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x7fe35383ee90>\n",
      "<keras.layers.core.Dense object at 0x7fe35383ed10>\n",
      "<keras.layers.core.Lambda object at 0x7fe35383ea10>\n"
     ]
    }
   ],
   "source": [
    "# VAE sampling \n",
    "# K.shape= Keras.shape\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal((batch, dim), mean=0.0, stddev=1.0)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon # mu + sigma*epsilon yields a shifted, rescaled gaussian, \n",
    "                                                     # if epsilon is the standard gaussian\n",
    "#latent space.last hidden_size = 16 to latent_dim = 32 \n",
    "# encode to latent space\n",
    "latent_dim = 32 \n",
    "z_mean_func = Dense(latent_dim, name='z_mean')\n",
    "log_z_func = Dense(latent_dim, name='z_log_var')\n",
    "z_func = Lambda(sampling, name='z_sample')\n",
    "print(z_mean_func)\n",
    "print(log_z_func)\n",
    "print(z_func)\n",
    "#z = Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define the RNN (Recurrent Neural Network) layers for decoding SMILES from latent space values. Recurrent neural networks are known to perform well for learning a time series of data, where each cell of the recurrent network can learn from the previous cells, thus learning time dependencies in the data. This RNN uses Gated Recurrent Units as cells and you can learn more about recurrent neural networks and Gated Recurrent Units [here](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this repeat vector just repeats the input `max_smiles_chars` times \n",
    "# so that we get a value for each character of the SMILES string\n",
    "repeat_1_func = RepeatVector(max_smiles_chars, name=\"Repeat-Latent-1\")\n",
    "\n",
    "# RNN decoder\n",
    "rnn_size = 32\n",
    "gru_1_func = GRU(rnn_size, name=\"RNN-decoder-1\", return_sequences=True, kernel_initializer=init_weights)\n",
    "gru_2_func = GRU(rnn_size, name=\"RNN-decoder-2\", return_sequences=True, kernel_initializer=init_weights)\n",
    "gru_3_func = GRU(rnn_size, name=\"RNN-decoder-3\", return_sequences=True, kernel_initializer=init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll define the output, which should map to the original SMILES input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_func = TimeDistributed(\n",
    "    Dense(charset_length, activation=\"softmax\", name=\"SMILES-Output\", kernel_initializer=init_weights), \n",
    "    name=\"Time-Distributed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.math import reduce_prod\n",
    "\n",
    "def _constant_if_small(value, shape, dtype, name):\n",
    "  try:\n",
    "    if np.reduce_prod(shape) < 1000:\n",
    "      return constant(value, shape=shape, dtype=dtype, name=name)\n",
    "  except TypeError:\n",
    "    # Happens when shape is a Tensor, list with Tensor elements, etc.\n",
    "    pass\n",
    "  return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined all the layers, we will connect them together to make a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting the VAE model as a graph\n",
    "\n",
    "# cnn encoder layers\n",
    "conv_1_fwd = conv_1_func(smiles_input)\n",
    "conv_2_fwd = conv_2_func(conv_1_fwd)\n",
    "conv_3_fwd = conv_3_func(conv_2_fwd)\n",
    "conv_4_fwd = conv_4_func(conv_3_fwd)\n",
    "\n",
    "# flattening\n",
    "flattened_convs = flatten_func(conv_4_fwd)\n",
    "dense_1_fwd = dense_1_func(flattened_convs)\n",
    "\n",
    "# latent space\n",
    "z_mean = z_mean_func(dense_1_fwd)\n",
    "z_log_var = log_z_func(dense_1_fwd)\n",
    "z = z_func([z_mean, z_log_var])\n",
    "\n",
    "# rnn decoder layers\n",
    "repeat_1_fwd = repeat_1_func(z)\n",
    "gru_1_fwd = gru_1_func(repeat_1_fwd)\n",
    "gru_2_fwd = gru_2_func(gru_1_fwd)\n",
    "gru_3_fwd = gru_3_func(gru_2_fwd)\n",
    "smiles_output = output_func(gru_3_fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View model structure and metadata\n",
    "Now the model is ready to train! But first we will compile the VAE model, then view model metadata, again using the [keras2ascii](https://github.com/stared/keras-sequential-ascii) tool. To compile the model, we will need to define our own VAE loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae loss function -- reconstruction loss (cross entropy) plus KL divergence loss against a Gaussian prior\n",
    "# Intuitive meaning for this loss function: \"Reconstruct the data but stay close to a Gaussian\"\n",
    "def vae_loss(x_input, x_predicted):\n",
    "    reconstruction_loss = K.sum(binary_crossentropy(x_input, x_predicted), axis=-1)\n",
    "    reconstruction_loss *= input_dim\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "# create model\n",
    "vae_model = Model(\n",
    "            inputs=[smiles_input],\n",
    "            outputs=[smiles_output]\n",
    ")\n",
    "\n",
    "# compile model\n",
    "vae_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=vae_loss,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "               Input   #####     40   23\n",
      "          InputLayer     |   -------------------         0     0.0%\n",
      "                       #####     40   23\n",
      "              Conv1D    \\|/  -------------------      1120     3.5%\n",
      "                relu   #####     38   16\n",
      "              Conv1D    \\|/  -------------------       784     2.4%\n",
      "                relu   #####     36   16\n",
      "              Conv1D    \\|/  -------------------       784     2.4%\n",
      "                relu   #####     34   16\n",
      "              Conv1D    \\|/  -------------------       784     2.4%\n",
      "                relu   #####     32   16\n",
      "             Flatten   ||||| -------------------         0     0.0%\n",
      "                       #####         512\n",
      "               Dense   XXXXX -------------------      8208    25.5%\n",
      "                relu   #####          16\n",
      "               Dense   XXXXX -------------------       544     1.7%\n",
      "                       #####          32\n",
      "               Dense   XXXXX -------------------       544     1.7%\n",
      "                       #####          32\n",
      "              Lambda   ????? -------------------         0     0.0%\n",
      "                       #####          32\n",
      "        RepeatVector   ????? -------------------         0     0.0%\n",
      "                       #####     40   32\n",
      "                 GRU   LLLLL -------------------      6240    19.4%\n",
      "                tanh   #####     40   32\n",
      "                 GRU   LLLLL -------------------      6240    19.4%\n",
      "                tanh   #####     40   32\n",
      "                 GRU   LLLLL -------------------      6240    19.4%\n",
      "                tanh   #####     40   32\n",
      "     TimeDistributed   ????? -------------------       759     2.4%\n",
      "                       #####     40   23\n"
     ]
    }
   ],
   "source": [
    "# view model as a graph\n",
    "keras2ascii(vae_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train VAE\n",
    "\n",
    "When training our VAE, we will see metrics printed after each epoch such as test/train loss and accuracy values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120500 samples, validate on 13385 samples\n",
      "Epoch 1/20\n",
      "120500/120500 [==============================] - 299s 2ms/step - loss: 1898.3080 - acc: 0.7577 - val_loss: 1725.2934 - val_acc: 0.7713\n",
      "Epoch 2/20\n",
      "120500/120500 [==============================] - 287s 2ms/step - loss: 1646.2692 - acc: 0.7790 - val_loss: 1515.7089 - val_acc: 0.7909\n",
      "Epoch 3/20\n",
      "120500/120500 [==============================] - 380s 3ms/step - loss: 1473.8204 - acc: 0.7958 - val_loss: 1428.0298 - val_acc: 0.8034\n",
      "Epoch 4/20\n",
      "120500/120500 [==============================] - 318s 3ms/step - loss: 1412.9525 - acc: 0.8038 - val_loss: 1397.9413 - val_acc: 0.8053\n",
      "Epoch 5/20\n",
      "120500/120500 [==============================] - 284s 2ms/step - loss: 1374.3107 - acc: 0.8093 - val_loss: 1322.5826 - val_acc: 0.8190\n",
      "Epoch 6/20\n",
      "120500/120500 [==============================] - 283s 2ms/step - loss: 1291.8081 - acc: 0.8242 - val_loss: 1253.5563 - val_acc: 0.8292\n",
      "Epoch 7/20\n",
      "120500/120500 [==============================] - 284s 2ms/step - loss: 1239.3353 - acc: 0.8314 - val_loss: 1218.6259 - val_acc: 0.8348\n",
      "Epoch 8/20\n",
      "120500/120500 [==============================] - 277s 2ms/step - loss: 1195.0093 - acc: 0.8384 - val_loss: 1162.2451 - val_acc: 0.8429\n",
      "Epoch 9/20\n",
      "120500/120500 [==============================] - 277s 2ms/step - loss: 1157.8179 - acc: 0.8439 - val_loss: 1124.5686 - val_acc: 0.8487\n",
      "Epoch 10/20\n",
      "120500/120500 [==============================] - 276s 2ms/step - loss: 1116.0357 - acc: 0.8496 - val_loss: 1110.0040 - val_acc: 0.8496\n",
      "Epoch 11/20\n",
      "120500/120500 [==============================] - 280s 2ms/step - loss: 1089.5124 - acc: 0.8533 - val_loss: 1070.9415 - val_acc: 0.8559\n",
      "Epoch 12/20\n",
      "120500/120500 [==============================] - 279s 2ms/step - loss: 1065.8106 - acc: 0.8571 - val_loss: 1172.3590 - val_acc: 0.8413\n",
      "Epoch 13/20\n",
      "120500/120500 [==============================] - 291s 2ms/step - loss: 1044.0272 - acc: 0.8602 - val_loss: 1029.2789 - val_acc: 0.8620\n",
      "Epoch 14/20\n",
      "120500/120500 [==============================] - 291s 2ms/step - loss: 1024.7519 - acc: 0.8631 - val_loss: 993.6348 - val_acc: 0.8673\n",
      "Epoch 15/20\n",
      "120500/120500 [==============================] - 292s 2ms/step - loss: 1003.8898 - acc: 0.8662 - val_loss: 986.7313 - val_acc: 0.8686\n",
      "Epoch 16/20\n",
      "120500/120500 [==============================] - 305s 3ms/step - loss: 983.6726 - acc: 0.8694 - val_loss: 973.1937 - val_acc: 0.8706\n",
      "Epoch 17/20\n",
      "120500/120500 [==============================] - 288s 2ms/step - loss: 959.9293 - acc: 0.8734 - val_loss: 945.8867 - val_acc: 0.8754\n",
      "Epoch 18/20\n",
      "120500/120500 [==============================] - 330s 3ms/step - loss: 947.1171 - acc: 0.8759 - val_loss: 956.0593 - val_acc: 0.8735\n",
      "Epoch 19/20\n",
      "120500/120500 [==============================] - 294s 2ms/step - loss: 925.5697 - acc: 0.8792 - val_loss: 967.7604 - val_acc: 0.8727\n",
      "Epoch 20/20\n",
      "120500/120500 [==============================] - 289s 2ms/step - loss: 910.5830 - acc: 0.8814 - val_loss: 886.1409 - val_acc: 0.8845\n"
     ]
    }
   ],
   "source": [
    "# Reset model and set all layers are trainable\n",
    "vae_model.reset_states()\n",
    "for layer in vae_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# fit model to training data\n",
    "history = vae_model.fit(\n",
    "    x=X_train,\n",
    "    y=X_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, X_test),\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the learning curve for the trained model. \n",
    "\n",
    "This code will generate a plot where we show the test and train errors as a function of epoch (one forward pass and one backward pass of all training examples through the NN).\n",
    "\n",
    "The learning curve will tell us if the model is overfitting or underfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the learning curve \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(0,)\n",
    "plt.legend(['Train', 'Validation',], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a decoder model and use to generate SMILES from noise\n",
    "\n",
    "Now that we have trained our VAE, we can use the decoding part of the VAE to generate SMILES strings! Let's start by defining our decoder model. Note that this model doesn't need to be compiled since we are not training this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect the decoder graph\n",
    "decoder_input = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "decoder_repeat_1_fwd = repeat_1_func(decoder_input)\n",
    "decoder_gru_1_fwd = gru_1_func(decoder_repeat_1_fwd)\n",
    "decoder_gru_2_fwd = gru_2_func(decoder_gru_1_fwd)\n",
    "decoder_gru_3_fwd = gru_3_func(decoder_gru_2_fwd)\n",
    "decoder_smiles_output = output_func(decoder_gru_3_fwd)\n",
    "\n",
    "# define decoder model\n",
    "decoder_model = Model(\n",
    "    inputs=[decoder_input],\n",
    "    outputs=[decoder_smiles_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "               Input   #####          32\n",
      "          InputLayer     |   -------------------         0     0.0%\n",
      "                       #####          32\n",
      "        RepeatVector   ????? -------------------         0     0.0%\n",
      "                       #####     40   32\n",
      "                 GRU   LLLLL -------------------      6240    32.0%\n",
      "                tanh   #####     40   32\n",
      "                 GRU   LLLLL -------------------      6240    32.0%\n",
      "                tanh   #####     40   32\n",
      "                 GRU   LLLLL -------------------      6240    32.0%\n",
      "                tanh   #####     40   32\n",
      "     TimeDistributed   ????? -------------------       759     3.9%\n",
      "                       #####     40   23\n"
     ]
    }
   ],
   "source": [
    "# view decoder graph. this should look like a subset of the VAE graph.\n",
    "keras2ascii(decoder_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate SMILES strings! First we will randomly sample from a unit gaussian distribution, feed the random samples into the decoder model, and take the output of the decoder model and convert it back into SMILES characters. Don't be surprised to see strange SMILES strings! We used a very small dataset, and did not train for very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")C1))CC=O\n",
      "C\n",
      "C1CCC2CCCCCC)C2\n",
      "C1CC2CCCCC)=O\n",
      "CC(C#OCC2CC1C2\n",
      "c1c(c(nn11C)O)\n",
      "CC()))12CCCC1\n",
      "CCCc))C1CCC1=O\n",
      "CC(C)CCCCO(C)N\n",
      "C#\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    \n",
    "    # draw from a unit gaussian \n",
    "    decoder_test_input = np.random.normal(0, 1, latent_dim).reshape(1, latent_dim)\n",
    "    decoder_test_output = decoder_model.predict(decoder_test_input)\n",
    "    \n",
    "    decoded_one_hots = np.argmax(decoder_test_output, axis = 2)\n",
    "\n",
    "    SMILES = ''\n",
    "    for char_idx in decoded_one_hots[0]:\n",
    "        if charset[char_idx] in [\"PAD\", \"NULL\"]: \n",
    "            break # Stop decoding if you hit padding or an out-of-vocab character (NULL)\n",
    "        \n",
    "        SMILES = SMILES + charset[char_idx]\n",
    "\n",
    "    print(SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save VAE and decoder models\n",
    "We can save/load these models for future use, again using the `save()` and `load_model()` functions from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save and load the decoder model \n",
    "decoder_model.save(\"decoder_model.hdf5\")\n",
    "loaded_decoder_model = load_model(\"decoder_model.hdf5\")\n",
    "\n",
    "# for VAEs, we must instantiate model w/ same architecture then load weights onto this model\n",
    "vae_model.save_weights(\"vae.hdf5\")\n",
    "loaded_vae_model = vae_model.load_weights(\"vae.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
