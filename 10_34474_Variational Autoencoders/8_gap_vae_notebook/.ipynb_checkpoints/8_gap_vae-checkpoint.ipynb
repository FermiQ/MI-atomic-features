{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Deep Learning for Materials \n",
    "\n",
    "## *Using deep learning to estimate solubility for organic molecules*\n",
    "\n",
    "The solubility of materials is crucial to pharmaceutical applications such as formulating novel drugs. In this notebook, you will learn how to train deep learning models to predict the aqueous solubility of organic materials given their composition. \n",
    "\n",
    "The composition will be specified as SMILES strings, which are a convenient way to represent the structure of organic materials. You can learn more about SMILES strings [here](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system). We will use these SMILES strings as inputs to a [convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) and predict the solubility of organic materials. We will also learn how to train [variational autoencoders](https://www.jeremyjordan.me/variational-autoencoders/) to learn SMILES string representations. Variational autoencoders are models used to learn low-dimensional representations of a high-dimensional dataset, and in our case these models will give us a low-dimensional numerical representation of a SMILES string, which can replace the sparse matrices often used to represent data when using convolutional neural networks.\n",
    "\n",
    "\n",
    "### Outline of this notebook:\n",
    "#### _Load and pre-process training data_ \n",
    "- Load solubility dataset containing many organic molecules and their associated solubilities\n",
    "- Pre-process data and split to test/train sets\n",
    "\n",
    "#### _Train a Convolutional neural network (CNN)_ \n",
    "- Train a CNN to predict solubility\n",
    "- Predict solubility from any given SMILES representation of a molecule \n",
    "\n",
    "#### _Train a Variational autoencoder (VAE)_\n",
    "- Train a VAE to take an encoded SMILES as input and learn a mapping from encoded SMILES to latent space and back to the input\n",
    "- Use a portion of the VAE to generate SMILES by sampling from a unit gaussian\n",
    "\n",
    "\n",
    "This notebook is a hands-on demo of *Deep learning for materials and chemicals*. This tutorial uses Python, some familiarity with programming would be beneficial but is not required. Run each code cell in order by clicking \"Shift + Enter\". Feel free to modify the code or change queries to familiarize yourself with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Let's start</ins> \n",
    "\n",
    "We'll start with required imports. These includes the [Keras](https://keras.io/) and [Tensorflow](https://www.tensorflow.org/) libraries for the neural network models, [Pandas](https://pandas.pydata.org/) and [Numpy](https://numpy.org/) to process data, as well as other relevant Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# general imports\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior() \n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "\n",
    "\n",
    "#import pymatgen as pymat\n",
    "#import mendeleev as mendel\n",
    "from subprocess import call\n",
    "import gzip\n",
    "\n",
    "from scipy.stats import norm\n",
    "from IPython.display import HTML\n",
    "\n",
    "# keras imports\n",
    "from keras.layers import (Input, Dense, Conv1D, MaxPool1D, Dropout, GRU, LSTM, TimeDistributed, Add, Flatten, RepeatVector, Lambda, Concatenate)\n",
    "from keras.models import Model, load_model\n",
    "from keras.metrics import binary_crossentropy\n",
    "from keras import initializers, regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "# Visualization\n",
    "from keras_sequential_ascii import keras2ascii\n",
    "\n",
    "\n",
    "# from utils import label_map_util\n",
    "# from utils import visualization_utils as vis_util\n",
    "\n",
    "#from object_detection.utils import label_map_util\n",
    "#from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# utils functions\n",
    "#from python_utils import *\n",
    "from utils import *\n",
    "\n",
    "# Hacky MacOS fix for Tensorflow runtimes... (You won't need this unless you are on MacOS)\n",
    "# This fixes a display bug with progress bars that can pop up on MacOS sometimes.\n",
    "#import sys\n",
    "#import os\n",
    "#sys.path.insert(0, '../src/')\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Remove warnings from output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#!python -m pip install --user numpy --upgrade\n",
    "#!python -m pip install --user tensorflow --upgrade\n",
    "#!python -m pip install --user numpy pycocotools==2.0.0\n",
    "\n",
    "#!python -V\n",
    "#import tensorflow as tf\n",
    "#print(tf.__version__)\n",
    "#import numpy as np\n",
    "#print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>Load, view, and preprocess dataset</ins> \n",
    "\n",
    "\n",
    "We will use the [ESOL dataset](http://moleculenet.ai/datasets-1) to train our models. The ESOL dataset contains the solubility of various small organic molecules. We will begin by loading the dataset as a dataframe and then inspecting some basic metadata. We'll also preprocess the dataset and create train/test splits for the Convolutional Neural Network (CNN) and Variational AutoEncoder (VAE) models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/nanohub/bbishnoi/data/results/vae/qm9.csv\n",
    "#dataset = pd.read_csv(\"/home/nanohub/bbishnoi/data/results/vae/qm9.csv\")\n",
    "# read dataset as a dataframe\n",
    "#dataset = pd.read_csv(\"../data/ESOL_delaney-processed.csv\")\n",
    "\n",
    "from random import shuffle\n",
    "dataset = pd.read_csv(\"./qm9.csv\")\n",
    "#dataset = pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/data/qm9.csv\")\n",
    "\n",
    "# This function randomly arranges the elements so we can have representation for all groups both in the training and testing set\n",
    "#shuffle(dataset) \n",
    "\n",
    "# print column names in dataset\n",
    "print(f\"Columns in dataset: {list(dataset.columns)}\")\n",
    "\n",
    "# print number of rows in dataset\n",
    "print(f\"\\nLength of dataset: {len(dataset)}\")\n",
    "\n",
    "# shuffle rows of the dataset (we could do this later as well when doing train/test splits)\n",
    "dataset = dataset.sample(frac=1, random_state=0)\n",
    "\n",
    "# show first 5 rows of dataframe\n",
    "dataset.head()\n",
    "#dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the range of solubilities found in the dataset by plotting a histogram of solubility values from the dataset. Our machine learning models will aim to predict these solubilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(dataset[\"measured log solubility in mols per litre\"])\n",
    "df = pd.DataFrame(dataset)\n",
    "display(df)\n",
    "df_condition = df[(df['alpha'] < 10) & (df[\"gap\"] > 0.25)]\n",
    "# \"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "# \"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"mol_id\" - Molecule ID (gdb9 index) mapping to the .sdf file\n",
    "#\"A\" - Rotational constant (unit: GHz)\n",
    "#\"B\" - Rotational constant (unit: GHz)\n",
    "#\"C\" - Rotational constant (unit: GHz)\n",
    "#\"mu\" - Dipole moment (unit: D)\n",
    "#\"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "#\"homo\" - Highest occupied molecular orbital energy (unit: Hartree)\n",
    "#\"lumo\" - Lowest unoccupied molecular orbital energy (unit: Hartree)\n",
    "#\"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"r2\" - Electronic spatial extent (unit: Bohr^2)\n",
    "#\"zpve\" - Zero point vibrational energy (unit: Hartree)\n",
    "#\"u0\" - Internal energy at 0K (unit: Hartree)\n",
    "#\"u298\" - Internal energy at 298.15K (unit: Hartree)\n",
    "#\"h298\" - Enthalpy at 298.15K (unit: Hartree)\n",
    "#\"g298\" - Free energy at 298.15K (unit: Hartree)\n",
    "#\"cv\" - Heat capavity at 298.15K (unit: cal/(mol*K))\n",
    "#\"u0_atom\" - Atomization energy at 0K (unit: kcal/mol)\n",
    "#\"u298_atom\" - Atomization energy at 298.15K (unit: kcal/mol)\n",
    "#\"h298_atom\" - Atomization enthalpy at 298.15K (unit: kcal/mol)\n",
    "display(df_condition)\n",
    "df_homo = df[df.homo.eq(0.26)]\n",
    "display(df_homo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we will plot a histogram of SMILES string lengths from dataset. These lengths will be used to determine the length of the inputs for our CNN and VAE models. Below are examples of the SMILES representation: \n",
    "1. Methane: 'C'\n",
    "2. Pentane: 'CCCCC'\n",
    "3. Methanol and Ethanol: 'CO' and 'CCO'\n",
    "4. Pyridine: 'C1:C:C:N:C:C:1'\n",
    "\n",
    "To learn more about the SMILES representation, click [here](https://chem.libretexts.org/Courses/University_of_Arkansas_Little_Rock/ChemInformatics_(2017)%3A_Chem_4399%2F%2F5399/2.3%3A_Chemical_Representations_on_Computer%3A_Part_III)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_lengths = map(len, dataset.smiles.values)\n",
    "#sns.distplot(list(smiles_lengths), bins=20, kde=False)\n",
    "ax = sns.distplot(list(smiles_lengths), bins=20, kde=True, kde_kws={\"color\": \"k\", \"label\": \"KDE\"})\n",
    "ax=plt.savefig('./gap_fig_smiles_lengths.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_smiles_lengths.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n",
    "# ax=plt.savefig('../data/fig_smiles_lengths.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smiles_lengths = map(len, dataset.smiles.values)\n",
    "# #sns.distplot(list(smiles_lengths), bins=20, kde=False)\n",
    "# sns.displot(list(smiles_lengths), bins=20, kde=False)\n",
    "\n",
    "# #ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "# ax=plt.savefig('./fig_gap.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Now we will pre-process the dataset for the CNN and VAE models. First, we'll get the unique character set from all SMILES strings in the dataset. Then we will use the unique character set to convert our SMILES strings to a one-hot representation, which is a representation that converts raw strings of text to numerical inputs for our models.\n",
    "\n",
    "In a one-hot representation, each character of our SMILES string is encoded as a vector of zeros, except for one non-zero value. For instance, the character 'C' in the SMILES string is converted to a vector of length 31, consisting of 30 zeros and one non-zero entry of one. The length of this vector (31 in our case) is the total number of unique characters in the dataset.\n",
    "\n",
    "Given a string of 5 characters (say Pentane, which is represented as 'CCCCC'), we would thus get 5 vectors each of length 31. Since different molecules have different SMILES string lengths, we can pre-define the length of each string to be the maximum length from the database, with smaller molecules represented with additional characters. In our case, this maximum length is 40 and we represent the extra characters for smaller molecules with pre-defined one-hot vectors. This means that each molecule is now represented as a set of 40 vectors, each of length 31. We can represent this as a 40x31 matrix.\n",
    "\n",
    "One-hot encoding is commonly used in natural language processing, and you can learn more about one-hot encoding [here](https://en.wikipedia.org/wiki/One-hot). \n",
    "\n",
    "Finally, we will define our input and output and create test/train splits in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = generate_charset(\n",
    "    dataset[\"smiles\"].values.ravel()\n",
    ")\n",
    "# get the number of unique characters\n",
    "charset_length = len(charset)\n",
    "# define max number of SMILES for model input vector\n",
    "max_smiles_chars = 40\n",
    "# dimension of input vector\n",
    "input_dim = charset_length * max_smiles_chars\n",
    "# get one-hot representation of the SMILES strings \n",
    "one_hots = smiles_to_onehots(dataset[\"smiles\"].values, charset, max_smiles_chars)\n",
    "# split input into train and test sets\n",
    "X_train = one_hots[:-13385] #This takes the first 133885-13385=120500  entries to be the Training Set\n",
    "X_test = one_hots[-13385:] # This takes the last 13385 entries to be the Testing Set\n",
    "\n",
    "# split output to train and test sets\n",
    "output = dataset[\"gap\"].values\n",
    "#output = dataset[\"homo\"].values\n",
    "#output = dataset[\"cv\"].values\n",
    "#output = dataset[\"r2\"].values\n",
    "\n",
    "# \"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "# \"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"mol_id\" - Molecule ID (gdb9 index) mapping to the .sdf file\n",
    "#\"A\" - Rotational constant (unit: GHz)\n",
    "#\"B\" - Rotational constant (unit: GHz)\n",
    "#\"C\" - Rotational constant (unit: GHz)\n",
    "#\"mu\" - Dipole moment (unit: D)\n",
    "#\"alpha\" - Isotropic polarizability (unit: Bohr^3)\n",
    "#\"homo\" - Highest occupied molecular orbital energy (unit: Hartree)\n",
    "#\"lumo\" - Lowest unoccupied molecular orbital energy (unit: Hartree)\n",
    "#\"gap\" - Gap between HOMO and LUMO (unit: Hartree)\n",
    "#\"r2\" - Electronic spatial extent (unit: Bohr^2)\n",
    "#\"zpve\" - Zero point vibrational energy (unit: Hartree)\n",
    "#\"u0\" - Internal energy at 0K (unit: Hartree)\n",
    "#\"u298\" - Internal energy at 298.15K (unit: Hartree)\n",
    "#\"h298\" - Enthalpy at 298.15K (unit: Hartree)\n",
    "#\"g298\" - Free energy at 298.15K (unit: Hartree)\n",
    "#\"cv\" - Heat capavity at 298.15K (unit: cal/(mol*K))\n",
    "#\"u0_atom\" - Atomization energy at 0K (unit: kcal/mol)\n",
    "#\"u298_atom\" - Atomization energy at 298.15K (unit: kcal/mol)\n",
    "#\"h298_atom\" - Atomization enthalpy at 298.15K (unit: kcal/mol)\n",
    "Y_train = output[:-13385] #This takes the first 133885-100=133785 entries to be the Training Set\n",
    "Y_test = output[-13385:] # This takes the last 100 entries to be the Testing Set\n",
    "\n",
    "# This Reshape function in the next two lines, turns each of the horizontal lists [ x, y, z] into a\n",
    "# vertical NumPy array [[x]\n",
    "#                       [y]\n",
    "#                       [z]]\n",
    "# This Step is required to work with the Sklearn Linear Model\n",
    "#Y_train = np.array(melt_train).reshape(-1,1) \n",
    "#Y_test  = np.array(melt_test).reshape(-1,1)\n",
    "print(len(X_train),len(X_test),len(Y_train),len(Y_test))\n",
    "# print(X_train[0]) # print a sample entry from the training set\n",
    "# print(X_test[0]) # print a sample entry from the training set\n",
    "# print(order)\n",
    "\n",
    "\n",
    "##  Train-Test Split  ##\n",
    "# https://proxy.nanohub.org/weber/1914019/IVqSH6gE0f3W6g9X/5/notebooks/mldefect.ipynb?\n",
    "# XX = copy.deepcopy(X)\n",
    "# n = dopant.size\n",
    "# m = np.int(X.size/n)\n",
    "\n",
    "# print(n)\n",
    "# print(m)\n",
    "\n",
    "# t = 0.20\n",
    "\n",
    "# X_train, X_test, Prop_train, Prop_test, dop_train, dop_test, sc_train, sc_test, ds_train, ds_test = train_test_split(XX, prop, dopant, CdX, doping_site, test_size=t)\n",
    "\n",
    "# n_tr = Prop_train.size\n",
    "# n_te = Prop_test.size\n",
    "\n",
    "# print(n_tr)\n",
    "# print(n_te)\n",
    "\n",
    "# Prop_train_fl = np.zeros(n_tr)\n",
    "# for i in range(0,n_tr):\n",
    "#     Prop_train_fl[i] = copy.deepcopy(float(Prop_train[i]))\n",
    "    \n",
    "# print(Prop_train_fl)\n",
    "\n",
    "# Prop_test_fl = np.zeros(n_te)\n",
    "# for i in range(0,n_te):\n",
    "#     Prop_test_fl[i] = copy.deepcopy(float(Prop_test[i]))\n",
    "    \n",
    "# print(Prop_test_fl)\n",
    "    \n",
    "# X_train_fl = [[0.0 for a in range(m)] for b in range(n_tr)]\n",
    "# for i in range(0,n_tr):\n",
    "#     for j in range(0,m):\n",
    "#         X_train_fl[i][j] = np.float(X_train[i][j])\n",
    "\n",
    "# print(X_train_fl)\n",
    "\n",
    "# X_test_fl = [[0.0 for a in range(m)] for b in range(n_te)]\n",
    "# for i in range(0,n_te):\n",
    "#     for j in range(0,m):\n",
    "#         X_test_fl[i][j] = np.float(X_test[i][j])\n",
    "\n",
    "# print(X_test_fl)\n",
    "\n",
    "# X_out_fl = [[0.0 for a in range(m)] for b in range(n_out)]\n",
    "# for i in range(0,n_out):\n",
    "#     for j in range(0,m):\n",
    "#         X_out_fl[i][j] = np.float(X_out[i][j])\n",
    "\n",
    "# print(X_out_fl)\n",
    "\n",
    "# X_all_fl = [[0.0 for a in range(m)] for b in range(n_all)]\n",
    "# for i in range(0,n_all):\n",
    "#     for j in range(0,m):\n",
    "#         X_all_fl[i][j] = np.float(X_all[i][j])\n",
    "\n",
    "# print(X_all_fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's briefly visualize what our input data looks like using a heatmap that shows the position of each character in the SMILES string, you can change the index to see various molecules. Each molecule is represented by a 40x31 sparse matrix, the bright spots in the heatmap indicate the position at which a one is found in the matrix. For instance, the first row has a bright spot at index 18, indicating that the first character is 'C'. The second row has a bright spot at index 23, which indicates that the second character is 'O'. For the compound Dimethoxymethane with a SMILES string 'COCOC', we expect the matrix to have alternating bright spots at index 18 and index 23 for the first five rows. Beyond that, the rows all have a bright spot at index 1, which stands for the extra characters padded on to our string to make all SMILES strings the same length. The heatmap below is plotted using the [Seaborn](https://seaborn.pydata.org/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 5\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(6*num_cols, 6*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, num_cols, i+1)\n",
    "    #plot_image(i, predictions, testLabels, testImages)\n",
    "#plt.figure(figsize=(30,30))\n",
    "#for i in range(25): #133785 \n",
    "    #plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    #plt.xlabel('Character')\n",
    "    #plt.ylabel('Position in SMILES String')\n",
    "    sns.heatmap(X_train[i])\n",
    "    #plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    #plt.xlabel(class_names[int(trainLabels[i])])\n",
    "    print(dataset.iloc[i]['smiles'])\n",
    "\n",
    "#plt.imshow(X_train[index]) # By altering 'index' you will see another of the pictures imported\n",
    "#plt.colorbar()\n",
    "#plt.grid(False)\n",
    "#print(\"Train Images Array shape:\", trainImages.shape)\n",
    "#print(\"Train Labels Array shape:\", trainLabels.shape)\n",
    "#print(\"Test Images Array shape:\", testImages.shape)\n",
    "#print(\"Test Labels Array shape:\", testLabels.shape)\n",
    "\n",
    "#index = 6986 #index runs from 0 to 138388\n",
    "#sns.heatmap(X_train[index]) # This is a single training example -- note that it is a matrix, not a single vector!\n",
    "#plt.xlabel('Character')\n",
    "#plt.ylabel('Position in SMILES String')\n",
    "#print(dataset.iloc[index]['smiles'])\n",
    "#ax=plt.savefig('gdrive/MyDrive/Colab Notebooks/data/fig_smiles_character.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n",
    "ax=plt.savefig('./gap_fig_smiles_character.png', dpi=600, facecolor='w', edgecolor='w',orientation='portrait', papertype=None, format=None,transparent=False, bbox_inches=None, pad_inches=0.1,frameon=None, metadata=None)\n",
    "\n",
    "#ax = sns.distplot(dataset[\"r2\"], rug=True, rug_kws={\"color\": \"g\"},kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\"alpha\": 1, \"color\": \"r\"})\n",
    "ax=plt.savefig('./fig_gap.png', dpi=600, facecolor='w', edgecolor='w',orientation='landscape', papertype='a4', format=None, transparent=False, bbox_inches=None, pad_inches=None, frameon=None, metadata=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>Supervised CNN model for predicting solubility</ins>\n",
    "\n",
    "In this section, we will set up a convolutional neural network to predict solubility using one-hot SMILES as input. A convolutional neural network is a machine learning model that is commonly used to classify images, and you can learn more about them [here](https://en.wikipedia.org/wiki/Convolutional_neural_network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create the model structure, starting with the input layer. As described above, each training example is a 40x31 matrix, which is the shape we pass to the Input layer in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer\n",
    "# NOTE: We feed in a sequence here! We're inputting up to max_smiles_chars characters, \n",
    "# and each character is an array of length charset_length\n",
    "\n",
    "\n",
    "smiles_input = Input(shape=(max_smiles_chars, charset_length), name=\"SMILES-Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define the convolution layers where each layer attempts to learn certain features of the images, such as edges and corners. The input to each layer (a matrix) is transformed via convolution operations, which are element by element multiplications of the input matrix and a filter matrix. The convolutional layer learns the filter matrix that will best identify unique features of the image. You can learn more about convolution operations and the math behind convolutional neural networks [here](https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for convolutional layers \n",
    "num_conv_filters = 16\n",
    "kernel_size = 3\n",
    "#kernel_init = initializers.RandomNormal(seed=0)\n",
    "#bias_init = initializers.Zeros()\n",
    "init_weights = initializers.glorot_normal(seed=0)\n",
    "\n",
    "# Define the convolutional layers\n",
    "# Multiple convolutions in a row is a common architecture (but there are many \"right\" choices here)\n",
    "conv_1_func = Conv1D(\n",
    "    filters=num_conv_filters, # What is the \"depth\" of the convolution? How many times do you look at the same spot?\n",
    "    kernel_size=kernel_size, # How \"wide\" of a spot does each filter look at?\n",
    "    name=\"Convolution-1\",\n",
    "    activation=\"relu\", # This is a common activation function: Rectified Linear Unit (ReLU)\n",
    "    kernel_initializer=init_weights #This defines the initial values for the weights\n",
    ")\n",
    "conv_2_func = Conv1D(\n",
    "    filters=num_conv_filters, \n",
    "    kernel_size=kernel_size, \n",
    "    name=\"Convolution-2\",\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=init_weights\n",
    ")\n",
    "conv_3_func = Conv1D(\n",
    "    filters=num_conv_filters, \n",
    "    kernel_size=kernel_size, \n",
    "    name=\"Convolution-3\",\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=init_weights\n",
    ")\n",
    "conv_4_func = Conv1D(\n",
    "    filters=num_conv_filters, \n",
    "    kernel_size=kernel_size,\n",
    "    name=\"Convolution-4\",\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=init_weights\n",
    ")\n",
    "\n",
    "# strides and paddind can be added in the convolution netowrk\n",
    "# strides=2, padding=\"same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four convolution layers defined above will attempt to learn features of the SMILES string (represented as a 40x31 matrix) that are relevant to predicting the solubility. To get a numerical prediction, we now flatten the output of the convolution and pass it to a set of regular `Dense` layers, the last layer predicting one value for the solubility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layer to flatten convolutions\n",
    "flatten_func = Flatten(name=\"Flattened-Convolutions\")\n",
    "\n",
    "# Define the activation function layer\n",
    "hidden_size = 32\n",
    "dense_1_func = Dense(hidden_size, activation=\"relu\", name=\"Fully-Connected\", kernel_initializer=init_weights)\n",
    "\n",
    "# Add a Dense layer with a L1 activity regularizer\n",
    "#dense_1_func = Dense(hidden_size, activation=\"relu\", name=\"Fully-Connected\", activity_regularizer=regularizers.l1(10e-5), kernel_initializer=init_weights)\n",
    "\n",
    "# Define output layer -- it's only one dimension since it is regression\n",
    "output_size = 1\n",
    "output_mobility_func = Dense(output_size, activation=\"linear\", name=\"Log-lumo\", kernel_initializer=init_weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined all the layers, we will connect them together to make a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect the CNN graph together\n",
    "conv_1_fwd = conv_1_func(smiles_input)\n",
    "conv_2_fwd = conv_2_func(conv_1_fwd)\n",
    "conv_3_fwd = conv_3_func(conv_2_fwd)\n",
    "conv_4_fwd = conv_4_func(conv_3_fwd)\n",
    "flattened_convs = flatten_func(conv_4_fwd)\n",
    "dense_1_fwd = dense_1_func(flattened_convs)\n",
    "output_mobility_fwd = output_mobility_func(flattened_convs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View model structure and metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is ready to train! But first we will define the model as `solubility_model` and compile it, then view some information on the model using the [keras2ascii](https://github.com/stared/keras-sequential-ascii) tool, which visually represents the layers in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mobility_model = Model(\n",
    "            inputs=[smiles_input],\n",
    "            outputs=[output_mobility_fwd]\n",
    ")\n",
    "mae_st = []\n",
    "# compile model\n",
    "#optimizer = optimizers.RMSprop(0.002) # Root Mean Squared Propagation\n",
    "# This line matches the optimizer to the model and states which metrics will evaluate the model's accuracy\n",
    "\n",
    "# loss= mse, mae\n",
    "# loss= categorical_crossentropy\n",
    "#loss='sparse_categorical_crossentropy'\n",
    "#loss='binary_crossentropy'\n",
    "#metrics=['accuracy', 'binary_crossentropy']\n",
    "#metrics=['accuracy']\n",
    "mobility_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "mobility_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install keras_sequential_ascii\n",
    "from keras_sequential_ascii import keras2ascii\n",
    "# view model as a graph\n",
    "keras2ascii(mobility_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN\n",
    "\n",
    "Now we will train our CNN solubility model to the training data! During training, we will see metrics printed after each epoch such as test/train loss (both as Mean Squared Error (MSE) and Mean Absolute Error (MAE))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#logdir=\"mobility_logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "mae_st = []\n",
    "history = mobility_model.fit(\n",
    "    X_train, # Inputs\n",
    "    Y_train, # Outputs\n",
    "    epochs=20, # How many times to pass over the data\n",
    "    batch_size=64, # How many data rows to compute at once\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    #callbacks=[tensorboard_callback] # You would usually use more splits of the data if you plan to tune hyperparams\n",
    ")\n",
    "#print('mse')\n",
    "#print('mae')\n",
    "mobility_model.save(os.path.expanduser('./gap_cnn_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the learning curve for the trained model.\n",
    "\n",
    "This code will generate a plot where we show the test and train errors (MSE) as a function of epoch (one pass of all training examples through the NN).\n",
    "\n",
    "The learning curve will tell us if the model is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(0,)\n",
    "plt.legend(['Train', 'Validation',], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CNN to make solubility predictions\n",
    "Now that we've trained our model, we can use it to make solubility predictions for any SMILES string! We just have to convert the SMILES string to 1-hot representation, then feed it to the `solubility_model` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_smiles = ['CC(C)CCCCO(C)N','CCC(C)CCC(C)OC','CC=CC1CCC1=O','CCOC()CCC','CC1(CC1OC)C#C']\n",
    "                  \n",
    "for smiles in example_smiles:\n",
    "    predict_test_input = smiles_to_onehots([smiles], charset, max_smiles_chars)\n",
    "    mobility_prediction = mobility_model.predict(predict_test_input)[0][0]\n",
    "    print(f'The predicted log mobility for SMILES {smiles} is {mobility_prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make a parity plot comparing the CNN model predictions to the ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mobility_model.predict(X_train)\n",
    "x_y_line = np.linspace(min(Y_train.flatten()), max(Y_train.flatten()), 500)\n",
    "plt.figure(figsize=(6,6))\n",
    "#plt.subplots_adjust(left=0.16, bottom=0.16, right=0.95, top=0.90)\n",
    "#plt.rc('font', family='Arial narrow')\n",
    "\n",
    "plt.plot(Y_train.flatten(), preds.flatten(), 'o', label='predictions')\n",
    "plt.plot(x_y_line, x_y_line, label='y=x')\n",
    "plt.xlabel(\"mobility (ground truth)\", fontname='Arial Narrow', size=32)\n",
    "plt.ylabel(\"mobility (predicted)\", fontname='Arial Narrow', size=32)\n",
    "plt.title('Parity plot: predictions vs ground truth data', fontsize=20, pad=12)\n",
    "plt.rc('xtick', labelsize=28)\n",
    "plt.rc('ytick', labelsize=28)\n",
    "#a = [-175,0,125]\n",
    "#b = [-175,0,125]\n",
    "#plt.plot(b, a, c='k', ls='-')\n",
    "#plt.legend(loc='upper left',ncol=1, frameon=True, prop={'family':'Arial narrow','size':16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model\n",
    "We can save/load this model for future use, using the `save()` and `load_model()` functions from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "mobility_model.save(\"gap_mobility_model.hdf5\")\n",
    "\n",
    "# Load it back\n",
    "loaded_model = load_model(\"gap_mobility_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>VAE model for generating SMILES strings</ins>\n",
    "In this section, we will set up a variational autoencoder to encode and decode SMILES strings. An autoencoder is a model that encodes the input to the model into a set of variables (known as encoded or 'latent variables'), which are then decoded to recover the original input. A variational autoencoder is an advanced version of an autoencoder where the encoded/latent variables are learnt as probability distributions rather than discrete values. You can learn more about autoencoders and variational autoencoders [here](https://www.jeremyjordan.me/variational-autoencoders/) and [here](https://www.jeremyjordan.me/autoencoders/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to define some new layers for this model, but we can also reuse old ones! (You will see this when we connect the model together.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden activation layer\n",
    "hidden_size = 16\n",
    "dense_1_func = Dense(hidden_size, activation=\"relu\", name=\"Fully-Connected-Latent\", kernel_initializer=init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define the layers to map to the latent space. We then define a sampling function that samples from a gaussian distribution to return the sampled latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE sampling \n",
    "# K.shape= Keras.shape\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal((batch, dim), mean=0.0, stddev=1.0)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon # mu + sigma*epsilon yields a shifted, rescaled gaussian, \n",
    "                                                     # if epsilon is the standard gaussian\n",
    "#latent space.last hidden_size = 16 to latent_dim = 32 \n",
    "# encode to latent space\n",
    "latent_dim = 32 \n",
    "z_mean_func = Dense(latent_dim, name='z_mean')\n",
    "log_z_func = Dense(latent_dim, name='z_log_var')\n",
    "z_func = Lambda(sampling, name='z_sample')\n",
    "#print(z_mean_func)\n",
    "#print(log_z_func)\n",
    "#print(z_func)\n",
    "#z = Lambda(sampling)([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define the RNN (Recurrent Neural Network) layers for decoding SMILES from latent space values. Recurrent neural networks are known to perform well for learning a time series of data, where each cell of the recurrent network can learn from the previous cells, thus learning time dependencies in the data. This RNN uses Gated Recurrent Units as cells and you can learn more about recurrent neural networks and Gated Recurrent Units [here](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this repeat vector just repeats the input `max_smiles_chars` times \n",
    "# so that we get a value for each character of the SMILES string\n",
    "repeat_1_func = RepeatVector(max_smiles_chars, name=\"Repeat-Latent-1\")\n",
    "\n",
    "# RNN decoder\n",
    "rnn_size = 32\n",
    "gru_1_func = GRU(rnn_size, name=\"RNN-decoder-1\", return_sequences=True, kernel_initializer=init_weights)\n",
    "gru_2_func = GRU(rnn_size, name=\"RNN-decoder-2\", return_sequences=True, kernel_initializer=init_weights)\n",
    "gru_3_func = GRU(rnn_size, name=\"RNN-decoder-3\", return_sequences=True, kernel_initializer=init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll define the output, which should map to the original SMILES input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_func = TimeDistributed(\n",
    "    Dense(charset_length, activation=\"softmax\", name=\"SMILES-Output\", kernel_initializer=init_weights), \n",
    "    name=\"Time-Distributed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined all the layers, we will connect them together to make a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting the VAE model as a graph\n",
    "\n",
    "# cnn encoder layers\n",
    "conv_1_fwd = conv_1_func(smiles_input)\n",
    "conv_2_fwd = conv_2_func(conv_1_fwd)\n",
    "conv_3_fwd = conv_3_func(conv_2_fwd)\n",
    "conv_4_fwd = conv_4_func(conv_3_fwd)\n",
    "\n",
    "# flattening\n",
    "flattened_convs = flatten_func(conv_4_fwd)\n",
    "dense_1_fwd = dense_1_func(flattened_convs)\n",
    "\n",
    "# latent space\n",
    "z_mean = z_mean_func(dense_1_fwd)\n",
    "z_log_var = log_z_func(dense_1_fwd)\n",
    "z = z_func([z_mean, z_log_var])\n",
    "\n",
    "# rnn decoder layers\n",
    "repeat_1_fwd = repeat_1_func(z)\n",
    "gru_1_fwd = gru_1_func(repeat_1_fwd)\n",
    "gru_2_fwd = gru_2_func(gru_1_fwd)\n",
    "gru_3_fwd = gru_3_func(gru_2_fwd)\n",
    "smiles_output = output_func(gru_3_fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View model structure and metadata\n",
    "Now the model is ready to train! But first we will compile the VAE model, then view model metadata, again using the [keras2ascii](https://github.com/stared/keras-sequential-ascii) tool. To compile the model, we will need to define our own VAE loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae loss function -- reconstruction loss (cross entropy) plus KL divergence loss against a Gaussian prior\n",
    "# Intuitive meaning for this loss function: \"Reconstruct the data but stay close to a Gaussian\"\n",
    "def vae_loss(x_input, x_predicted):\n",
    "    reconstruction_loss = K.sum(binary_crossentropy(x_input, x_predicted), axis=-1)\n",
    "    reconstruction_loss *= input_dim\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "# create model\n",
    "vae_model = Model(\n",
    "            inputs=[smiles_input],\n",
    "            outputs=[smiles_output]\n",
    ")\n",
    "\n",
    "# compile model\n",
    "vae_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=vae_loss,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# view model as a graph\n",
    "keras2ascii(vae_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train VAE\n",
    "\n",
    "When training our VAE, we will see metrics printed after each epoch such as test/train loss and accuracy values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset model and set all layers are trainable\n",
    "vae_model.reset_states()\n",
    "for layer in vae_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# fit model to training data\n",
    "history = vae_model.fit(\n",
    "    x=X_train,\n",
    "    y=X_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, X_test),\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the learning curve for the trained model. \n",
    "\n",
    "This code will generate a plot where we show the test and train errors as a function of epoch (one forward pass and one backward pass of all training examples through the NN).\n",
    "\n",
    "The learning curve will tell us if the model is overfitting or underfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the learning curve \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(0,)\n",
    "plt.legend(['Train', 'Validation',], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a decoder model and use to generate SMILES from noise\n",
    "\n",
    "Now that we have trained our VAE, we can use the decoding part of the VAE to generate SMILES strings! Let's start by defining our decoder model. Note that this model doesn't need to be compiled since we are not training this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect the decoder graph\n",
    "decoder_input = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "decoder_repeat_1_fwd = repeat_1_func(decoder_input)\n",
    "decoder_gru_1_fwd = gru_1_func(decoder_repeat_1_fwd)\n",
    "decoder_gru_2_fwd = gru_2_func(decoder_gru_1_fwd)\n",
    "decoder_gru_3_fwd = gru_3_func(decoder_gru_2_fwd)\n",
    "decoder_smiles_output = output_func(decoder_gru_3_fwd)\n",
    "\n",
    "# define decoder model\n",
    "decoder_model = Model(\n",
    "    inputs=[decoder_input],\n",
    "    outputs=[decoder_smiles_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# view decoder graph. this should look like a subset of the VAE graph.\n",
    "keras2ascii(decoder_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate SMILES strings! First we will randomly sample from a unit gaussian distribution, feed the random samples into the decoder model, and take the output of the decoder model and convert it back into SMILES characters. Don't be surprised to see strange SMILES strings! We used a very small dataset, and did not train for very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(20):\n",
    "    \n",
    "    # draw from a unit gaussian \n",
    "    decoder_test_input = np.random.normal(0, 1, latent_dim).reshape(1, latent_dim)\n",
    "    decoder_test_output = decoder_model.predict(decoder_test_input)\n",
    "    \n",
    "    decoded_one_hots = np.argmax(decoder_test_output, axis = 2)\n",
    "\n",
    "    SMILES = ''\n",
    "    for char_idx in decoded_one_hots[0]:\n",
    "        if charset[char_idx] in [\"PAD\", \"NULL\"]: \n",
    "            break # Stop decoding if you hit padding or an out-of-vocab character (NULL)\n",
    "        \n",
    "        SMILES = SMILES + charset[char_idx]\n",
    "\n",
    "    print(SMILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save VAE and decoder models\n",
    "We can save/load these models for future use, again using the `save()` and `load_model()` functions from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save and load the decoder model \n",
    "decoder_model.save(\"gap_decoder_model.hdf5\")\n",
    "loaded_decoder_model = load_model(\"gap_decoder_model.hdf5\")\n",
    "\n",
    "# for VAEs, we must instantiate model w/ same architecture then load weights onto this model\n",
    "vae_model.save_weights(\"gap_vae.hdf5\")\n",
    "loaded_vae_model = vae_model.load_weights(\"gap_vae.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
