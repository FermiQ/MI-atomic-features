{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering a parsimonious neural network - melting temperature laws #\n",
    "\n",
    "<i>Saaketh Desai</i>, and <i>Alejandro Strachan</i>, School of Materials Engineering, Purdue University <br>\n",
    "\n",
    "This notebook describes the procedure to train a parsimonious neural network, i.e., a network designed to reproduce the training and testing datasets in the simplest, most interpretable manner possible. We use Keras to train neural networks and the DEAP package for genetic algorithms. The outline of this notebook is:\n",
    "\n",
    "1. Read datasets and split into training and testing sets\n",
    "2. Create a generic model\n",
    "3. Define the objective function for the genetic algorithm\n",
    "4. Set up the genetic algorithm and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter notebook --version\n",
    "!python --version\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "# 5.7.8\n",
    "# Python 3.7.7\n",
    "# 1.13.1\n",
    "# 0.24.1\n",
    "# 2.2.4\n",
    "# 0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "#Import Keras layers to build custom neural networks\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras.layers import Dense, Input, Activation, multiply\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers.merge import add, concatenate\n",
    "# DEAP Distributed Evolutionary Algorithms in Python Genetic Algorithm (GA)\n",
    "# https://github.com/DEAP/deap\n",
    "# https://deap.readthedocs.io/en/master/examples/index.html\n",
    "#Import modules from the ‘deap’ package\n",
    "from deap import base, creator, tools, algorithms  \n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read training and testing data##\n",
    "We read in a CSV file containing the fundamental quantities such as bulk modulus, shear modulus, density etc., along with the experimental melting temperature. We then compute quantities such as effective sound speed ($v_m$) to compute effective temperatures $\\theta_0, \\theta_1, \\theta_2, \\theta_3$ and normalized inputs $\\theta_1', \\theta_2', \\theta_3'$. Finally, we use the `train_test split()` method from scikit-learn to split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 15)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/Combined_data_v3.csv\")\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 6.62607015*1e-34\n",
    "k = 1.380649*1e-23\n",
    "Na = 6.0221407*1e23\n",
    "pi = np.pi\n",
    "hbar = 1.054571817*1e-34\n",
    "# Compute Debye temp and effective sound speed\n",
    "# define the volume and temp to unified\n",
    "vs = np.sqrt(df['G_VRH']/df['density']) #from Zack\n",
    "vp = np.sqrt((df['K_VRH'] + (4/3)*df['G_VRH'])/df['density']) #from Zack\n",
    "vm = ( 3/( (1/vp)**3 + 2*(1/vs)**3 ) )**(1/3) #from JP Poirier paper\n",
    "\n",
    "df['debye_temp'] = 10**13*(h/k)*(3/(4*pi*df['volume_per_atom']))**(1/3)*vm\n",
    "\n",
    "df['a'] = (df['volume_per_atom'])**(1/3)\n",
    "\n",
    "a = df['a']\n",
    "m = df['mean_mass']\n",
    "G = df['G_VRH']\n",
    "K = df['K_VRH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 4) (218, 1)\n",
      "(174, 4) (174, 1)\n",
      "(44, 4) (44, 1)\n"
     ]
    }
   ],
   "source": [
    "# define the temp unified unitless \n",
    "theta0 = (1.054571817/1.380649)*100*vm/a #hcross*vm/(k*a)\n",
    "theta1 = (1.054571817**2*6.0221407/1.380649)*10*(1/(m*a**2)) #hcross**2/(m*a**2*k)\n",
    "theta2 = (1/1.380649)*100*(a**3*G) #a**3*G/k\n",
    "theta3 = (1/1.380649)*100*(a**3*K) #a**3*K/k\n",
    "# temp to normailsed  Compute theta(s)\n",
    "theta1_prime = theta1/theta0\n",
    "theta2_prime = theta2/theta0\n",
    "theta3_prime = theta3/theta0\n",
    "# define the forth element in arrary\n",
    "ones = np.ones(len(theta1_prime))\n",
    "# define the Tm by the to normailsed \n",
    "Tm_prime = df['Tm']/theta0\n",
    "\n",
    "#Create input/output arrays\n",
    "inputs = np.array([theta1_prime, theta2_prime, theta3_prime, ones], dtype='float') # theta0, theta1,theta2, one \n",
    "inputs = inputs.T # transpose\n",
    "outputs = np.array(Tm_prime).reshape(-1, 1) # reshape \n",
    "\n",
    "print (inputs.shape, outputs.shape)\n",
    "#Split into train/test sets\n",
    "train_inputs, test_inputs, train_outputs, test_outputs = train_test_split(inputs, outputs, test_size=0.2, random_state=0)\n",
    "print (train_inputs.shape, train_outputs.shape)\n",
    "print (test_inputs.shape, test_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different activation function encoding python directory \n",
    "act_dict = {0: 'linear', 1: 'squared', 2: 'inverse', 3: 'multiply', 4: 'tanh'}\n",
    "np.random.seed(300000)\n",
    "weight_dict = {0: 0, 1: 1, 2: np.random.uniform(-1,1,1)[0]}\n",
    "nact_terms = 4\n",
    "nweight_terms = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a generic model\n",
    "\n",
    "We will now create a generic model whose activations and weights will be optimized to discover PNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define funtion for customised layer in NN\n",
    "def squared_act(x):\n",
    "    return x*x\n",
    "\n",
    "def inverse_act(x):\n",
    "    return 1/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node(input1, input2, input3, name, trainable1, trainable2, trainable3, act, x, idx):\n",
    "    base = name\n",
    "    n1 = base + \"1\"\n",
    "    n2 = base + \"2\"\n",
    "    n3 = base + \"3\"\n",
    "    #Each connection is a Dense layer with 1 input and 1 output\n",
    "    an1 = Dense(1, activation = 'linear', use_bias = False, name=n1, trainable=trainable1) (input1) #customised layer from node 1 in layer 1 to 1 connection layer 2 and input1 \n",
    "    an2 = Dense(1, activation = 'linear', use_bias = False, name=n2, trainable=trainable2) (input2) #customised layer from node 2 in layer 1 to 1 connection and layer 2 and  input1 \n",
    "    an3 = Dense(1, activation = 'linear', use_bias = False, name=n3, trainable=trainable3) (input3) #customised layer from node 3 in layer 1 to 1 connection and layer 2 and input1 \n",
    "    \n",
    "    node_list = [an1, an2, an3] # list of node \n",
    "    if (act == \"multiply\"):    #  customised actication function multiple or cube\n",
    "        non_zero_list = []\n",
    "        zero_list = []\n",
    "        for i, j in enumerate(node_list):   #  dont muliple with zero if one of activation is zero in node list, will make weight zero \n",
    "            if (x[idx+i] == 1 or x[idx+i] == 2): #For a multiply activation, multiply non-zero nodes\n",
    "                non_zero_list.append(j)\n",
    "            else:\n",
    "                zero_list.append(j)\n",
    "        if ( len(non_zero_list) == 0 ):\n",
    "            non_zero_list = node_list\n",
    "            an = multiply(non_zero_list)\n",
    "        if ( len(non_zero_list) == 1 ):\n",
    "            anx = non_zero_list[0]\n",
    "            an = add([anx, zero_list[0], zero_list[1]])\n",
    "        else:\n",
    "            an = multiply(non_zero_list)\n",
    "    else:\n",
    "        an = add(node_list)   #Add each connection\n",
    "        if (act == \"squared\"):  #  squared or inverse activation on basis of condition  \n",
    "            an = Activation(squared_act) (an)\n",
    "        elif (act == \"inverse\"):\n",
    "            an = Activation(inverse_act) (an) # Apply activation\n",
    "        else:\n",
    "            an = Activation(act) (an)\n",
    "    return an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create customised model now\n",
    "def create_model(x):\n",
    "    #initializer = keras.initializers.RandomUniform(minval=-0.001, maxval=0.001, seed=0)\n",
    "    bias_initial = keras.initializers.Zeros()\n",
    "\n",
    "    trainable_list = []\n",
    "    for i in range(nweight_terms):\n",
    "        if (x[i+nact_terms] == 2):\n",
    "            trainable_list.append(True)\n",
    "        else:\n",
    "            trainable_list.append(False)\n",
    "\n",
    "    input1 = Input(shape=(1,))  # inputs idenstified by (shape=(1,)\n",
    "    input2 = Input(shape=(1,))\n",
    "    input3 = Input(shape=(1,))\n",
    "    input4 = Input(shape=(1,))\n",
    "    # Create nodes a1, a2, a3 in the first hidden layer\n",
    "    a1 = create_node(input1, input2, input3, \"a1\", trainable_list[0], trainable_list[1],   # custome layers connection to make one striing in nw end to end\n",
    "                     trainable_list[2], act_dict[x[0]], x, 0+nact_terms)\n",
    "    a2 = create_node(input1, input2, input3, \"a2\", trainable_list[3], trainable_list[4], \n",
    "                     trainable_list[5], act_dict[x[1]], x, 3+nact_terms)\n",
    "    a3 = create_node(input1, input2, input3, \"a3\", trainable_list[6], trainable_list[7], \n",
    "                     trainable_list[8], act_dict[x[2]], x, 6+nact_terms)\n",
    "\n",
    "    an1 = Dense(1, activation = 'linear', use_bias = False, name='output1', trainable=trainable_list[9]) (a1)   #customised layer from node 1 in layer 2 to dense connection layer 3 and input1 \n",
    "    an2 = Dense(1, activation = 'linear', use_bias = False, name='output2', trainable=trainable_list[10]) (a2)\n",
    "    an3 = Dense(1, activation = 'linear', use_bias = False, name='output3', trainable=trainable_list[11]) (a3)\n",
    "    # Setup connections for output layer\n",
    "    an4 = Dense(1, activation = 'linear', use_bias = False, name='output4', trainable=trainable_list[12]) (input4)\n",
    "\n",
    "    act = act_dict[x[3]]\n",
    "    node_list = [an1, an2, an3, an4]\n",
    "    if (act == \"multiply\"):\n",
    "        non_zero_list = []\n",
    "        zero_list = []\n",
    "        for i, j in enumerate(node_list):   # same for lyer 2,  dont muliple with zero if one of activation is zero in node list, will make weight zero \n",
    "            if (x[9+i] == 1 or x[9+i] == 2): # Add/multiply connections and apply activation functions to get output neuron\n",
    "                non_zero_list.append(j)\n",
    "            else:\n",
    "                zero_list.append(j)\n",
    "        if ( len(non_zero_list) == 0 ):\n",
    "            non_zero_list = node_list\n",
    "            an = multiply(non_zero_list)\n",
    "        elif ( len(non_zero_list) == 1 ):\n",
    "            anx = non_zero_list[0]\n",
    "            an = add([anx, zero_list[0], zero_list[1], zero_list[2]])\n",
    "        else:\n",
    "            an = multiply(non_zero_list)\n",
    "    else:\n",
    "        an = add(node_list)\n",
    "        if (act == \"squared\"):                    #  same layer 2 squared or inverse activation on basis of condition \n",
    "            an = Activation(squared_act) (an)\n",
    "        elif (act == \"inverse\"):\n",
    "            an = Activation(inverse_act) (an)\n",
    "        else:\n",
    "            an = Activation(act) (an)\n",
    "    output = an\n",
    "    # Define model with 3 inputs, 1 bias, and 1 output\n",
    "    model = Model(inputs=[input1, input2, input3, input4], outputs=[output])\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    model.compile(loss='mse', optimizer=optimizer)  # model comple to draw kera entire network\n",
    "    \n",
    "    layer_list = []\n",
    "    for i in range(len(model.layers)):\n",
    "        name = model.layers[i].name\n",
    "        if ( (\"activation\" in name) or (\"input\" in name) or (\"add\" in name) or (\"multiply\" in name) ): # cudtome activation to feed in entire network\n",
    "            continue\n",
    "        else:\n",
    "            layer_list.append(i)\n",
    "    \n",
    "    for i in range(len(layer_list)):\n",
    "        model.layers[layer_list[i]].set_weights( [ np.array( [[ weight_dict[x[nact_terms+i]] ]] ) ] )\n",
    "        #model.layers[layer_list[i]].set_weights( [ np.array( [[ weights_list[i] ]] ) ] )\n",
    "\n",
    "    #model.summary()\n",
    "    #Set some model weights\n",
    "    return model, trainable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and keras.callbacks\n",
    "\n",
    "losses = []\n",
    "class PrintEpNum(keras.callbacks.Callback): # This is a function for the Epoch Counter\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"Current Epoch: \" + str(epoch+1) + ' Loss: ' + str(logs.get('loss')) + '                     \\r')\n",
    "        losses.append(logs.get('loss'))\n",
    "#EarlyStopping criterion to prevent overfitting\n",
    "def train(model, train_inputs, train_outputs, verbose=False):\n",
    "    mae_es= keras.callbacks.EarlyStopping(monitor='val_loss', patience=1000,\n",
    "                                          min_delta=1e-5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    terminate = keras.callbacks.TerminateOnNaN()\n",
    "    # train model \n",
    "    EPOCHS = 10000 # Number of EPOCHS\n",
    "    history = model.fit([train_inputs[:,0], train_inputs[:,1], train_inputs[:,2], train_inputs[:,3]], train_outputs[:,0],\n",
    "                        epochs=EPOCHS,\n",
    "                        shuffle=False, batch_size=len(train_inputs), verbose = False, callbacks=[mae_es, terminate],\n",
    "                        validation_split=0.2)\n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Sq Error')\n",
    "        plt.plot(history.epoch, np.array(history.history['loss']),label='Training loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(w):\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the objective function for the genetic algorithm\n",
    "The objective function consists of three parts: \n",
    "1. The mean squared error of the model on the test set \n",
    "2. A penalty term for non-linear activation functions\n",
    "3. A penalty term for weights that are not fixed, simple values such as 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN to genetic algorithm connection through individual layer function defined above make connection\n",
    "# create_model(individual) used in the GA next\n",
    "def objective_function(individual):\n",
    "    new_model, trainable = create_model(individual)\n",
    "    #print (\"Trainable: \", trainable)\n",
    "    valid_flag = True\n",
    "    stringlist = []\n",
    "    new_model.summary(print_fn=lambda x: stringlist.append(x)) #Determine # of trainable weights\n",
    "    for string in stringlist:\n",
    "        if (\"Trainable params\" in string):\n",
    "            ntrainable = int(string[-1])\n",
    "\n",
    "    if (ntrainable > 0):  # Train and evaluate model\n",
    "        train(new_model, train_inputs, train_outputs, verbose=False)\n",
    "\n",
    "    mse_train = new_model.evaluate([train_inputs[:, 0], train_inputs[:, 1], train_inputs[:, 2], train_inputs[:, 3]], \n",
    "                                   train_outputs, verbose=0)\n",
    "    mse_test = new_model.evaluate([test_inputs[:, 0], test_inputs[:, 1], test_inputs[:, 2], test_inputs[:, 3]], \n",
    "                                  test_outputs, verbose=0)\n",
    "\n",
    "    if (np.isnan(mse_train) or np.isnan(mse_test) or np.isinf(mse_train) or np.isinf(mse_test)):\n",
    "        valid_flag = False\n",
    "\n",
    "    weights = new_model.get_weights()\n",
    "    weight_list = []\n",
    "    for weight in weights:\n",
    "        weight_list.append(weight[0][0])\n",
    "    weight_list = np.array(weight_list)  # Collect final weights of model\n",
    "\n",
    "    #handle nan weights\n",
    "    if (np.isnan(weight_list).any()):\n",
    "        valid_flag = False\n",
    "\n",
    "    if (valid_flag):\n",
    "        print (weight_list)\n",
    "    else:\n",
    "        mse_test = 1e50\n",
    "\n",
    "    actfunc_term = [i**2 for i in individual[:nact_terms]]\n",
    "    weights = individual[nact_terms:]\n",
    "    weight_term = 0\n",
    "    for j in range(nweight_terms):\n",
    "        weight_term += f3(weights[j])\n",
    "        \n",
    "    mse_test_term = np.log10(mse_test)\n",
    "\n",
    "    p = 0.1\n",
    "    obj = mse_test_term + p*(np.sum(actfunc_term) + weight_term)  # Add MSE term, activation function term and weight score term of get obj func\n",
    "    print (\"Individual: \", individual, flush=True)\n",
    "    print (\"Objective function: \", mse_test, np.sum(actfunc_term), weight_term, obj, flush=True)\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    return (obj,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up the genetic algorithm and saving the results\n",
    "Each network is expressed as an individual of 17 genes, the genes representing the possible activations and weights. We thus define an individual to be a custom container, which is repeated to create a population. For details on this, please refer to the DEAP guide on setting up a genetic algorithm, which can be found [here](https://deap.readthedocs.io/en/master/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### DEAP #####################\n",
    "#create fitness class and individual class\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "# create customised tool box to call later \n",
    "toolbox = base.Toolbox()  # Determine # of trainable weights\n",
    "#pool = Pool(1)\n",
    "#toolbox.register(\"attr_int\", random.randint, 0, 3)\n",
    "# custom Repeat function \n",
    "def custom_initRepeat(container, func, max1, max2, n):\n",
    "    func_list = []\n",
    "    for i in range(n):\n",
    "        if (i < nact_terms):\n",
    "            func_list.append(func(0, max1))  #Define custom repeat func to design tailormade individuals\n",
    "        else:\n",
    "            func_list.append(func(0, max2))\n",
    "    return container(func_list[i] for i in range(n))\n",
    "\n",
    "#gen = initRepeat(list, random.randint, 3, 7, 4)\n",
    "toolbox.register(\"create_individual\", custom_initRepeat, creator.Individual, random.randint, # register customised tool box in GA to be called with available tool\n",
    "                 max1=4, max2=2, n=nact_terms+nweight_terms)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.create_individual) # population is used in next celll for GA to play torunament and choose best\n",
    "# custom mutation function \n",
    "def custom_mutation(individual, max1, max2, indpb):\n",
    "    size = len(individual)\n",
    "    for i in range(size):\n",
    "        if random.random() < indpb:\n",
    "            if (i < nact_terms):     #Define custom mutation\n",
    "                individual[i] = random.randint(0, max1)\n",
    "            else:\n",
    "                individual[i] = random.randint(0, max2)\n",
    "    return individual,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the two point crossover method for mating two individuals, and perform a random mutation using the custom mutation function. We then define a population size of 200 and define the statistics that we wish to log in the output of the code. The stats object decides which quantities are saved to the logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.train' has no attribute 'AdamOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fa70d55581ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m  \u001b[0;31m# GA called run on user definsed tool box and avaiable tool with population, cxpb, mutpb, ngens variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meaSimple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalloffame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# ploting of data and evolution of equation is in the val_melting notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ade2ae1685c3>\u001b[0m in \u001b[0;36mobjective_function\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# create_model(individual) used in the GA next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print (\"Trainable: \", trainable)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalid_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-f6c137c70bde>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model comple to draw kera entire network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.train' has no attribute 'AdamOptimizer'"
     ]
    }
   ],
   "source": [
    "cxpb = 0.5 # crossover probablity\n",
    "mutpb = 0.3 # mutation probablity\n",
    "ngens = 3 # no. of generation to train\n",
    "\n",
    "# GA avaiable tool box and user definsed tool box from above register\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)  #crossover\n",
    "#toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=3, indpb=mutpb)\n",
    "toolbox.register(\"mutate\", custom_mutation, max1=4, max2=2, indpb=mutpb)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
    "toolbox.register(\"evaluate\", objective_function)  #selection\n",
    "\n",
    "random.seed(100000)\n",
    "population = toolbox.population(n=5) #population \n",
    "interesting_individual = [0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 2] # individual players \n",
    "for i in range(len(interesting_individual)):\n",
    "    population[0][i] = interesting_individual[i]\n",
    "\n",
    "hof = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "#Use simple evolutionary algorithm\n",
    " # GA called run on user definsed tool box and avaiable tool with population, cxpb, mutpb, ngens variable\n",
    "pop, logbook = algorithms.eaSimple(population, toolbox, cxpb, mutpb, ngens, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "# ploting of data and evolution of equation is in the val_melting notebook\n",
    "#(https://proxy.nanohub.org/weber/1919263/NXUGNZSrkpFDc2XN/26/notebooks/data/pnn/eval_melting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
